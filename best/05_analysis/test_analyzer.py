#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê²°ê³¼ ë¶„ì„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
"""

import sys
import json
import tempfile
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))

from configs.best_config import CONFIG, logger
from results_analyzer import ResultsAnalyzer, PerformanceMetrics

def create_dummy_inference_results(output_dir: Path, num_images: int = 5):
    """ë”ë¯¸ ì¶”ë¡  ê²°ê³¼ íŒŒì¼ë“¤ ìƒì„±"""
    
    dummy_results = []
    
    for i in range(num_images):
        # ë”ë¯¸ ê²€ì¶œ ê²°ê³¼ ìƒì„±
        detections = []
        num_detections = (i % 3) + 1  # 1-3ê°œ ê²€ì¶œ
        
        for j in range(num_detections):
            detection = {
                'bbox': [100 + j*50, 100 + j*30, 200 + j*50, 200 + j*30],
                'confidence': 0.7 + (j * 0.1),
                'class_id': j % 2,
                'class_name': 'greenhouse_multi' if j % 2 == 0 else 'greenhouse_single',
                'area': 10000 + j*1000
            }
            detections.append(detection)
        
        # ë”ë¯¸ ê²°ê³¼ ìƒì„±
        result = {
            'image_path': f'/dummy/path/image_{i:03d}.jpg',
            'detections': detections,
            'processing_time': 0.2 + (i * 0.05),  # 0.2~0.4ì´ˆ
            'confidence_stats': {
                'mean': 0.75,
                'std': 0.1,
                'min': 0.6,
                'max': 0.9
            },
            'metadata': {
                'model_type': 'YOLO',
                'device': 'cuda',
                'timestamp': '2025-10-28T15:00:00'
            }
        }
        
        dummy_results.append(result)
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        result_file = output_dir / f"image_{i:03d}_result.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
    
    logger.info(f"ë”ë¯¸ ì¶”ë¡  ê²°ê³¼ ìƒì„± ì™„ë£Œ: {num_images}ê°œ íŒŒì¼")
    return dummy_results

def test_analyzer_initialization():
    """ë¶„ì„ê¸° ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ”§ ê²°ê³¼ ë¶„ì„ê¸° ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸")
    
    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            analyzer = ResultsAnalyzer(output_dir=temp_dir)
            
            logger.info(f"ì¶œë ¥ ë””ë ‰í† ë¦¬: {analyzer.output_dir}")
            logger.info("âœ… ê²°ê³¼ ë¶„ì„ê¸° ì´ˆê¸°í™” ì„±ê³µ")
            return analyzer
            
    except Exception as e:
        logger.error(f"âŒ ê²°ê³¼ ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None

def test_performance_metrics():
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­ í…ŒìŠ¤íŠ¸")
    
    try:
        # ë”ë¯¸ ë©”íŠ¸ë¦­ ìƒì„±
        metrics = PerformanceMetrics()
        metrics.map_50 = 0.85
        metrics.map_75 = 0.70
        metrics.precision = 0.82
        metrics.recall = 0.78
        metrics.f1_score = 0.80
        metrics.avg_inference_time = 0.25
        metrics.throughput_fps = 4.0
        metrics.avg_confidence = 0.75
        metrics.total_detections = 123
        
        # í´ë˜ìŠ¤ë³„ ë©”íŠ¸ë¦­
        metrics.class_metrics = {
            'greenhouse_multi': {'count': 80, 'percentage': 65.0},
            'greenhouse_single': {'count': 43, 'percentage': 35.0}
        }
        
        # ì‹ ë¢°ë„ ë¶„í¬
        metrics.confidence_distribution = {
            '0.0-0.3': 5,
            '0.3-0.5': 15,
            '0.5-0.7': 35,
            '0.7-0.9': 50,
            '0.9-1.0': 18
        }
        
        logger.info(f"mAP@0.5: {metrics.map_50}")
        logger.info(f"í‰ê·  ì¶”ë¡  ì‹œê°„: {metrics.avg_inference_time*1000:.1f}ms")
        logger.info(f"ì´ ê²€ì¶œ ìˆ˜: {metrics.total_detections}")
        logger.info(f"í´ë˜ìŠ¤ ìˆ˜: {len(metrics.class_metrics)}")
        
        logger.info("âœ… ì„±ëŠ¥ ë©”íŠ¸ë¦­ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
        return metrics
        
    except Exception as e:
        logger.error(f"âŒ ì„±ëŠ¥ ë©”íŠ¸ë¦­ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return None

def test_dummy_analysis():
    """ë”ë¯¸ ë°ì´í„°ë¡œ ë¶„ì„ í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ§ª ë”ë¯¸ ë°ì´í„° ë¶„ì„ í…ŒìŠ¤íŠ¸")
    
    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            
            # ë”ë¯¸ ê²°ê³¼ íŒŒì¼ ìƒì„±
            results_dir = temp_path / "results"
            results_dir.mkdir()
            
            dummy_results = create_dummy_inference_results(results_dir, num_images=10)
            
            # ë¶„ì„ê¸° ì´ˆê¸°í™”
            output_dir = temp_path / "analysis"
            analyzer = ResultsAnalyzer(output_dir=str(output_dir))
            
            # ë¶„ì„ ì‹¤í–‰
            report = analyzer.analyze_inference_results(
                results_dir=str(results_dir),
                model_name="Test_Model",
                dataset_name="Test_Dataset"
            )
            
            logger.info(f"ë¶„ì„ ì™„ë£Œ:")
            logger.info(f"  - ì´ ê²€ì¶œ ìˆ˜: {report.overall_metrics.total_detections}")
            logger.info(f"  - í‰ê·  ì‹ ë¢°ë„: {report.overall_metrics.avg_confidence:.3f}")
            logger.info(f"  - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {report.overall_metrics.avg_inference_time*1000:.1f}ms")
            logger.info(f"  - ê²€ì¶œ ë°€ë„: {report.overall_metrics.detection_density:.2f}")
            logger.info(f"  - ì‹œê°í™” íŒŒì¼ ìˆ˜: {len(report.visualization_paths)}")
            logger.info(f"  - ê¶Œì¥ì‚¬í•­ ìˆ˜: {len(report.recommendations)}")
            
            logger.info("âœ… ë”ë¯¸ ë°ì´í„° ë¶„ì„ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            return True
            
    except Exception as e:
        logger.error(f"âŒ ë”ë¯¸ ë°ì´í„° ë¶„ì„ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_visualization_generation():
    """ì‹œê°í™” ìƒì„± í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ“ˆ ì‹œê°í™” ìƒì„± í…ŒìŠ¤íŠ¸")
    
    try:
        # ë”ë¯¸ ë©”íŠ¸ë¦­ìœ¼ë¡œ ì‹œê°í™” í…ŒìŠ¤íŠ¸
        metrics = test_performance_metrics()
        if not metrics:
            return False
        
        with tempfile.TemporaryDirectory() as temp_dir:
            analyzer = ResultsAnalyzer(output_dir=temp_dir)
            
            # ë”ë¯¸ ì¶”ë¡  ê²°ê³¼
            dummy_inference_results = [
                {
                    'detections': [
                        {'confidence': 0.8, 'class_name': 'greenhouse_multi'},
                        {'confidence': 0.7, 'class_name': 'greenhouse_single'}
                    ],
                    'processing_time': 0.25
                },
                {
                    'detections': [
                        {'confidence': 0.9, 'class_name': 'greenhouse_multi'}
                    ],
                    'processing_time': 0.30
                }
            ]
            
            # ì‹œê°í™” ìƒì„±
            viz_paths = analyzer._create_visualizations(
                dummy_inference_results, metrics, "Test_Model", "Test_Dataset"
            )
            
            logger.info(f"ìƒì„±ëœ ì‹œê°í™” íŒŒì¼ ìˆ˜: {len(viz_paths)}")
            for path in viz_paths:
                if Path(path).exists():
                    logger.info(f"  âœ… {Path(path).name}")
                else:
                    logger.warning(f"  âŒ {Path(path).name} (ìƒì„± ì‹¤íŒ¨)")
            
            logger.info("âœ… ì‹œê°í™” ìƒì„± í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            return True
            
    except Exception as e:
        logger.error(f"âŒ ì‹œê°í™” ìƒì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_config_validation():
    """ì„¤ì • ê²€ì¦ í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ”§ ì„¤ì • ê²€ì¦ í…ŒìŠ¤íŠ¸")
    
    # ë¶„ì„ ê´€ë ¨ ì„¤ì • í™•ì¸
    logger.info(f"ë°ì´í„° ì¶œë ¥ ê²½ë¡œ: {CONFIG.data.output_path}")
    logger.info(f"í”„ë¡œì íŠ¸ ì´ë¦„: {CONFIG.project_name}")
    logger.info(f"ë²„ì „: {CONFIG.version}")
    
    # ì¶”ë¡  ì„¤ì • í™•ì¸ (ë¶„ì„ì— í•„ìš”)
    logger.info(f"ì‹ ë¢°ë„ ì„ê³„ê°’: {CONFIG.inference.conf_threshold}")
    logger.info(f"IoU ì„ê³„ê°’: {CONFIG.inference.iou_threshold}")
    
    return True

if __name__ == "__main__":
    print("ğŸ“Š Nong-View Best Performance - ê²°ê³¼ ë¶„ì„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    success_count = 0
    total_tests = 5
    
    # 1. ì„¤ì • ê²€ì¦
    if test_config_validation():
        success_count += 1
    
    # 2. ë¶„ì„ê¸° ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸
    analyzer = test_analyzer_initialization()
    if analyzer:
        success_count += 1
    
    # 3. ì„±ëŠ¥ ë©”íŠ¸ë¦­ í…ŒìŠ¤íŠ¸
    metrics = test_performance_metrics()
    if metrics:
        success_count += 1
    
    # 4. ì‹œê°í™” ìƒì„± í…ŒìŠ¤íŠ¸
    if test_visualization_generation():
        success_count += 1
    
    # 5. ë”ë¯¸ ë°ì´í„° ë¶„ì„ í…ŒìŠ¤íŠ¸
    if test_dummy_analysis():
        success_count += 1
    
    print("\n" + "=" * 60)
    print(f"í…ŒìŠ¤íŠ¸ ê²°ê³¼: {success_count}/{total_tests} ì„±ê³µ")
    
    if success_count == total_tests:
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
        print("\nğŸ“Š ì£¼ìš” ê¸°ëŠ¥:")
        print("  âœ… ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìë™ ê³„ì‚°")
        print("  âœ… ëŒ€í™”í˜• ì‹œê°í™” ìƒì„±")
        print("  âœ… ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±")
        print("  âœ… ìë™ ê¶Œì¥ì‚¬í•­ ì œê³µ")
        print("  âœ… ëª¨ë¸ ë¹„êµ ë¶„ì„ ì§€ì›")
    else:
        print("âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        
    print("=" * 60)