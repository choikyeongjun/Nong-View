#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Nong-View Best Performance Configuration
ìµœì  ì„±ëŠ¥ì„ ìœ„í•œ í†µí•© ì„¤ì • ì‹œìŠ¤í…œ

ê°œë°œíŒ€: Claude Opus (Architecture) + Claude Sonnet (Implementation)
ë²„ì „: 1.0.0
ë‚ ì§œ: 2025-10-28
"""

import os
import torch
from pathlib import Path
from dataclasses import dataclass, field
from typing import Dict, List, Tuple, Optional, Any
from enum import Enum

class ModelType(Enum):
    """ì§€ì›í•˜ëŠ” ëª¨ë¸ íƒ€ì…"""
    # Detection ëª¨ë¸
    YOLO11N = "yolo11n"
    YOLO11S = "yolo11s"
    YOLO11M = "yolo11m"
    YOLO11L = "yolo11l"
    YOLO11X = "yolo11x"
    # Segmentation ëª¨ë¸
    YOLO11N_SEG = "yolo11n-seg"
    YOLO11S_SEG = "yolo11s-seg"
    YOLO11M_SEG = "yolo11m-seg"
    YOLO11L_SEG = "yolo11l-seg"
    YOLO11X_SEG = "yolo11x-seg"

class DatasetType(Enum):
    """ì§€ì›í•˜ëŠ” ë°ì´í„°ì…‹ íƒ€ì…"""
    # Detection ë°ì´í„°ì…‹
    GREENHOUSE_MULTI = "greenhouse_multi"
    GREENHOUSE_SINGLE = "greenhouse_single"
    GROWTH_TIF = "growth_tif"
    # Segmentation ë°ì´í„°ì…‹
    MODEL3_GREENHOUSE_SEG = "model3_greenhouse_seg"

@dataclass
class HardwareConfig:
    """í•˜ë“œì›¨ì–´ ì„¤ì •"""
    # GPU ì„¤ì •
    device: str = "cuda" if torch.cuda.is_available() else "cpu"
    gpu_memory_fraction: float = 0.95  # RTX A6000 48GB ê¸°ì¤€
    cpu_workers: int = field(default_factory=lambda: min(16, os.cpu_count() or 8))
    
    # ë©”ëª¨ë¦¬ ìµœì í™”
    use_amp: bool = True  # Automatic Mixed Precision
    use_tf32: bool = True  # TensorFloat-32
    memory_efficient: bool = True
    
    def __post_init__(self):
        """í•˜ë“œì›¨ì–´ ìµœì í™” ì„¤ì • ì ìš©"""
        if self.device == "cuda":
            # TF32 í™œì„±í™” (Ampere GPU ì´ìƒ)
            if self.use_tf32:
                torch.backends.cuda.matmul.allow_tf32 = True
                torch.backends.cudnn.allow_tf32 = True
            
            # cuDNN ë²¤ì¹˜ë§ˆí¬ í™œì„±í™”
            torch.backends.cudnn.benchmark = True
            
            # ë©”ëª¨ë¦¬ ê´€ë¦¬
            if self.memory_efficient:
                torch.cuda.empty_cache()

@dataclass
class DataConfig:
    """ë°ì´í„° ê´€ë ¨ ì„¤ì •"""
    # ê²½ë¡œ ì„¤ì •
    namwon_data_path: str = "D:/Nong-View/Namwon_data"
    output_path: str = "D:/Nong-View/best/results"
    cache_path: str = "D:/Nong-View/best/cache"
    
    # ë°ì´í„°ì…‹ë³„ ì •ë³´
    dataset_info: Dict[DatasetType, Dict[str, Any]] = field(default_factory=lambda: {
        DatasetType.GREENHOUSE_MULTI: {
            "path": "dataset_greenhouse_multi",
            "classes": ["greenhouse_multi"],
            "total_images": 569,
            "total_objects": 669,
            "class_balance": {"greenhouse_multi": 1.0}
        },
        DatasetType.GREENHOUSE_SINGLE: {
            "path": "dataset_greenhouse_single", 
            "classes": ["greenhouse_single"],
            "total_images": 358,
            "total_objects": 584,
            "class_balance": {"greenhouse_single": 1.0}
        },
        DatasetType.GROWTH_TIF: {
            "path": "growth_tif_dataset",
            "classes": ["IRG_production", "Rye_production", "Greenhouse_single", 
                       "Greenhouse_multi", "Silage_bale"],
            "total_images": 1356,
            "total_objects": 1862,
            "class_balance": {
                "IRG_production": 0.25,     # 74% â†’ 25% (ë‹¤ìš´ ê°€ì¤‘ì¹˜)
                "Silage_bale": 1.0,         # 16% â†’ 1.0 (ê¸°ì¤€)
                "Rye_production": 1.5,      # 8% â†’ 1.5 (ì—… ê°€ì¤‘ì¹˜)
                "Greenhouse_single": 3.0,   # 2% â†’ 3.0 (ê°•í•œ ì—… ê°€ì¤‘ì¹˜)  
                "Greenhouse_multi": 5.0     # 1% â†’ 5.0 (ìµœê°• ì—… ê°€ì¤‘ì¹˜)
            }
        },
        DatasetType.MODEL3_GREENHOUSE_SEG: {
            "path": "model3_greenhouse_seg_processed",
            "classes": ["Greenhouse_single", "Greenhouse_multi"],
            "total_images": 3855,  # ì›ë³¸ 1483 + ì¦ê°• 2372
            "original_images": 1483,
            "augmented_images": 2372,
            "total_objects": 3855,
            "task": "segment",
            "original_image_size": 1024,  # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°
            "recommended_train_size": 1024,  # í•™ìŠµ ê¶Œì¥ í¬ê¸° (ì›ë³¸ í¬ê¸° ìœ ì§€)
            "split_info": {
                "train": 3558,  # ì›ë³¸ 1186 + ì¦ê°• 2372
                "val": 147,
                "test": 150
            },
            "augmentation_info": {
                "enabled": True,
                "factor": 3,
                "method": "stratified_split_segmentation"
            },
            "class_balance": {
                "Greenhouse_single": 1.0,
                "Greenhouse_multi": 1.0
            }
        }
    })
    
    # ë°ì´í„° ë¶„í•  ì„¤ì •
    train_ratio: float = 0.8
    val_ratio: float = 0.1
    test_ratio: float = 0.1
    stratify_method: str = "class_distribution"
    random_seed: int = 42

@dataclass 
class TrainingConfig:
    """í›ˆë ¨ ê´€ë ¨ ì„¤ì •"""
    # ê¸°ë³¸ í›ˆë ¨ íŒŒë¼ë¯¸í„°
    epochs: int = 100
    batch_size: int = 16  # ê¸°ë³¸ê°’ (ìë™ ì¡°ì •ë¨)
    image_size: int = 640
    patience: int = 30
    save_period: int = 10
    
    # í•™ìŠµë¥  ì„¤ì •
    lr0: float = 0.01  # ì´ˆê¸° í•™ìŠµë¥ 
    lrf: float = 0.01  # ìµœì¢… í•™ìŠµë¥  ë¹„ìœ¨
    momentum: float = 0.937
    weight_decay: float = 0.0005
    
    # ì˜µí‹°ë§ˆì´ì € ì„¤ì •
    optimizer: str = "AdamW"  # SGD, Adam, AdamW
    scheduler: str = "cosine"  # linear, cosine
    
    # ì†ì‹¤ í•¨ìˆ˜ ê°€ì¤‘ì¹˜ (YOLO)
    box_loss_gain: float = 7.5
    cls_loss_gain: float = 0.5
    dfl_loss_gain: float = 1.5
    # Segmentation ì „ìš©
    mask_loss_gain: float = 2.5  # Mask loss weight for segmentation
    
    # ì •ê·œí™” ì„¤ì •
    dropout: float = 0.0
    label_smoothing: float = 0.0
    
    # ë°ì´í„° ì¦ê°• ì„¤ì •
    augmentation: Dict[str, Any] = field(default_factory=lambda: {
        # ìƒ‰ìƒ ë³€í™˜
        "hsv_h": 0.015,  # ìƒ‰ì¡°
        "hsv_s": 0.7,    # ì±„ë„  
        "hsv_v": 0.4,    # ëª…ë„
        
        # ê¸°í•˜í•™ì  ë³€í™˜
        "degrees": 10.0,    # íšŒì „
        "translate": 0.1,   # ì´ë™
        "scale": 0.5,       # ìŠ¤ì¼€ì¼
        "shear": 2.0,       # ì „ë‹¨
        "perspective": 0.0, # ì›ê·¼
        
        # í”Œë¦½
        "flipud": 0.5,      # ìƒí•˜ ë°˜ì „
        "fliplr": 0.5,      # ì¢Œìš° ë°˜ì „
        
        # ê³ ê¸‰ ì¦ê°•
        "mosaic": 0.5,      # ëª¨ìì´í¬ (ê°ì†Œ)
        "mixup": 0.1,       # ë¯¹ìŠ¤ì—…
        "copy_paste": 0.3,  # ì¹´í”¼-í˜ì´ìŠ¤íŠ¸ (ì¦ê°€)
        
        # í’ˆì§ˆ í–¥ìƒ ê¸°ë²•
        "erasing": 0.4,     # ëœë¤ ì§€ìš°ê¸°
        "crop_fraction": 1.0, # í¬ë¡­ ë¹„ìœ¨
    })
    
    # ëª¨ë¸ë³„ ìµœì  ì„¤ì •
    model_specific: Dict[ModelType, Dict[str, Any]] = field(default_factory=lambda: {
        # Detection ëª¨ë¸
        ModelType.YOLO11N: {
            "batch_size": 32,
            "lr0": 0.01,
            "warmup_epochs": 3
        },
        ModelType.YOLO11S: {
            "batch_size": 24,
            "lr0": 0.01, 
            "warmup_epochs": 3
        },
        ModelType.YOLO11M: {
            "batch_size": 16,
            "lr0": 0.008,
            "warmup_epochs": 5
        },
        ModelType.YOLO11L: {
            "batch_size": 12,
            "lr0": 0.005,
            "warmup_epochs": 5  
        },
        ModelType.YOLO11X: {
            "batch_size": 8,
            "lr0": 0.003,
            "warmup_epochs": 5
        },
        # Segmentation ëª¨ë¸ (1024px ì›ë³¸ ë°ì´í„° ìµœì í™”)
        ModelType.YOLO11N_SEG: {
            "batch_size": 8,   # 1024px ê¸°ì¤€ (640pxì¼ ë•Œ 16)
            "imgsz": 1024,     # ì›ë³¸ í¬ê¸° ìœ ì§€
            "lr0": 0.001,
            "warmup_epochs": 3,
            "overlap_mask": True,
            "mask_ratio": 4
        },
        ModelType.YOLO11S_SEG: {
            "batch_size": 6,   # 1024px ê¸°ì¤€ (640pxì¼ ë•Œ 12)
            "imgsz": 1024,
            "lr0": 0.001,
            "warmup_epochs": 3,
            "overlap_mask": True,
            "mask_ratio": 4
        },
        ModelType.YOLO11M_SEG: {
            "batch_size": 16,  # 1024px ê¸°ì¤€, RTX A6000 ìµœì í™”
            "imgsz": 1024,
            "lr0": 0.0008,
            "warmup_epochs": 5,
            "overlap_mask": True,
            "mask_ratio": 4
        },
        ModelType.YOLO11L_SEG: {
            "batch_size": 12,  # 1024px ê¸°ì¤€, RTX A6000 ìµœì í™”
            "imgsz": 1024,
            "lr0": 0.0005,
            "warmup_epochs": 5,
            "overlap_mask": True,
            "mask_ratio": 4
        },
        ModelType.YOLO11X_SEG: {
            "batch_size": 8,   # 1024px ê¸°ì¤€, RTX A6000 ìµœì í™”
            "imgsz": 1024,
            "lr0": 0.0003,
            "warmup_epochs": 5,
            "overlap_mask": True,
            "mask_ratio": 4
        }
    })

@dataclass
class InferenceConfig:
    """ì¶”ë¡  ê´€ë ¨ ì„¤ì •"""
    # ì¶”ë¡  íŒŒë¼ë¯¸í„°
    conf_threshold: float = 0.25
    iou_threshold: float = 0.45
    max_det: int = 1000
    
    # ë°°ì¹˜ ì²˜ë¦¬
    batch_size: int = 16
    
    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    image_size: int = 640
    normalize: bool = True
    
    # í›„ì²˜ë¦¬ ìµœì í™”
    agnostic_nms: bool = False  # í´ë˜ìŠ¤ ë¬´ê´€ NMS
    multi_label: bool = False   # ë‹¤ì¤‘ ë¼ë²¨
    
    # ì„±ëŠ¥ ìµœì í™”
    half_precision: bool = True  # FP16 ì¶”ë¡ 
    device: str = "cuda"
    
    # ê²°ê³¼ ì €ì¥
    save_txt: bool = True
    save_conf: bool = True
    save_crop: bool = False
    
    # ì‹œê°í™”
    visualize: bool = True
    line_thickness: int = 2
    font_size: float = 1.0

@dataclass
class BenchmarkConfig:
    """ë²¤ì¹˜ë§ˆí¬ ê´€ë ¨ ì„¤ì •"""
    # ì„±ëŠ¥ ì¸¡ì • í•­ëª©
    metrics: List[str] = field(default_factory=lambda: [
        "mAP@0.5", "mAP@0.75", "mAP@0.5:0.95",
        "precision", "recall", "f1_score",
        "inference_time", "preprocessing_time", "postprocessing_time",
        "gpu_memory", "cpu_usage", "throughput"
    ])
    
    # ë²¤ì¹˜ë§ˆí¬ ì„¤ì •
    num_runs: int = 5  # í‰ê·  ì„±ëŠ¥ ê³„ì‚°ìš©
    warmup_runs: int = 3  # ì›œì—… ì‹¤í–‰
    
    # ë¹„êµ ëŒ€ìƒ
    baseline_models: List[ModelType] = field(default_factory=lambda: [
        ModelType.YOLO11N, ModelType.YOLO11S, ModelType.YOLO11M
    ])
    
    # ê²°ê³¼ ì €ì¥
    save_detailed: bool = True
    save_plots: bool = True
    save_csv: bool = True

@dataclass
class BestConfig:
    """ìµœì  ì„±ëŠ¥ í†µí•© ì„¤ì •"""
    # í•˜ìœ„ ì„¤ì •ë“¤
    hardware: HardwareConfig = field(default_factory=HardwareConfig)
    data: DataConfig = field(default_factory=DataConfig)
    training: TrainingConfig = field(default_factory=TrainingConfig) 
    inference: InferenceConfig = field(default_factory=InferenceConfig)
    benchmark: BenchmarkConfig = field(default_factory=BenchmarkConfig)
    
    # í”„ë¡œì íŠ¸ ì •ë³´
    project_name: str = "Nong-View-Best"
    version: str = "1.0.0"
    description: str = "ìµœì  ì„±ëŠ¥ ë†ì—… AI ê°ì²´íƒì§€ ì‹œìŠ¤í…œ"
    
    # ë¡œê¹… ì„¤ì •
    log_level: str = "INFO"
    log_format: str = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    
    # ì‹¤í—˜ ì¶”ì 
    experiment_name: str = field(default_factory=lambda: f"best_experiment_{os.getpid()}")
    save_checkpoints: bool = True
    
    def __post_init__(self):
        """ì„¤ì • í›„ì²˜ë¦¬"""
        # ê²½ë¡œ ìƒì„±
        for path in [self.data.output_path, self.data.cache_path]:
            Path(path).mkdir(parents=True, exist_ok=True)
        
        # í•˜ë“œì›¨ì–´ ìµœì í™” ì ìš©
        self.hardware.__post_init__()
    
    def get_model_config(self, model_type: ModelType) -> Dict[str, Any]:
        """ëª¨ë¸ë³„ ìµœì  ì„¤ì • ë°˜í™˜"""
        base_config = {
            "epochs": self.training.epochs,
            "batch": self.training.batch_size,
            "imgsz": self.training.image_size,
            "lr0": self.training.lr0,
            "optimizer": self.training.optimizer,
        }
        
        # ëª¨ë¸ë³„ íŠ¹í™” ì„¤ì • ì ìš©
        if model_type in self.training.model_specific:
            base_config.update(self.training.model_specific[model_type])
        
        return base_config
    
    def get_dataset_config(self, dataset_type: DatasetType) -> Dict[str, Any]:
        """ë°ì´í„°ì…‹ë³„ ì„¤ì • ë°˜í™˜"""
        if dataset_type not in self.data.dataset_info:
            raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ë°ì´í„°ì…‹: {dataset_type}")
        
        return self.data.dataset_info[dataset_type]

# ì „ì—­ ì„¤ì • ì¸ìŠ¤í„´ìŠ¤
CONFIG = BestConfig()

# í¸ì˜ í•¨ìˆ˜ë“¤
def get_device():
    """í˜„ì¬ ë””ë°”ì´ìŠ¤ ë°˜í™˜"""
    return CONFIG.hardware.device

def get_output_path(subdir: str = "") -> Path:
    """ì¶œë ¥ ê²½ë¡œ ë°˜í™˜"""
    path = Path(CONFIG.data.output_path)
    if subdir:
        path = path / subdir
    path.mkdir(parents=True, exist_ok=True)
    return path

def get_cache_path(subdir: str = "") -> Path:
    """ìºì‹œ ê²½ë¡œ ë°˜í™˜"""
    path = Path(CONFIG.data.cache_path)
    if subdir:
        path = path / subdir
    path.mkdir(parents=True, exist_ok=True)
    return path

def setup_logging():
    """ë¡œê¹… ì„¤ì •"""
    import logging
    
    logging.basicConfig(
        level=getattr(logging, CONFIG.log_level),
        format=CONFIG.log_format,
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler(get_output_path() / "best_performance.log")
        ]
    )
    
    return logging.getLogger(__name__)

# ë¡œê±° ì´ˆê¸°í™”
logger = setup_logging()

if __name__ == "__main__":
    # ì„¤ì • ê²€ì¦ ë° ì¶œë ¥
    print("ğŸ† Nong-View Best Performance Configuration")
    print("=" * 60)
    print(f"í”„ë¡œì íŠ¸: {CONFIG.project_name} v{CONFIG.version}")
    print(f"ë””ë°”ì´ìŠ¤: {CONFIG.hardware.device}")
    print(f"GPU ë©”ëª¨ë¦¬: {CONFIG.hardware.gpu_memory_fraction * 100:.0f}%")
    print(f"CPU ì›Œì»¤: {CONFIG.hardware.cpu_workers}ê°œ")
    print(f"ì¶œë ¥ ê²½ë¡œ: {CONFIG.data.output_path}")
    
    print("\nğŸ“Š ë°ì´í„°ì…‹ ì •ë³´:")
    for dataset_type, info in CONFIG.data.dataset_info.items():
        print(f"  - {dataset_type.value}: {info['total_images']}ê°œ ì´ë¯¸ì§€")
    
    print(f"\nğŸ¯ ì„±ëŠ¥ ëª©í‘œ:")
    print(f"  - ì •í™•ë„: mAP@0.5 > 95%")
    print(f"  - ì†ë„: ì¶”ë¡  < 200ms/ì´ë¯¸ì§€")
    print(f"  - ë©”ëª¨ë¦¬: GPU í™œìš©ë¥  > 90%")
    print("=" * 60)