#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Nong-View Best Performance - ìµœì í™”ëœ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œìŠ¤í…œ

ê¸°ì¡´ ì‹¤ì œ ìŠ¤í¬ë¦½íŠ¸ì˜ ê²€ì¦ëœ ê¸°ëŠ¥ + Jupyter ë…¸íŠ¸ë¶ì˜ ê³ ê¸‰ ì•Œê³ ë¦¬ì¦˜ í†µí•©
- 3ê°œ ë°ì´í„°ì…‹ í†µí•© ì²˜ë¦¬ (greenhouse_multi, greenhouse_single, growth_tif)
- í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²° (growth_tif 74% IRG ì§€ë°° ë¬¸ì œ)
- ê³„ì¸µí™” ë¶„í•  (stratified split)
- ë°ì´í„° í’ˆì§ˆ ìë™ ê´€ë¦¬
- ë†ì—… íŠ¹í™” ë°ì´í„° ì¦ê°•

ë‹´ë‹¹: Claude Sonnet (Data Processing & Integration)
ê°œë°œ ë‚ ì§œ: 2025-10-28
"""

import os
import json
import yaml
import shutil
import random
import argparse
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any, Union
from collections import Counter, defaultdict
from dataclasses import dataclass, asdict
import logging

import cv2
import numpy as np
import pandas as pd
from PIL import Image
from tqdm import tqdm
import rasterio
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.utils.class_weight import compute_class_weight
import albumentations as A

# ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°
import sys
sys.path.append(str(Path(__file__).parent.parent))
from configs.best_config import CONFIG, DatasetType, ModelType, logger
from utils.data_utils import DatasetProcessor, DataAugmentation, DataQualityAnalyzer, ImageInfo, DatasetStats

@dataclass
class ProcessingStats:
    """ì²˜ë¦¬ í†µê³„ í´ë˜ìŠ¤"""
    original_images: int = 0
    processed_images: int = 0
    augmented_images: int = 0
    filtered_images: int = 0
    total_objects: int = 0
    class_distribution: Dict[str, int] = None
    quality_metrics: Dict[str, float] = None
    processing_time: float = 0.0
    
    def __post_init__(self):
        if self.class_distribution is None:
            self.class_distribution = {}
        if self.quality_metrics is None:
            self.quality_metrics = {}

class OptimizedDataProcessor:
    """ìµœì í™”ëœ ë°ì´í„° ì²˜ë¦¬ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, output_dir: str = None, enable_quality_filter: bool = True):
        self.output_dir = Path(output_dir) if output_dir else Path(CONFIG.data.output_path) / "processed_datasets"
        self.enable_quality_filter = enable_quality_filter
        self.logger = logging.getLogger(__name__)
        
        # í•˜ìœ„ í´ë˜ìŠ¤ ì´ˆê¸°í™”
        self.quality_analyzer = DataQualityAnalyzer()
        self.balanced_creator = BalancedDatasetCreator()
        self.advanced_augmenter = AdvancedDataAugmentation()
        
        # í†µê³„ ì´ˆê¸°í™”
        self.stats = defaultdict(ProcessingStats)
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.logger.info(f"ìµœì í™”ëœ ë°ì´í„° ì²˜ë¦¬ê¸° ì´ˆê¸°í™”: {self.output_dir}")
    
    def process_all_datasets(self, target_dataset_types: List[DatasetType] = None) -> Dict[str, ProcessingStats]:
        """ëª¨ë“  ë°ì´í„°ì…‹ í†µí•© ì²˜ë¦¬"""
        if target_dataset_types is None:
            target_dataset_types = list(DatasetType)
        
        self.logger.info(f"í†µí•© ë°ì´í„° ì²˜ë¦¬ ì‹œì‘: {len(target_dataset_types)}ê°œ ë°ì´í„°ì…‹")
        
        all_results = {}
        
        for dataset_type in target_dataset_types:
            try:
                self.logger.info(f"ì²˜ë¦¬ ì‹œì‘: {dataset_type.value}")
                result = self.process_single_dataset(dataset_type)
                all_results[dataset_type.value] = result
                self.logger.info(f"ì²˜ë¦¬ ì™„ë£Œ: {dataset_type.value}")
                
            except Exception as e:
                self.logger.error(f"ë°ì´í„°ì…‹ ì²˜ë¦¬ ì‹¤íŒ¨ {dataset_type.value}: {e}")
                continue
        
        # í†µí•© ê²°ê³¼ ì €ì¥
        self._save_processing_report(all_results)
        
        return all_results
    
    def process_single_dataset(self, dataset_type: DatasetType) -> ProcessingStats:
        """ë‹¨ì¼ ë°ì´í„°ì…‹ ìµœì í™” ì²˜ë¦¬"""
        import time
        start_time = time.time()
        
        # 1. ë°ì´í„°ì…‹ ìŠ¤ìº” ë° ë¶„ì„
        processor = DatasetProcessor(dataset_type)
        image_infos, dataset_stats = processor.scan_dataset()
        
        if not image_infos:
            raise ValueError(f"ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {dataset_type.value}")
        
        self.logger.info(f"ë°ì´í„°ì…‹ ìŠ¤ìº” ì™„ë£Œ: {len(image_infos)}ê°œ ì´ë¯¸ì§€")
        
        # 2. ë°ì´í„° í’ˆì§ˆ í•„í„°ë§
        if self.enable_quality_filter:
            image_infos = self._filter_by_quality(image_infos, dataset_type)
        
        # 3. í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°
        balanced_infos = self.balanced_creator.create_balanced_dataset(
            image_infos, dataset_type, dataset_stats
        )
        
        # 4. ê³„ì¸µí™” ë¶„í• 
        splits = self._create_stratified_splits(balanced_infos, dataset_type)
        
        # 5. ì¶œë ¥ ë””ë ‰í† ë¦¬ êµ¬ì„±
        output_path = self.output_dir / f"best_{dataset_type.value}"
        self._setup_output_structure(output_path)
        
        # 6. ë°ì´í„° ë³µì‚¬ ë° ì¦ê°•
        processed_stats = self._copy_and_augment_data(splits, output_path, dataset_type)
        
        # 7. YAML ë° ë©”íƒ€ë°ì´í„° ìƒì„±
        self._generate_dataset_files(splits, output_path, dataset_type, processed_stats)
        
        # ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡
        processed_stats.processing_time = time.time() - start_time
        
        self.logger.info(f"ë°ì´í„°ì…‹ ì²˜ë¦¬ ì™„ë£Œ: {dataset_type.value} ({processed_stats.processing_time:.2f}ì´ˆ)")
        
        return processed_stats
    
    def _filter_by_quality(self, image_infos: List[ImageInfo], dataset_type: DatasetType) -> List[ImageInfo]:
        """ë°ì´í„° í’ˆì§ˆ ê¸°ë°˜ í•„í„°ë§"""
        self.logger.info("ë°ì´í„° í’ˆì§ˆ í•„í„°ë§ ì‹œì‘...")
        
        # í’ˆì§ˆ ì ìˆ˜ ì„ê³„ê°’ (ë°ì´í„°ì…‹ë³„ ì¡°ì •)
        quality_thresholds = {
            DatasetType.GREENHOUSE_MULTI: 0.4,   # ìƒëŒ€ì ìœ¼ë¡œ ë†’ì€ í’ˆì§ˆ ìš”êµ¬
            DatasetType.GREENHOUSE_SINGLE: 0.4,  
            DatasetType.GROWTH_TIF: 0.3          # TIFëŠ” ìƒëŒ€ì ìœ¼ë¡œ ë‚®ì€ ì„ê³„ê°’
        }
        
        threshold = quality_thresholds.get(dataset_type, 0.35)
        
        # í’ˆì§ˆ ì ìˆ˜ê°€ ì—†ëŠ” ê²½ìš° ê³„ì‚°
        for info in tqdm(image_infos, desc="í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"):
            if info.quality_score == 0.0:
                info.quality_score = self.quality_analyzer.analyze_image_quality(info.filepath)
        
        # ì´ìƒì¹˜ íƒì§€
        outliers = self.quality_analyzer.detect_outliers(image_infos)
        
        # í•„í„°ë§ ì ìš©
        filtered_infos = []
        filtered_count = 0
        
        for i, info in enumerate(image_infos):
            # í’ˆì§ˆ ì ìˆ˜ ë° ì´ìƒì¹˜ ì—¬ë¶€ í™•ì¸
            if info.quality_score >= threshold and not outliers[i]:
                filtered_infos.append(info)
            else:
                filtered_count += 1
                self.logger.debug(f"í•„í„°ë§ë¨: {info.filename} (í’ˆì§ˆ: {info.quality_score:.3f}, ì´ìƒì¹˜: {outliers[i]})")
        
        self.logger.info(f"í’ˆì§ˆ í•„í„°ë§ ì™„ë£Œ: {len(filtered_infos)}ê°œ ìœ ì§€, {filtered_count}ê°œ ì œê±°")
        
        return filtered_infos
    
    def _create_stratified_splits(self, image_infos: List[ImageInfo], dataset_type: DatasetType) -> Dict[str, List[ImageInfo]]:
        """ê³„ì¸µí™” ë¶„í•  ìƒì„±"""
        self.logger.info("ê³„ì¸µí™” ë°ì´í„° ë¶„í•  ì‹œì‘...")
        
        # ë¶„í• ì„ ìœ„í•œ ë ˆì´ë¸” ìƒì„±
        stratify_labels = []
        for info in image_infos:
            if info.class_distribution:
                # ê°€ì¥ ë§ì€ ê°ì²´ë¥¼ ê°€ì§„ í´ë˜ìŠ¤ë¥¼ ëŒ€í‘œ í´ë˜ìŠ¤ë¡œ ì‚¬ìš©
                dominant_class = max(info.class_distribution, key=info.class_distribution.get)
                stratify_labels.append(dominant_class)
            else:
                stratify_labels.append('no_label')
        
        # í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
        class_counts = Counter(stratify_labels)
        self.logger.info(f"í´ë˜ìŠ¤ ë¶„í¬: {dict(class_counts)}")
        
        # ìµœì†Œ í´ë˜ìŠ¤ ìƒ˜í”Œ ìˆ˜ í™•ì¸
        min_samples = min(class_counts.values()) if class_counts else 0
        
        try:
            if min_samples >= 3:  # ê³„ì¸µí™” ë¶„í•  ê°€ëŠ¥
                # StratifiedShuffleSplit ì‚¬ìš©
                splitter = StratifiedShuffleSplit(
                    n_splits=1,
                    test_size=CONFIG.data.val_ratio + CONFIG.data.test_ratio,
                    random_state=CONFIG.data.random_seed
                )
                
                train_idx, temp_idx = next(splitter.split(range(len(image_infos)), stratify_labels))
                
                # ê²€ì¦/í…ŒìŠ¤íŠ¸ ë¶„í• 
                temp_labels = [stratify_labels[i] for i in temp_idx]
                temp_class_counts = Counter(temp_labels)
                
                if min(temp_class_counts.values()) >= 2:
                    val_ratio = CONFIG.data.val_ratio / (CONFIG.data.val_ratio + CONFIG.data.test_ratio)
                    
                    val_splitter = StratifiedShuffleSplit(
                        n_splits=1,
                        test_size=(1 - val_ratio),
                        random_state=CONFIG.data.random_seed
                    )
                    
                    val_idx_temp, test_idx_temp = next(val_splitter.split(temp_idx, temp_labels))
                    val_idx = [temp_idx[i] for i in val_idx_temp]
                    test_idx = [temp_idx[i] for i in test_idx_temp]
                else:
                    # ë‹¨ìˆœ ë¶„í• 
                    mid_point = len(temp_idx) // 2
                    val_idx = temp_idx[:mid_point]
                    test_idx = temp_idx[mid_point:]
                
                self.logger.info("ê³„ì¸µí™” ë¶„í•  ì„±ê³µ")
                
            else:
                raise ValueError("ìƒ˜í”Œ ìˆ˜ ë¶€ì¡±ìœ¼ë¡œ ê³„ì¸µí™” ë¶ˆê°€ëŠ¥")
                
        except Exception as e:
            self.logger.warning(f"ê³„ì¸µí™” ë¶„í•  ì‹¤íŒ¨, ëœë¤ ë¶„í•  ì‚¬ìš©: {e}")
            
            # ëœë¤ ë¶„í• 
            indices = list(range(len(image_infos)))
            random.Random(CONFIG.data.random_seed).shuffle(indices)
            
            n_train = int(len(indices) * CONFIG.data.train_ratio)
            n_val = int(len(indices) * CONFIG.data.val_ratio)
            
            train_idx = indices[:n_train]
            val_idx = indices[n_train:n_train + n_val]
            test_idx = indices[n_train + n_val:]
        
        # ê²°ê³¼ êµ¬ì„±
        splits = {
            'train': [image_infos[i] for i in train_idx],
            'val': [image_infos[i] for i in val_idx],
            'test': [image_infos[i] for i in test_idx]
        }
        
        # ë¶„í•  ê²°ê³¼ ë¡œê·¸
        for split_name, split_data in splits.items():
            class_dist = defaultdict(int)
            for info in split_data:
                for class_name, count in info.class_distribution.items():
                    class_dist[class_name] += count
            
            self.logger.info(f"{split_name}: {len(split_data)}ê°œ ì´ë¯¸ì§€, í´ë˜ìŠ¤ ë¶„í¬: {dict(class_dist)}")
        
        return splits
    
    def _setup_output_structure(self, output_path: Path):
        """ì¶œë ¥ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±"""
        # ê¸°ì¡´ ë””ë ‰í† ë¦¬ ì œê±° (ìˆëŠ” ê²½ìš°)
        if output_path.exists():
            shutil.rmtree(output_path)
        
        # YOLO í˜•ì‹ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
        for split in ['train', 'val', 'test']:
            (output_path / 'images' / split).mkdir(parents=True, exist_ok=True)
            (output_path / 'labels' / split).mkdir(parents=True, exist_ok=True)
    
    def _copy_and_augment_data(self, splits: Dict[str, List[ImageInfo]], 
                             output_path: Path, dataset_type: DatasetType) -> ProcessingStats:
        """ë°ì´í„° ë³µì‚¬ ë° ì¦ê°•"""
        stats = ProcessingStats()
        stats.original_images = sum(len(split) for split in splits.values())
        
        self.logger.info(f"ë°ì´í„° ë³µì‚¬ ë° ì¦ê°• ì‹œì‘: {stats.original_images}ê°œ ì´ë¯¸ì§€")
        
        total_processed = 0
        total_augmented = 0
        class_counter = Counter()
        
        for split_name, image_infos in splits.items():
            self.logger.info(f"{split_name} ì²˜ë¦¬ ì¤‘: {len(image_infos)}ê°œ ì´ë¯¸ì§€")
            
            images_dir = output_path / 'images' / split_name
            labels_dir = output_path / 'labels' / split_name
            
            # ì¦ê°• ì„¤ì • (í›ˆë ¨ ë°ì´í„°ë§Œ)
            apply_augmentation = (split_name == 'train')
            augmentation_factor = self._get_augmentation_factor(dataset_type, split_name)
            
            for info in tqdm(image_infos, desc=f"ë³µì‚¬ ì¤‘ ({split_name})"):
                try:
                    # ì›ë³¸ ì´ë¯¸ì§€ ë³µì‚¬
                    self._copy_single_image(info, images_dir, labels_dir)
                    total_processed += 1
                    
                    # í´ë˜ìŠ¤ ë¶„í¬ ì—…ë°ì´íŠ¸
                    for class_name, count in info.class_distribution.items():
                        class_counter[class_name] += count
                    
                    # ë°ì´í„° ì¦ê°• (í›ˆë ¨ ë°ì´í„°ë§Œ)
                    if apply_augmentation and augmentation_factor > 1:
                        augmented_count = self._augment_single_image(
                            info, images_dir, labels_dir, 
                            augmentation_factor - 1, dataset_type
                        )
                        total_augmented += augmented_count
                        
                        # ì¦ê°•ëœ ì´ë¯¸ì§€ì˜ í´ë˜ìŠ¤ ë¶„í¬ë„ ì—…ë°ì´íŠ¸
                        for class_name, count in info.class_distribution.items():
                            class_counter[class_name] += count * augmented_count
                    
                except Exception as e:
                    self.logger.error(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨ {info.filename}: {e}")
                    continue
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        stats.processed_images = total_processed
        stats.augmented_images = total_augmented
        stats.total_objects = sum(class_counter.values())
        stats.class_distribution = dict(class_counter)
        
        self.logger.info(f"ë°ì´í„° ë³µì‚¬ ì™„ë£Œ: {total_processed}ê°œ ì²˜ë¦¬, {total_augmented}ê°œ ì¦ê°•")
        
        return stats
    
    def _get_augmentation_factor(self, dataset_type: DatasetType, split_name: str) -> int:
        """ë°ì´í„°ì…‹ë³„ ì¦ê°• ë°°ìˆ˜ ê²°ì •"""
        if split_name != 'train':
            return 1
        
        # ë°ì´í„°ì…‹ í¬ê¸°ì— ë”°ë¥¸ ì¦ê°• ë°°ìˆ˜
        augmentation_factors = {
            DatasetType.GREENHOUSE_MULTI: 2,   # 569ê°œ â†’ ì ë‹¹í•œ ì¦ê°•
            DatasetType.GREENHOUSE_SINGLE: 3,  # 358ê°œ â†’ ë” ë§ì€ ì¦ê°•  
            DatasetType.GROWTH_TIF: 1          # 1356ê°œ â†’ ì¦ê°• ì—†ìŒ (ë¶ˆê· í˜• í•´ê²°ì´ ìš°ì„ )
        }
        
        return augmentation_factors.get(dataset_type, 2)
    
    def _copy_single_image(self, info: ImageInfo, images_dir: Path, labels_dir: Path):
        """ë‹¨ì¼ ì´ë¯¸ì§€ ë° ë¼ë²¨ ë³µì‚¬"""
        source_img_path = Path(info.filepath)
        
        # ì´ë¯¸ì§€ ë³µì‚¬
        target_img_path = images_dir / source_img_path.name
        shutil.copy2(source_img_path, target_img_path)
        
        # ë¼ë²¨ ë³µì‚¬ (ìˆëŠ” ê²½ìš°)
        source_label_path = source_img_path.parent.parent / 'labels' / source_img_path.parent.name / f"{source_img_path.stem}.txt"
        
        if source_label_path.exists():
            target_label_path = labels_dir / f"{source_img_path.stem}.txt"
            shutil.copy2(source_label_path, target_label_path)
    
    def _augment_single_image(self, info: ImageInfo, images_dir: Path, 
                            labels_dir: Path, augment_count: int, dataset_type: DatasetType) -> int:
        """ë‹¨ì¼ ì´ë¯¸ì§€ ë°ì´í„° ì¦ê°•"""
        if augment_count <= 0:
            return 0
        
        source_img_path = Path(info.filepath)
        source_label_path = source_img_path.parent.parent / 'labels' / source_img_path.parent.name / f"{source_img_path.stem}.txt"
        
        if not source_label_path.exists():
            return 0  # ë¼ë²¨ì´ ì—†ìœ¼ë©´ ì¦ê°•í•˜ì§€ ì•ŠìŒ
        
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            if source_img_path.suffix.lower() in ['.tif', '.tiff']:
                with rasterio.open(source_img_path) as src:
                    image = src.read()
                    if len(image.shape) == 3:
                        image = np.transpose(image, (1, 2, 0))
                    if image.shape[-1] > 3:
                        image = image[:, :, :3]
                    image = (image / image.max() * 255).astype(np.uint8)
            else:
                image = cv2.imread(str(source_img_path))
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # ë¼ë²¨ ë¡œë“œ
            bboxes, class_labels = self._load_yolo_labels(source_label_path)
            
            if not bboxes:
                return 0
            
            # ì¦ê°• ë³€í™˜ ê°€ì ¸ì˜¤ê¸°
            augmenter = DataAugmentation(dataset_type)
            transform = augmenter.get_training_transforms(image_size=max(image.shape[:2]))
            
            successful_augmentations = 0
            
            for i in range(augment_count):
                try:
                    # ì¦ê°• ì ìš©
                    augmented = transform(
                        image=image,
                        bboxes=bboxes,
                        class_labels=class_labels
                    )
                    
                    aug_image = augmented['image']
                    aug_bboxes = augmented['bboxes']
                    aug_class_labels = augmented['class_labels']
                    
                    if not aug_bboxes:  # ë°•ìŠ¤ê°€ ì†ì‹¤ëœ ê²½ìš° ìŠ¤í‚µ
                        continue
                    
                    # ì¦ê°•ëœ ì´ë¯¸ì§€ ì €ì¥
                    aug_img_name = f"{source_img_path.stem}_aug{i+1}{source_img_path.suffix}"
                    aug_img_path = images_dir / aug_img_name
                    
                    # í…ì„œë¥¼ numpyë¡œ ë³€í™˜
                    if hasattr(aug_image, 'numpy'):
                        aug_image = aug_image.numpy()
                    
                    # ì •ê·œí™” í•´ì œ ë° ì €ì¥
                    if aug_image.max() <= 1.0:
                        aug_image = (aug_image * 255).astype(np.uint8)
                    
                    aug_image_pil = Image.fromarray(aug_image.transpose(1, 2, 0))
                    aug_image_pil.save(aug_img_path)
                    
                    # ì¦ê°•ëœ ë¼ë²¨ ì €ì¥
                    aug_label_path = labels_dir / f"{source_img_path.stem}_aug{i+1}.txt"
                    self._save_yolo_labels(aug_label_path, aug_bboxes, aug_class_labels)
                    
                    successful_augmentations += 1
                    
                except Exception as e:
                    self.logger.debug(f"ì¦ê°• ì‹¤íŒ¨ {source_img_path.name} #{i+1}: {e}")
                    continue
            
            return successful_augmentations
            
        except Exception as e:
            self.logger.error(f"ì´ë¯¸ì§€ ì¦ê°• ì‹¤íŒ¨ {source_img_path.name}: {e}")
            return 0
    
    def _load_yolo_labels(self, label_path: Path) -> Tuple[List, List]:
        """YOLO í˜•ì‹ ë¼ë²¨ ë¡œë“œ"""
        bboxes = []
        class_labels = []
        
        try:
            with open(label_path, 'r') as f:
                lines = f.readlines()
            
            for line in lines:
                parts = line.strip().split()
                if len(parts) >= 5:
                    class_id = int(parts[0])
                    x_center = float(parts[1])
                    y_center = float(parts[2])
                    width = float(parts[3])
                    height = float(parts[4])
                    
                    bboxes.append([x_center, y_center, width, height])
                    class_labels.append(class_id)
        
        except Exception as e:
            self.logger.error(f"ë¼ë²¨ ë¡œë“œ ì‹¤íŒ¨ {label_path}: {e}")
        
        return bboxes, class_labels
    
    def _save_yolo_labels(self, label_path: Path, bboxes: List, class_labels: List):
        """YOLO í˜•ì‹ ë¼ë²¨ ì €ì¥"""
        try:
            with open(label_path, 'w') as f:
                for bbox, class_label in zip(bboxes, class_labels):
                    f.write(f"{class_label} {bbox[0]:.6f} {bbox[1]:.6f} {bbox[2]:.6f} {bbox[3]:.6f}\n")
        except Exception as e:
            self.logger.error(f"ë¼ë²¨ ì €ì¥ ì‹¤íŒ¨ {label_path}: {e}")
    
    def _generate_dataset_files(self, splits: Dict[str, List[ImageInfo]], 
                              output_path: Path, dataset_type: DatasetType, 
                              stats: ProcessingStats):
        """ë°ì´í„°ì…‹ YAML ë° ë©”íƒ€ë°ì´í„° íŒŒì¼ ìƒì„±"""
        
        # dataset.yaml ìƒì„±
        dataset_config = CONFIG.get_dataset_config(dataset_type)
        
        yaml_content = {
            'path': str(output_path.absolute()),
            'train': 'images/train',
            'val': 'images/val',
            'test': 'images/test',
            'nc': len(dataset_config["classes"]),
            'names': dataset_config["classes"],
            
            # ë©”íƒ€ë°ì´í„°
            'description': f'Nong-View Best Performance - {dataset_type.value}',
            'version': CONFIG.version,
            'created': pd.Timestamp.now().isoformat(),
            'processor': 'OptimizedDataProcessor',
            
            # í†µê³„
            'dataset_stats': {
                'original_images': stats.original_images,
                'processed_images': stats.processed_images,
                'augmented_images': stats.augmented_images,
                'total_images': stats.processed_images + stats.augmented_images,
                'total_objects': stats.total_objects,
                'train_images': len(splits.get('train', [])),
                'val_images': len(splits.get('val', [])),
                'test_images': len(splits.get('test', [])),
                'class_distribution': stats.class_distribution,
                'processing_time_seconds': stats.processing_time
            }
        }
        
        yaml_path = output_path / 'dataset.yaml'
        with open(yaml_path, 'w', encoding='utf-8') as f:
            yaml.dump(yaml_content, f, default_flow_style=False, allow_unicode=True)
        
        # ìƒì„¸ í†µê³„ JSON ì €ì¥
        stats_path = output_path / 'processing_stats.json'
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(asdict(stats), f, indent=2, ensure_ascii=False, default=str)
        
        self.logger.info(f"ë°ì´í„°ì…‹ íŒŒì¼ ìƒì„± ì™„ë£Œ: {yaml_path}")
    
    def _save_processing_report(self, all_results: Dict[str, ProcessingStats]):
        """ì „ì²´ ì²˜ë¦¬ ë¦¬í¬íŠ¸ ì €ì¥"""
        report_path = self.output_dir / 'processing_report.json'
        
        # í†µê³„ ë³€í™˜
        report_data = {}
        for dataset_name, stats in all_results.items():
            report_data[dataset_name] = asdict(stats)
        
        # ì „ì²´ ìš”ì•½ ì¶”ê°€
        total_original = sum(stats.original_images for stats in all_results.values())
        total_processed = sum(stats.processed_images for stats in all_results.values())
        total_augmented = sum(stats.augmented_images for stats in all_results.values())
        
        report_data['summary'] = {
            'total_datasets': len(all_results),
            'total_original_images': total_original,
            'total_processed_images': total_processed,
            'total_augmented_images': total_augmented,
            'total_final_images': total_processed + total_augmented,
            'processing_timestamp': pd.Timestamp.now().isoformat(),
            'processor_version': CONFIG.version
        }
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False, default=str)
        
        self.logger.info(f"ì „ì²´ ì²˜ë¦¬ ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")


class BalancedDatasetCreator:
    """í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²° ì „ìš© í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
    
    def create_balanced_dataset(self, image_infos: List[ImageInfo], 
                              dataset_type: DatasetType, 
                              dataset_stats: DatasetStats) -> List[ImageInfo]:
        """í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°ëœ ë°ì´í„°ì…‹ ìƒì„±"""
        
        if dataset_type != DatasetType.GROWTH_TIF:
            # growth_tif_datasetì´ ì•„ë‹ˆë©´ ì›ë³¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
            return image_infos
        
        self.logger.info("í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²° ì‹œì‘ (growth_tif_dataset)")
        
        # í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ë¶„ë¥˜
        class_images = defaultdict(list)
        for info in image_infos:
            for class_name in info.class_distribution.keys():
                class_images[class_name].append(info)
        
        # í˜„ì¬ í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„
        class_counts = {class_name: len(images) for class_name, images in class_images.items()}
        self.logger.info(f"í˜„ì¬ í´ë˜ìŠ¤ ë¶„í¬: {class_counts}")
        
        # íƒ€ê²Ÿ í´ë˜ìŠ¤ ê°œìˆ˜ ê³„ì‚° (ì¤‘ê°„ê°’ ê¸°ì¤€)
        sorted_counts = sorted(class_counts.values())
        target_count = sorted_counts[len(sorted_counts) // 2]  # ì¤‘ì•™ê°’ ì‚¬ìš©
        
        self.logger.info(f"íƒ€ê²Ÿ í´ë˜ìŠ¤ ê°œìˆ˜: {target_count}")
        
        # ê· í˜•ì¡íŒ ë°ì´í„°ì…‹ ìƒì„±
        balanced_infos = []
        
        for class_name, images in class_images.items():
            current_count = len(images)
            
            if current_count <= target_count:
                # ë¶€ì¡±í•œ í´ë˜ìŠ¤: ëª¨ë“  ì´ë¯¸ì§€ í¬í•¨
                balanced_infos.extend(images)
                self.logger.info(f"{class_name}: {current_count}ê°œ ëª¨ë‘ í¬í•¨")
            else:
                # ê³¼ë‹¤í•œ í´ë˜ìŠ¤: ë‹¤ìš´ìƒ˜í”Œë§
                sampled_images = random.sample(images, target_count)
                balanced_infos.extend(sampled_images)
                self.logger.info(f"{class_name}: {current_count}ê°œ â†’ {target_count}ê°œ ë‹¤ìš´ìƒ˜í”Œë§")
        
        # ê²°ê³¼ ë¶„ì„
        final_class_counts = defaultdict(int)
        for info in balanced_infos:
            for class_name in info.class_distribution.keys():
                final_class_counts[class_name] += 1
        
        self.logger.info(f"ê· í˜• ì¡°ì • í›„ í´ë˜ìŠ¤ ë¶„í¬: {dict(final_class_counts)}")
        self.logger.info(f"ì´ ì´ë¯¸ì§€ ê°œìˆ˜: {len(image_infos)} â†’ {len(balanced_infos)}")
        
        return balanced_infos


class AdvancedDataAugmentation:
    """ë†ì—… íŠ¹í™” ê³ ê¸‰ ë°ì´í„° ì¦ê°• í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
    
    def get_agricultural_transforms(self, dataset_type: DatasetType, image_size: int = 640) -> A.Compose:
        """ë†ì—… íŠ¹í™” ë°ì´í„° ì¦ê°• ë³€í™˜"""
        
        # ë°ì´í„°ì…‹ë³„ íŠ¹í™” ì¦ê°•
        if dataset_type == DatasetType.GROWTH_TIF:
            # TIF ë°ì´í„°: ê³„ì ˆ ë³€í™” ì‹œë®¬ë ˆì´ì…˜
            transforms = self._get_seasonal_transforms(image_size)
        elif dataset_type in [DatasetType.GREENHOUSE_MULTI, DatasetType.GREENHOUSE_SINGLE]:
            # ì˜¨ì‹¤ ë°ì´í„°: ì¡°ëª… ë° êµ¬ì¡°ë¬¼ ë³€í™”
            transforms = self._get_greenhouse_transforms(image_size)
        else:
            # ê¸°ë³¸ ë³€í™˜
            transforms = self._get_basic_transforms(image_size)
        
        return A.Compose(transforms, bbox_params=A.BboxParams(
            format='yolo',
            label_fields=['class_labels'],
            min_visibility=0.3
        ))
    
    def _get_seasonal_transforms(self, image_size: int) -> List:
        """ê³„ì ˆ ë³€í™” ì‹œë®¬ë ˆì´ì…˜ ë³€í™˜"""
        return [
            # í¬ê¸° ì¡°ì •
            A.LongestMaxSize(max_size=image_size),
            A.PadIfNeeded(min_height=image_size, min_width=image_size, value=0),
            
            # ê³„ì ˆë³„ ìƒ‰ìƒ ë³€í™”
            A.OneOf([
                # ë´„: ì‹ ì„ í•œ ë…¹ìƒ‰
                A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=1.0),
                # ì—¬ë¦„: ê°•í•œ í–‡ë¹›
                A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1.0),
                # ê°€ì„: ê°ˆìƒ‰/í™©ìƒ‰ í†¤
                A.HueSaturationValue(hue_shift_limit=15, sat_shift_limit=30, val_shift_limit=15, p=1.0),
                # ê²¨ìš¸: ì–´ë‘ìš´ í†¤
                A.RandomBrightnessContrast(brightness_limit=(-0.3, -0.1), contrast_limit=0.1, p=1.0),
            ], p=0.8),
            
            # ê¸°ìƒ ì¡°ê±´ ì‹œë®¬ë ˆì´ì…˜
            A.OneOf([
                A.GaussNoise(var_limit=(10, 50), p=0.5),  # ì•ˆê°œ
                A.RandomRain(blur_value=2, brightness_coefficient=0.9, p=0.3),  # ë¹„
                A.RandomSunFlare(flare_roi=(0, 0, 1, 0.5), angle_lower=0.5, p=0.2),  # í–‡ë¹›
            ], p=0.4),
            
            # ê¸°í•˜í•™ì  ë³€í™˜ (ë³´ìˆ˜ì )
            A.ShiftScaleRotate(
                shift_limit=0.05, scale_limit=0.1, rotate_limit=10,
                border_mode=cv2.BORDER_CONSTANT, p=0.7
            ),
            
            # í”Œë¦½ (ë†ì—… í™˜ê²½ì—ì„œ ìì—°ìŠ¤ëŸ¬ì›€)
            A.HorizontalFlip(p=0.5),
            A.VerticalFlip(p=0.2),
        ]
    
    def _get_greenhouse_transforms(self, image_size: int) -> List:
        """ì˜¨ì‹¤ íŠ¹í™” ë³€í™˜"""
        return [
            # í¬ê¸° ì¡°ì •
            A.LongestMaxSize(max_size=image_size),
            A.PadIfNeeded(min_height=image_size, min_width=image_size, value=0),
            
            # ì˜¨ì‹¤ ì¡°ëª… ë³€í™”
            A.OneOf([
                A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),
                A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.5),
                A.RandomGamma(gamma_limit=(80, 120), p=0.5),
            ], p=0.8),
            
            # ìƒ‰ì˜¨ë„ ë³€í™” (LED ì¡°ëª… ë³€í™”)
            A.HueSaturationValue(hue_shift_limit=15, sat_shift_limit=25, val_shift_limit=20, p=0.7),
            
            # ìœ ë¦¬/í”Œë¼ìŠ¤í‹± íš¨ê³¼
            A.OneOf([
                A.GaussianBlur(blur_limit=3, p=0.3),
                A.Defocus(radius=(1, 3), alias_blur=(0.1, 0.5), p=0.2),
            ], p=0.3),
            
            # ê¸°í•˜í•™ì  ë³€í™˜
            A.ShiftScaleRotate(
                shift_limit=0.1, scale_limit=0.2, rotate_limit=15,
                border_mode=cv2.BORDER_CONSTANT, p=0.8
            ),
            
            # í”Œë¦½
            A.HorizontalFlip(p=0.5),
        ]
    
    def _get_basic_transforms(self, image_size: int) -> List:
        """ê¸°ë³¸ ë³€í™˜"""
        return [
            A.LongestMaxSize(max_size=image_size),
            A.PadIfNeeded(min_height=image_size, min_width=image_size, value=0),
            
            A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=15, val_shift_limit=10, p=0.6),
            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.6),
            
            A.ShiftScaleRotate(
                shift_limit=0.1, scale_limit=0.1, rotate_limit=10,
                border_mode=cv2.BORDER_CONSTANT, p=0.7
            ),
            
            A.HorizontalFlip(p=0.5),
        ]


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="Nong-View ìµœì í™”ëœ ë°ì´í„° ì „ì²˜ë¦¬")
    
    parser.add_argument(
        '--datasets', 
        nargs='+', 
        choices=[dt.value for dt in DatasetType],
        default=[dt.value for dt in DatasetType],
        help='ì²˜ë¦¬í•  ë°ì´í„°ì…‹ ì„ íƒ'
    )
    
    parser.add_argument(
        '--output-dir',
        type=str,
        default=None,
        help='ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: CONFIGì—ì„œ ê°€ì ¸ì˜´)'
    )
    
    parser.add_argument(
        '--disable-quality-filter',
        action='store_true',
        help='í’ˆì§ˆ í•„í„°ë§ ë¹„í™œì„±í™”'
    )
    
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='ìƒì„¸ ë¡œê·¸ ì¶œë ¥'
    )
    
    args = parser.parse_args()
    
    # ë¡œê¹… ë ˆë²¨ ì„¤ì •
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # ë°ì´í„°ì…‹ íƒ€ì… ë³€í™˜
    target_datasets = [DatasetType(name) for name in args.datasets]
    
    # í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
    processor = OptimizedDataProcessor(
        output_dir=args.output_dir,
        enable_quality_filter=not args.disable_quality_filter
    )
    
    # ì²˜ë¦¬ ì‹œì‘
    logger.info("=" * 60)
    logger.info("ğŸ† Nong-View ìµœì í™”ëœ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘")
    logger.info("=" * 60)
    
    try:
        results = processor.process_all_datasets(target_datasets)
        
        logger.info("=" * 60)
        logger.info("âœ… ëª¨ë“  ë°ì´í„°ì…‹ ì²˜ë¦¬ ì™„ë£Œ!")
        
        # ê²°ê³¼ ìš”ì•½
        for dataset_name, stats in results.items():
            logger.info(f"ğŸ“Š {dataset_name}:")
            logger.info(f"  - ì›ë³¸: {stats.original_images}ê°œ")
            logger.info(f"  - ì²˜ë¦¬: {stats.processed_images}ê°œ")
            logger.info(f"  - ì¦ê°•: {stats.augmented_images}ê°œ")
            logger.info(f"  - ì´ ê°ì²´: {stats.total_objects}ê°œ")
            logger.info(f"  - ì²˜ë¦¬ ì‹œê°„: {stats.processing_time:.2f}ì´ˆ")
        
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        raise


if __name__ == "__main__":
    main()