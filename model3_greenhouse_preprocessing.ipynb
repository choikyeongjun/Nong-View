{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ­ Model3 Greenhouse ë°ì´í„°ì…‹ ì „ì²˜ë¦¬\n",
    "\n",
    "**ëª©ì **: ì„ì˜ë¡œ ë¶„í• ëœ train/val/test ë°ì´í„°ë¥¼ ê³¼í•™ì ìœ¼ë¡œ ì¬êµ¬ì„±\n",
    "\n",
    "**ì£¼ìš” ê¸°ëŠ¥**:\n",
    "- âœ… ê³„ì¸µí™” ë¶„í•  (Stratified Split)\n",
    "- âœ… í´ë˜ìŠ¤ ê· í˜• ìœ ì§€\n",
    "- âœ… YOLO í˜•ì‹ ë””ë ‰í† ë¦¬ êµ¬ì¡°\n",
    "- âœ… ì¬í˜„ì„± ë³´ì¥ (random_seed=42)\n",
    "\n",
    "**ì‘ì„±**: Claude Sonnet  \n",
    "**ë‚ ì§œ**: 2025-11-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… tqdm.notebook ì‚¬ìš©\n",
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "from collections import Counter, defaultdict\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# tqdm ì„í¬íŠ¸ (ë…¸íŠ¸ë¶ ë²„ì „ ì‹œë„, ì‹¤íŒ¨ ì‹œ ì¼ë°˜ ë²„ì „ ì‚¬ìš©)\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "    print(\"âœ… tqdm.notebook ì‚¬ìš©\")\n",
    "except ImportError:\n",
    "    from tqdm import tqdm\n",
    "    print(\"âœ… tqdm ì‚¬ìš© (ì§„í–‰ë°”ëŠ” í…ìŠ¤íŠ¸ë¡œ í‘œì‹œë©ë‹ˆë‹¤)\")\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ì†ŒìŠ¤ ë””ë ‰í† ë¦¬: C:\\Users\\LX\\Nong-View\\model3_greenhouse\n",
      "ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: C:\\Users\\LX\\Nong-View\\model3_greenhouse_processed\n",
      "ğŸ“Š ë¶„í•  ë¹„ìœ¨: Train=0.8, Val=0.1, Test=0.1\n",
      "ğŸ² ëœë¤ ì‹œë“œ: 42\n"
     ]
    }
   ],
   "source": [
    "# ì„¤ì •\n",
    "SOURCE_DIR = r\"C:\\Users\\LX\\Nong-View\\model3_greenhouse\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\LX\\Nong-View\\model3_greenhouse_processed\"\n",
    "\n",
    "TRAIN_RATIO = 0.8\n",
    "VAL_RATIO = 0.1\n",
    "TEST_RATIO = 0.1\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# í´ë˜ìŠ¤ ì´ë¦„\n",
    "CLASS_NAMES = {0: 'Greenhouse_single', 1: 'Greenhouse_multi'}\n",
    "\n",
    "# ëœë¤ ì‹œë“œ ì„¤ì •\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "print(f\"ğŸ“ ì†ŒìŠ¤ ë””ë ‰í† ë¦¬: {SOURCE_DIR}\")\n",
    "print(f\"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {OUTPUT_DIR}\")\n",
    "print(f\"ğŸ“Š ë¶„í•  ë¹„ìœ¨: Train={TRAIN_RATIO}, Val={VAL_RATIO}, Test={TEST_RATIO}\")\n",
    "print(f\"ğŸ² ëœë¤ ì‹œë“œ: {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ë¯¸ì§€ ì •ë³´ í´ë˜ìŠ¤\n",
    "@dataclass\n",
    "class ImageInfo:\n",
    "    image_path: Path\n",
    "    label_path: Path\n",
    "    filename: str\n",
    "    classes: List[int]\n",
    "    dominant_class: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ ë°ì´í„° ìˆ˜ì§‘\n",
    "ê¸°ì¡´ train/val/test í´ë”ì˜ ëª¨ë“  ì´ë¯¸ì§€ì™€ ë¼ë²¨ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_label_file(label_path: Path) -> List[int]:\n",
    "    \"\"\"YOLO í˜•ì‹ ë¼ë²¨ íŒŒì¼ íŒŒì‹±\"\"\"\n",
    "    classes = []\n",
    "    try:\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    class_id = int(parts[0])\n",
    "                    classes.append(class_id)\n",
    "    except Exception as e:\n",
    "        print(f\"âš  ë¼ë²¨ íŒŒì‹± ì‹¤íŒ¨: {label_path.name} - {e}\")\n",
    "    return classes\n",
    "\n",
    "\n",
    "def collect_all_images(source_dir: Path) -> List[ImageInfo]:\n",
    "    \"\"\"ëª¨ë“  ì´ë¯¸ì§€ ìˆ˜ì§‘\"\"\"\n",
    "    all_images = []\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        images_dir = source_dir / 'images' / split\n",
    "        labels_dir = source_dir / 'labels' / split\n",
    "        \n",
    "        if not images_dir.exists():\n",
    "            print(f\"âš  ë””ë ‰í† ë¦¬ ì—†ìŒ: {images_dir}\")\n",
    "            continue\n",
    "        \n",
    "        # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°\n",
    "        image_files = list(images_dir.glob('*.png')) + list(images_dir.glob('*.jpg'))\n",
    "        \n",
    "        for img_path in image_files:\n",
    "            label_path = labels_dir / f\"{img_path.stem}.txt\"\n",
    "            \n",
    "            if label_path.exists():\n",
    "                classes = parse_label_file(label_path)\n",
    "                \n",
    "                if classes:\n",
    "                    # ê°€ì¥ ë§ì€ ê°ì²´ë¥¼ ê°€ì§„ í´ë˜ìŠ¤\n",
    "                    class_counts = Counter(classes)\n",
    "                    dominant_class = class_counts.most_common(1)[0][0]\n",
    "                    \n",
    "                    all_images.append(ImageInfo(\n",
    "                        image_path=img_path,\n",
    "                        label_path=label_path,\n",
    "                        filename=img_path.name,\n",
    "                        classes=classes,\n",
    "                        dominant_class=dominant_class\n",
    "                    ))\n",
    "    \n",
    "    return all_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ë°ì´í„° ìˆ˜ì§‘ ì¤‘...\n",
      "âœ… ì´ 1483ê°œ ì´ë¯¸ì§€ ìˆ˜ì§‘ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰\n",
    "print(\"ğŸ” ë°ì´í„° ìˆ˜ì§‘ ì¤‘...\")\n",
    "all_images = collect_all_images(Path(SOURCE_DIR))\n",
    "print(f\"âœ… ì´ {len(all_images)}ê°œ ì´ë¯¸ì§€ ìˆ˜ì§‘ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ ë°ì´í„° ë¶„ì„\n",
    "ìˆ˜ì§‘ëœ ë°ì´í„°ì˜ í†µê³„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š ë°ì´í„° í†µê³„:\n",
      "  - ì´ ì´ë¯¸ì§€: 1483ê°œ\n",
      "  - ì´ ê°ì²´: 2567ê°œ\n",
      "  - í´ë˜ìŠ¤ ë¶„í¬:\n",
      "    â€¢ Greenhouse_single: 1602ê°œ (62.4%)\n",
      "    â€¢ Greenhouse_multi: 965ê°œ (37.6%)\n"
     ]
    }
   ],
   "source": [
    "# í†µê³„ ë¶„ì„\n",
    "total_objects = 0\n",
    "class_distribution = Counter()\n",
    "\n",
    "for img_info in all_images:\n",
    "    total_objects += len(img_info.classes)\n",
    "    for class_id in img_info.classes:\n",
    "        class_distribution[class_id] += 1\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\nğŸ“Š ë°ì´í„° í†µê³„:\")\n",
    "print(f\"  - ì´ ì´ë¯¸ì§€: {len(all_images)}ê°œ\")\n",
    "print(f\"  - ì´ ê°ì²´: {total_objects}ê°œ\")\n",
    "print(f\"  - í´ë˜ìŠ¤ ë¶„í¬:\")\n",
    "\n",
    "for class_id, count in sorted(class_distribution.items()):\n",
    "    class_name = CLASS_NAMES.get(class_id, f'Class_{class_id}')\n",
    "    percentage = (count / total_objects) * 100\n",
    "    print(f\"    â€¢ {class_name}: {count}ê°œ ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ ê³„ì¸µí™” ë¶„í•  (Stratified Split)\n",
    "í´ë˜ìŠ¤ ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©´ì„œ train/val/testë¡œ ë¶„í• í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_split(images: List[ImageInfo], \n",
    "                    train_ratio: float, val_ratio: float, test_ratio: float,\n",
    "                    random_seed: int = 42) -> Tuple[List[ImageInfo], List[ImageInfo], List[ImageInfo]]:\n",
    "    \"\"\"ê³„ì¸µí™” ë¶„í• \"\"\"\n",
    "    # í´ë˜ìŠ¤ë³„ë¡œ ì´ë¯¸ì§€ ê·¸ë£¹í™”\n",
    "    class_groups = defaultdict(list)\n",
    "    for img_info in images:\n",
    "        class_groups[img_info.dominant_class].append(img_info)\n",
    "    \n",
    "    train_images = []\n",
    "    val_images = []\n",
    "    test_images = []\n",
    "    \n",
    "    # ê° í´ë˜ìŠ¤ë³„ë¡œ ë¶„í• \n",
    "    for class_id, class_images in class_groups.items():\n",
    "        # ì…”í”Œ\n",
    "        random.shuffle(class_images)\n",
    "        \n",
    "        n_total = len(class_images)\n",
    "        n_train = int(n_total * train_ratio)\n",
    "        n_val = int(n_total * val_ratio)\n",
    "        \n",
    "        # ë¶„í• \n",
    "        train_images.extend(class_images[:n_train])\n",
    "        val_images.extend(class_images[n_train:n_train + n_val])\n",
    "        test_images.extend(class_images[n_train + n_val:])\n",
    "        \n",
    "        class_name = CLASS_NAMES.get(class_id, f'Class_{class_id}')\n",
    "        print(f\"  â€¢ {class_name}: Train={n_train}, Val={n_val}, Test={n_total - n_train - n_val}\")\n",
    "    \n",
    "    # ìµœì¢… ì…”í”Œ\n",
    "    random.shuffle(train_images)\n",
    "    random.shuffle(val_images)\n",
    "    random.shuffle(test_images)\n",
    "    \n",
    "    return train_images, val_images, test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”€ ê³„ì¸µí™” ë¶„í•  ì¤‘...\n",
      "  â€¢ Greenhouse_multi: Train=607, Val=75, Test=77\n",
      "  â€¢ Greenhouse_single: Train=579, Val=72, Test=73\n",
      "\n",
      "âœ… ë¶„í•  ì™„ë£Œ:\n",
      "  - Train: 1186ê°œ\n",
      "  - Val: 147ê°œ\n",
      "  - Test: 150ê°œ\n"
     ]
    }
   ],
   "source": [
    "# ê³„ì¸µí™” ë¶„í•  ì‹¤í–‰\n",
    "print(\"\\nğŸ”€ ê³„ì¸µí™” ë¶„í•  ì¤‘...\")\n",
    "train_images, val_images, test_images = stratified_split(\n",
    "    all_images, TRAIN_RATIO, VAL_RATIO, TEST_RATIO, RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… ë¶„í•  ì™„ë£Œ:\")\n",
    "print(f\"  - Train: {len(train_images)}ê°œ\")\n",
    "print(f\"  - Val: {len(val_images)}ê°œ\")\n",
    "print(f\"  - Test: {len(test_images)}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "YOLO í˜•ì‹ì˜ ë””ë ‰í† ë¦¬ êµ¬ì¡°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš  ê¸°ì¡´ ë””ë ‰í† ë¦¬ ì‚­ì œ: C:\\Users\\LX\\Nong-View\\model3_greenhouse_processed\n",
      "âœ… ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ: C:\\Users\\LX\\Nong-View\\model3_greenhouse_processed\n"
     ]
    }
   ],
   "source": [
    "# ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "output_path = Path(OUTPUT_DIR)\n",
    "\n",
    "# ê¸°ì¡´ ë””ë ‰í† ë¦¬ ì‚­ì œ (ì£¼ì˜: ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‚­ì œë©ë‹ˆë‹¤!)\n",
    "if output_path.exists():\n",
    "    print(f\"âš  ê¸°ì¡´ ë””ë ‰í† ë¦¬ ì‚­ì œ: {output_path}\")\n",
    "    shutil.rmtree(output_path)\n",
    "\n",
    "# YOLO í˜•ì‹ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±\n",
    "for split in ['train', 'val', 'test']:\n",
    "    (output_path / 'images' / split).mkdir(parents=True, exist_ok=True)\n",
    "    (output_path / 'labels' / split).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"âœ… ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ ë°ì´í„° ë³µì‚¬\n",
    "ë¶„í• ëœ ë°ì´í„°ë¥¼ ìƒˆë¡œìš´ ë””ë ‰í† ë¦¬ êµ¬ì¡°ë¡œ ë³µì‚¬í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_split_data(split_name: str, images: List[ImageInfo], output_path: Path):\n",
    "    \"\"\"ë¶„í• ëœ ë°ì´í„° ë³µì‚¬\"\"\"\n",
    "    images_dir = output_path / 'images' / split_name\n",
    "    labels_dir = output_path / 'labels' / split_name\n",
    "    \n",
    "    class_dist = Counter()\n",
    "    \n",
    "    for img_info in tqdm(images, desc=f\"{split_name} ë³µì‚¬\"):\n",
    "        # ì´ë¯¸ì§€ ë³µì‚¬\n",
    "        shutil.copy2(img_info.image_path, images_dir / img_info.filename)\n",
    "        \n",
    "        # ë¼ë²¨ ë³µì‚¬\n",
    "        shutil.copy2(img_info.label_path, labels_dir / f\"{Path(img_info.filename).stem}.txt\")\n",
    "        \n",
    "        # í´ë˜ìŠ¤ ë¶„í¬ ì—…ë°ì´íŠ¸\n",
    "        for class_id in img_info.classes:\n",
    "            class_dist[class_id] += 1\n",
    "    \n",
    "    return class_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‹ ë°ì´í„° ë³µì‚¬ ì¤‘...\n",
      "\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m split_stats = {}\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m split_name, split_images \u001b[38;5;129;01min\u001b[39;00m [(\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m, train_images), (\u001b[33m'\u001b[39m\u001b[33mval\u001b[39m\u001b[33m'\u001b[39m, val_images), (\u001b[33m'\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m'\u001b[39m, test_images)]:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     class_dist = \u001b[43mcopy_split_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     split_stats[split_name] = {\n\u001b[32m      8\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(split_images),\n\u001b[32m      9\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mobjects\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28msum\u001b[39m(class_dist.values()),\n\u001b[32m     10\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mclass_distribution\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mdict\u001b[39m(class_dist)\n\u001b[32m     11\u001b[39m     }\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mâœ… ë°ì´í„° ë³µì‚¬ ì™„ë£Œ\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mcopy_split_data\u001b[39m\u001b[34m(split_name, images, output_path)\u001b[39m\n\u001b[32m      4\u001b[39m labels_dir = output_path / \u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m / split_name\n\u001b[32m      6\u001b[39m class_dist = Counter()\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m img_info \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msplit_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m ë³µì‚¬\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# ì´ë¯¸ì§€ ë³µì‚¬\u001b[39;00m\n\u001b[32m     10\u001b[39m     shutil.copy2(img_info.image_path, images_dir / img_info.filename)\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# ë¼ë²¨ ë³µì‚¬\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LX\\AppData\\Local\\anaconda3\\envs\\smg\\Lib\\site-packages\\tqdm\\notebook.py:234\u001b[39m, in \u001b[36mtqdm_notebook.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    232\u001b[39m unit_scale = \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.unit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.unit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m1\u001b[39m\n\u001b[32m    233\u001b[39m total = \u001b[38;5;28mself\u001b[39m.total * unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.total \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.total\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m \u001b[38;5;28mself\u001b[39m.container = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;28mself\u001b[39m.container.pbar = proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    236\u001b[39m \u001b[38;5;28mself\u001b[39m.displayed = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LX\\AppData\\Local\\anaconda3\\envs\\smg\\Lib\\site-packages\\tqdm\\notebook.py:108\u001b[39m, in \u001b[36mtqdm_notebook.status_printer\u001b[39m\u001b[34m(_, total, desc, ncols)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[32m    110\u001b[39m     pbar = IProgress(\u001b[38;5;28mmin\u001b[39m=\u001b[32m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m=total)\n",
      "\u001b[31mImportError\u001b[39m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ë³µì‚¬ ì‹¤í–‰\n",
    "print(\"\\nğŸ“‹ ë°ì´í„° ë³µì‚¬ ì¤‘...\\n\")\n",
    "\n",
    "split_stats = {}\n",
    "for split_name, split_images in [('train', train_images), ('val', val_images), ('test', test_images)]:\n",
    "    class_dist = copy_split_data(split_name, split_images, output_path)\n",
    "    split_stats[split_name] = {\n",
    "        'images': len(split_images),\n",
    "        'objects': sum(class_dist.values()),\n",
    "        'class_distribution': dict(class_dist)\n",
    "    }\n",
    "\n",
    "print(\"\\nâœ… ë°ì´í„° ë³µì‚¬ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ YAML ì„¤ì • íŒŒì¼ ìƒì„±\n",
    "YOLO í›ˆë ¨ì„ ìœ„í•œ data.yaml íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YAML íŒŒì¼ ìƒì„±\n",
    "yaml_content = {\n",
    "    'path': str(output_path.absolute()),\n",
    "    'train': 'images/train',\n",
    "    'val': 'images/val',\n",
    "    'test': 'images/test',\n",
    "    'nc': 2,\n",
    "    'names': ['Greenhouse_single', 'Greenhouse_multi'],\n",
    "    \n",
    "    'dataset_info': {\n",
    "        'total': len(all_images),\n",
    "        'train': len(train_images),\n",
    "        'val': len(val_images),\n",
    "        'test': len(test_images),\n",
    "        'augmented': 0\n",
    "    },\n",
    "    \n",
    "    'preprocessing': {\n",
    "        'method': 'stratified_split',\n",
    "        'train_ratio': TRAIN_RATIO,\n",
    "        'val_ratio': VAL_RATIO,\n",
    "        'test_ratio': TEST_RATIO,\n",
    "        'random_seed': RANDOM_SEED\n",
    "    }\n",
    "}\n",
    "\n",
    "yaml_path = output_path / 'data.yaml'\n",
    "with open(yaml_path, 'w', encoding='utf-8') as f:\n",
    "    yaml.dump(yaml_content, f, default_flow_style=False, allow_unicode=True, sort_keys=False)\n",
    "\n",
    "print(f\"âœ… YAML íŒŒì¼ ìƒì„±: {yaml_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ ìµœì¢… ìš”ì•½\n",
    "ì¬êµ¬ì„±ëœ ë°ì´í„°ì…‹ì˜ í†µê³„ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì¢… ìš”ì•½ ì¶œë ¥\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ¨ ë°ì´í„°ì…‹ ì¬êµ¬ì„± ì™„ë£Œ!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nğŸ“Š ìµœì¢… ë°ì´í„° ë¶„í¬:\")\n",
    "\n",
    "for split_name in ['train', 'val', 'test']:\n",
    "    split_info = split_stats[split_name]\n",
    "    print(f\"\\n  ğŸ“ {split_name.upper()}:\")\n",
    "    print(f\"    - ì´ë¯¸ì§€: {split_info['images']}ê°œ\")\n",
    "    print(f\"    - ê°ì²´: {split_info['objects']}ê°œ\")\n",
    "    print(f\"    - í´ë˜ìŠ¤ ë¶„í¬:\")\n",
    "    \n",
    "    for class_id, count in sorted(split_info['class_distribution'].items()):\n",
    "        class_name = CLASS_NAMES.get(class_id, f'Class_{class_id}')\n",
    "        percentage = (count / split_info['objects']) * 100\n",
    "        print(f\"      â€¢ {class_name}: {count}ê°œ ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nğŸ¯ ì¬êµ¬ì„±ëœ ë°ì´í„°ì…‹ ìœ„ì¹˜: {output_path}\")\n",
    "print(f\"ğŸ¯ ì„¤ì • íŒŒì¼: {yaml_path}\")\n",
    "print(\"\\nâœ… ì´ì œ YOLO í›ˆë ¨ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¶”ê°€: ë¶„í•  ë¹„ìœ¨ ê²€ì¦\n",
    "print(\"\\nğŸ“ˆ ë¶„í•  ë¹„ìœ¨ ê²€ì¦:\")\n",
    "total = len(all_images)\n",
    "print(f\"  - Train: {len(train_images)/total*100:.1f}% (ëª©í‘œ: {TRAIN_RATIO*100}%)\")\n",
    "print(f\"  - Val: {len(val_images)/total*100:.1f}% (ëª©í‘œ: {VAL_RATIO*100}%)\")\n",
    "print(f\"  - Test: {len(test_images)/total*100:.1f}% (ëª©í‘œ: {TEST_RATIO*100}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
