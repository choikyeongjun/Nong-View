{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¤– Nong-View ê³ ê¸‰ ì‹œìŠ¤í…œ í™•ì¥ v4.0 (Part 2)\n",
    "\n",
    "**ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬, ë†ì—… íŠ¹í™” ì¦ê°•, í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”**  \n",
    "**ê°œë°œ ë‚ ì§œ**: 2025-10-27  \n",
    "**ë²„ì „**: v4.0 Part 2\n",
    "\n",
    "## ğŸ“‹ ì¶”ê°€ ê³ ê¸‰ ê¸°ëŠ¥\n",
    "- âœ… ìë™ ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ ì‹œìŠ¤í…œ\n",
    "- âœ… ë†ì—… íŠ¹í™” ë°ì´í„° ì¦ê°• ì—”ì§„\n",
    "- âœ… ë² ì´ì§€ì•ˆ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”\n",
    "- âœ… ì•™ìƒë¸” í•™ìŠµ ë° ì§€ì‹ ì¦ë¥˜\n",
    "- âœ… ì™„ì „ í†µí•© API ì‹œìŠ¤í…œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” 6. ìë™ ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ ì‹œìŠ¤í…œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataQualityManager:\n",
    "    \"\"\"ìë™ ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ ì‹œìŠ¤í…œ\"\"\"\n",
    "    \n",
    "    def __init__(self, quality_threshold: float = 0.7, outlier_contamination: float = 0.1):\n",
    "        self.quality_threshold = quality_threshold\n",
    "        self.outlier_contamination = outlier_contamination\n",
    "        \n",
    "    def analyze_dataset_quality(self, db: Session, dataset_id: str) -> dict:\n",
    "        \"\"\"ë°ì´í„°ì…‹ ì „ì²´ í’ˆì§ˆ ë¶„ì„\"\"\"\n",
    "        \n",
    "        logger.info(f\"ë°ì´í„°ì…‹ í’ˆì§ˆ ë¶„ì„ ì‹œì‘: {dataset_id}\")\n",
    "        \n",
    "        # ëª¨ë“  ì´ë¯¸ì§€ ì¡°íšŒ\n",
    "        images = db.query(AnnotatedImage).filter(\n",
    "            AnnotatedImage.dataset_id == dataset_id\n",
    "        ).all()\n",
    "        \n",
    "        if not images:\n",
    "            return {\"error\": \"ë¶„ì„í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤\"}\n",
    "        \n",
    "        # ê¸°ì¡´ í’ˆì§ˆ ì§€í‘œ ì‚­ì œ\n",
    "        db.query(QualityMetric).filter(\n",
    "            QualityMetric.image_id.in_([img.id for img in images])\n",
    "        ).delete(synchronize_session=False)\n",
    "        \n",
    "        # ê° ì´ë¯¸ì§€ë³„ í’ˆì§ˆ ë¶„ì„\n",
    "        quality_results = []\n",
    "        failed_analyses = 0\n",
    "        \n",
    "        for image in images:\n",
    "            try:\n",
    "                quality_metrics = self._analyze_image_quality(image)\n",
    "                \n",
    "                # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥\n",
    "                quality_metric = QualityMetric(\n",
    "                    image_id=image.id,\n",
    "                    **quality_metrics\n",
    "                )\n",
    "                db.add(quality_metric)\n",
    "                \n",
    "                # ì´ë¯¸ì§€ ê°ì²´ì—ë„ í’ˆì§ˆ ì •ë³´ ì—…ë°ì´íŠ¸\n",
    "                image.quality_score = quality_metrics['overall_quality_score']\n",
    "                image.quality_status = quality_metrics['quality_status']\n",
    "                image.blur_score = quality_metrics['blur_score']\n",
    "                image.brightness_score = quality_metrics['brightness_score']\n",
    "                image.contrast_score = quality_metrics['contrast_score']\n",
    "                \n",
    "                quality_results.append(quality_metrics)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"ì´ë¯¸ì§€ {image.filename} í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "                failed_analyses += 1\n",
    "                continue\n",
    "        \n",
    "        # ì´ìƒì¹˜ íƒì§€\n",
    "        outliers = self._detect_outliers(quality_results, images)\n",
    "        \n",
    "        # ë¼ë²¨ í’ˆì§ˆ ë¶„ì„\n",
    "        label_quality = self._analyze_label_quality(db, dataset_id)\n",
    "        \n",
    "        # ì „ì²´ í†µê³„ ê³„ì‚°\n",
    "        quality_stats = self._calculate_quality_statistics(quality_results)\n",
    "        \n",
    "        # í’ˆì§ˆ ë³´ê³ ì„œ ìƒì„±\n",
    "        quality_report = QualityReport(\n",
    "            dataset_id=dataset_id,\n",
    "            total_images_analyzed=len(quality_results),\n",
    "            excellent_count=quality_stats['excellent_count'],\n",
    "            good_count=quality_stats['good_count'],\n",
    "            acceptable_count=quality_stats['acceptable_count'],\n",
    "            poor_count=quality_stats['poor_count'],\n",
    "            rejected_count=quality_stats['rejected_count'],\n",
    "            average_quality_score=quality_stats['average_quality_score'],\n",
    "            quality_std_dev=quality_stats['quality_std_dev'],\n",
    "            outlier_count=len(outliers),\n",
    "            outlier_image_ids=[outlier['image_id'] for outlier in outliers],\n",
    "            label_consistency_score=label_quality['consistency_score'],\n",
    "            suspected_label_errors=label_quality['suspected_errors'],\n",
    "            analysis_details={\n",
    "                'failed_analyses': failed_analyses,\n",
    "                'quality_distribution': quality_stats['distribution'],\n",
    "                'outlier_details': outliers\n",
    "            },\n",
    "            recommendations=self._generate_recommendations(quality_stats, outliers, label_quality)\n",
    "        )\n",
    "        \n",
    "        db.add(quality_report)\n",
    "        \n",
    "        # ë°ì´í„°ì…‹ í’ˆì§ˆ ì •ë³´ ì—…ë°ì´íŠ¸\n",
    "        dataset = db.query(Dataset).filter(Dataset.id == dataset_id).first()\n",
    "        if dataset:\n",
    "            dataset.average_quality_score = quality_stats['average_quality_score']\n",
    "            dataset.quality_distribution = quality_stats['distribution']\n",
    "        \n",
    "        db.commit()\n",
    "        \n",
    "        result = {\n",
    "            'report_id': quality_report.id,\n",
    "            'total_analyzed': len(quality_results),\n",
    "            'failed_analyses': failed_analyses,\n",
    "            'quality_statistics': quality_stats,\n",
    "            'outliers_detected': len(outliers),\n",
    "            'label_quality': label_quality,\n",
    "            'recommendations': quality_report.recommendations\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"ë°ì´í„°ì…‹ í’ˆì§ˆ ë¶„ì„ ì™„ë£Œ: {result}\")\n",
    "        return result\n",
    "    \n",
    "    def _analyze_image_quality(self, image: AnnotatedImage) -> dict:\n",
    "        \"\"\"ê°œë³„ ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„\"\"\"\n",
    "        \n",
    "        # ì´ë¯¸ì§€ ë¡œë“œ\n",
    "        img = cv2.imread(image.file_path)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image.file_path}\")\n",
    "        \n",
    "        # ê¸°ë³¸ í’ˆì§ˆ ì§€í‘œ ê³„ì‚°\n",
    "        blur_score = self._calculate_blur_score(img)\n",
    "        brightness_score = self._calculate_brightness_score(img)\n",
    "        contrast_score = self._calculate_contrast_score(img)\n",
    "        saturation_score = self._calculate_saturation_score(img)\n",
    "        \n",
    "        # ê³ ê¸‰ í’ˆì§ˆ ì§€í‘œ\n",
    "        edge_density = self._calculate_edge_density(img)\n",
    "        noise_level = self._calculate_noise_level(img)\n",
    "        compression_artifacts = self._calculate_compression_artifacts(img)\n",
    "        \n",
    "        # ë†ì—… íŠ¹í™” ì§€í‘œ\n",
    "        vegetation_coverage = self._calculate_vegetation_coverage(img)\n",
    "        soil_visibility = self._calculate_soil_visibility(img)\n",
    "        shadow_ratio = self._calculate_shadow_ratio(img)\n",
    "        \n",
    "        # ì¢…í•© í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°\n",
    "        overall_score = self._calculate_overall_quality_score({\n",
    "            'blur': blur_score,\n",
    "            'brightness': brightness_score,\n",
    "            'contrast': contrast_score,\n",
    "            'saturation': saturation_score,\n",
    "            'edge_density': edge_density,\n",
    "            'noise_level': noise_level,\n",
    "            'vegetation_coverage': vegetation_coverage\n",
    "        })\n",
    "        \n",
    "        # í’ˆì§ˆ ìƒíƒœ ê²°ì •\n",
    "        quality_status = self._determine_quality_status(overall_score)\n",
    "        \n",
    "        return {\n",
    "            'blur_score': float(blur_score),\n",
    "            'brightness_score': float(brightness_score),\n",
    "            'contrast_score': float(contrast_score),\n",
    "            'saturation_score': float(saturation_score),\n",
    "            'edge_density': float(edge_density),\n",
    "            'noise_level': float(noise_level),\n",
    "            'compression_artifacts': float(compression_artifacts),\n",
    "            'vegetation_coverage': float(vegetation_coverage),\n",
    "            'soil_visibility': float(soil_visibility),\n",
    "            'shadow_ratio': float(shadow_ratio),\n",
    "            'overall_quality_score': float(overall_score),\n",
    "            'quality_status': quality_status,\n",
    "            'is_outlier': False,  # ë‚˜ì¤‘ì— ì „ì²´ ë¶„ì„ì—ì„œ ê²°ì •\n",
    "            'outlier_score': 0.0,\n",
    "            'outlier_reason': None\n",
    "        }\n",
    "    \n",
    "    def _calculate_blur_score(self, img: np.ndarray) -> float:\n",
    "        \"\"\"ë¸”ëŸ¬ ì ìˆ˜ ê³„ì‚° (ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚°)\"\"\"\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "        \n",
    "        # ì ìˆ˜ ì •ê·œí™” (0-1, ë†’ì„ìˆ˜ë¡ ì„ ëª…)\n",
    "        normalized_score = min(laplacian_var / 1000.0, 1.0)\n",
    "        return normalized_score\n",
    "    \n",
    "    def _calculate_brightness_score(self, img: np.ndarray) -> float:\n",
    "        \"\"\"ë°ê¸° ì ìˆ˜ ê³„ì‚°\"\"\"\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        mean_brightness = np.mean(gray)\n",
    "        \n",
    "        # ì ì • ë°ê¸° ë²”ìœ„ (80-180)ì—ì„œ ìµœëŒ€ ì ìˆ˜\n",
    "        if 80 <= mean_brightness <= 180:\n",
    "            score = 1.0\n",
    "        elif mean_brightness < 80:\n",
    "            score = mean_brightness / 80.0\n",
    "        else:  # mean_brightness > 180\n",
    "            score = max(0.0, 1.0 - (mean_brightness - 180) / 75.0)\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def _calculate_contrast_score(self, img: np.ndarray) -> float:\n",
    "        \"\"\"ëŒ€ë¹„ ì ìˆ˜ ê³„ì‚°\"\"\"\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        contrast = gray.std()\n",
    "        \n",
    "        # ì •ê·œí™” (0-1, ì ì • ëŒ€ë¹„ 40-80ì—ì„œ ìµœëŒ€)\n",
    "        if 40 <= contrast <= 80:\n",
    "            score = 1.0\n",
    "        elif contrast < 40:\n",
    "            score = contrast / 40.0\n",
    "        else:  # contrast > 80\n",
    "            score = max(0.0, 1.0 - (contrast - 80) / 40.0)\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def _calculate_saturation_score(self, img: np.ndarray) -> float:\n",
    "        \"\"\"ì±„ë„ ì ìˆ˜ ê³„ì‚°\"\"\"\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        saturation = hsv[:, :, 1]\n",
    "        mean_saturation = np.mean(saturation)\n",
    "        \n",
    "        # ë†ì—… ì´ë¯¸ì§€ì— ì í•©í•œ ì±„ë„ ë²”ìœ„\n",
    "        optimal_range = (60, 200)\n",
    "        if optimal_range[0] <= mean_saturation <= optimal_range[1]:\n",
    "            score = 1.0\n",
    "        elif mean_saturation < optimal_range[0]:\n",
    "            score = mean_saturation / optimal_range[0]\n",
    "        else:\n",
    "            score = max(0.0, 1.0 - (mean_saturation - optimal_range[1]) / 55.0)\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def _calculate_edge_density(self, img: np.ndarray) -> float:\n",
    "        \"\"\"ì—£ì§€ ë°€ë„ ê³„ì‚°\"\"\"\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        edges = cv2.Canny(gray, 50, 150)\n",
    "        edge_density = np.sum(edges > 0) / edges.size\n",
    "        \n",
    "        return edge_density\n",
    "    \n",
    "    def _calculate_noise_level(self, img: np.ndarray) -> float:\n",
    "        \"\"\"ë…¸ì´ì¦ˆ ë ˆë²¨ ê³„ì‚°\"\"\"\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì ìš© í›„ ì°¨ì´ ê³„ì‚°\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        noise = cv2.absdiff(gray, blurred)\n",
    "        noise_level = np.mean(noise) / 255.0\n",
    "        \n",
    "        return noise_level\n",
    "    \n",
    "    def _calculate_compression_artifacts(self, img: np.ndarray) -> float:\n",
    "        \"\"\"ì••ì¶• ì•„í‹°íŒ©íŠ¸ íƒì§€\"\"\"\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # DCT ê³„ìˆ˜ì˜ ë¶„í¬ë¥¼ í†µí•œ ì••ì¶• ì•„í‹°íŒ©íŠ¸ ì¶”ì •\n",
    "        # ê°„ë‹¨í•œ ë²„ì „: 8x8 ë¸”ë¡ì˜ ê· ì¼ì„± ê²€ì‚¬\n",
    "        h, w = gray.shape\n",
    "        block_size = 8\n",
    "        artifacts = 0\n",
    "        block_count = 0\n",
    "        \n",
    "        for i in range(0, h - block_size, block_size):\n",
    "            for j in range(0, w - block_size, block_size):\n",
    "                block = gray[i:i+block_size, j:j+block_size]\n",
    "                \n",
    "                # ë¸”ë¡ ê²½ê³„ì—ì„œì˜ ë¶ˆì—°ì†ì„± ê²€ì‚¬\n",
    "                if i > 0 and j > 0:\n",
    "                    top_diff = np.abs(block[0, :].astype(float) - gray[i-1, j:j+block_size].astype(float))\n",
    "                    left_diff = np.abs(block[:, 0].astype(float) - gray[i:i+block_size, j-1].astype(float))\n",
    "                    \n",
    "                    artifacts += np.mean(top_diff) + np.mean(left_diff)\n",
    "                    block_count += 1\n",
    "        \n",
    "        artifact_score = (artifacts / block_count / 255.0) if block_count > 0 else 0.0\n",
    "        return min(artifact_score, 1.0)\n",
    "    \n",
    "    def _calculate_vegetation_coverage(self, img: np.ndarray) -> float:\n",
    "        \"\"\"ì‹ìƒ í”¼ë³µë„ ê³„ì‚° (ê°„ë‹¨í•œ NDVI ê·¼ì‚¬)\"\"\"\n",
    "        \n",
    "        # RGBì—ì„œ ê°„ë‹¨í•œ ì‹ìƒ ì§€ìˆ˜ ê³„ì‚°\n",
    "        b, g, r = cv2.split(img.astype(np.float32))\n",
    "        \n",
    "        # ê°„ë‹¨í•œ ë…¹ìƒ‰ ì§€ìˆ˜\n",
    "        green_index = (g - r) / (g + r + 1e-8)\n",
    "        \n",
    "        # ì‹ìƒ í”½ì…€ ë¹„ìœ¨\n",
    "        vegetation_mask = green_index > 0.1\n",
    "        vegetation_ratio = np.sum(vegetation_mask) / vegetation_mask.size\n",
    "        \n",
    "        return vegetation_ratio\n",
    "    \n",
    "    def _calculate_soil_visibility(self, img: np.ndarray) -> float:\n",
    "        \"\"\"í† ì–‘ ê°€ì‹œì„± ê³„ì‚°\"\"\"\n",
    "        \n",
    "        # HSV ë³€í™˜\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        h, s, v = cv2.split(hsv)\n",
    "        \n",
    "        # í† ì–‘ ìƒ‰ìƒ ë²”ìœ„ (ê°ˆìƒ‰ ê³„ì—´)\n",
    "        soil_mask = ((h >= 5) & (h <= 25)) & (s >= 30) & (s <= 200) & (v >= 50)\n",
    "        soil_ratio = np.sum(soil_mask) / soil_mask.size\n",
    "        \n",
    "        return soil_ratio\n",
    "    \n",
    "    def _calculate_shadow_ratio(self, img: np.ndarray) -> float:\n",
    "        \"\"\"ê·¸ë¦¼ì ë¹„ìœ¨ ê³„ì‚°\"\"\"\n",
    "        \n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # ì–´ë‘ìš´ ì˜ì—­ì„ ê·¸ë¦¼ìë¡œ ê°„ì£¼\n",
    "        shadow_threshold = np.percentile(gray, 20)  # í•˜ìœ„ 20%\n",
    "        shadow_mask = gray < shadow_threshold\n",
    "        shadow_ratio = np.sum(shadow_mask) / shadow_mask.size\n",
    "        \n",
    "        return shadow_ratio\n",
    "    \n",
    "    def _calculate_overall_quality_score(self, metrics: dict) -> float:\n",
    "        \"\"\"ì¢…í•© í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°\"\"\"\n",
    "        \n",
    "        # ê°€ì¤‘ì¹˜ ì„¤ì •\n",
    "        weights = {\n",
    "            'blur': 0.25,          # ì„ ëª…ë„ëŠ” ë§¤ìš° ì¤‘ìš”\n",
    "            'brightness': 0.15,    # ì ì • ë°ê¸°\n",
    "            'contrast': 0.15,      # ì ì • ëŒ€ë¹„\n",
    "            'saturation': 0.10,    # ìƒ‰ìƒ í’ˆì§ˆ\n",
    "            'edge_density': 0.10,  # ë””í…Œì¼ ìˆ˜ì¤€\n",
    "            'noise_level': -0.15,  # ë…¸ì´ì¦ˆëŠ” í’ˆì§ˆ ì €í•˜ (ìŒìˆ˜ ê°€ì¤‘ì¹˜)\n",
    "            'vegetation_coverage': 0.10  # ë†ì—… ì´ë¯¸ì§€ íŠ¹ì„±\n",
    "        }\n",
    "        \n",
    "        # ê°€ì¤‘ í‰ê·  ê³„ì‚°\n",
    "        total_score = 0.0\n",
    "        total_weight = 0.0\n",
    "        \n",
    "        for metric, weight in weights.items():\n",
    "            if metric in metrics:\n",
    "                if weight > 0:\n",
    "                    total_score += metrics[metric] * weight\n",
    "                else:  # ìŒìˆ˜ ê°€ì¤‘ì¹˜ (ë…¸ì´ì¦ˆ ë“±)\n",
    "                    total_score += (1.0 - metrics[metric]) * abs(weight)\n",
    "                total_weight += abs(weight)\n",
    "        \n",
    "        overall_score = total_score / total_weight if total_weight > 0 else 0.0\n",
    "        return np.clip(overall_score, 0.0, 1.0)\n",
    "    \n",
    "    def _determine_quality_status(self, score: float) -> QualityStatus:\n",
    "        \"\"\"í’ˆì§ˆ ì ìˆ˜ì— ë”°ë¥¸ ìƒíƒœ ê²°ì •\"\"\"\n",
    "        \n",
    "        if score >= 0.9:\n",
    "            return QualityStatus.EXCELLENT\n",
    "        elif score >= 0.75:\n",
    "            return QualityStatus.GOOD\n",
    "        elif score >= 0.6:\n",
    "            return QualityStatus.ACCEPTABLE\n",
    "        elif score >= 0.4:\n",
    "            return QualityStatus.POOR\n",
    "        else:\n",
    "            return QualityStatus.REJECTED\n",
    "    \n",
    "    def _detect_outliers(self, quality_results: List[dict], images: List[AnnotatedImage]) -> List[dict]:\n",
    "        \"\"\"ì´ìƒì¹˜ íƒì§€\"\"\"\n",
    "        \n",
    "        if len(quality_results) < 10:\n",
    "            return []  # ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ì´ìƒì¹˜ íƒì§€ ê±´ë„ˆë›°ê¸°\n",
    "        \n",
    "        # ì£¼ìš” ì§€í‘œë“¤ë¡œ íŠ¹ì§• ë²¡í„° êµ¬ì„±\n",
    "        features = []\n",
    "        feature_names = ['blur_score', 'brightness_score', 'contrast_score', \n",
    "                        'edge_density', 'noise_level', 'vegetation_coverage']\n",
    "        \n",
    "        for result in quality_results:\n",
    "            feature_vector = [result.get(name, 0.0) for name in feature_names]\n",
    "            features.append(feature_vector)\n",
    "        \n",
    "        features = np.array(features)\n",
    "        \n",
    "        # Isolation Forestë¡œ ì´ìƒì¹˜ íƒì§€\n",
    "        iso_forest = IsolationForest(\n",
    "            contamination=self.outlier_contamination,\n",
    "            random_state=42\n",
    "        )\n",
    "        outlier_labels = iso_forest.fit_predict(features)\n",
    "        outlier_scores = iso_forest.score_samples(features)\n",
    "        \n",
    "        # LOFë¡œ ì¶”ê°€ ê²€ì¦\n",
    "        lof = LocalOutlierFactor(\n",
    "            contamination=self.outlier_contamination,\n",
    "            novelty=False\n",
    "        )\n",
    "        lof_labels = lof.fit_predict(features)\n",
    "        lof_scores = lof.negative_outlier_factor_\n",
    "        \n",
    "        # ì´ìƒì¹˜ ì •ë³´ ìˆ˜ì§‘\n",
    "        outliers = []\n",
    "        for i, (iso_label, lof_label) in enumerate(zip(outlier_labels, lof_labels)):\n",
    "            if iso_label == -1 or lof_label == -1:  # í•˜ë‚˜ë¼ë„ ì´ìƒì¹˜ë¡œ íŒì •\n",
    "                outlier_info = {\n",
    "                    'image_id': images[i].id,\n",
    "                    'filename': images[i].filename,\n",
    "                    'isolation_score': float(outlier_scores[i]),\n",
    "                    'lof_score': float(lof_scores[i]),\n",
    "                    'quality_score': quality_results[i]['overall_quality_score'],\n",
    "                    'reason': self._determine_outlier_reason(quality_results[i])\n",
    "                }\n",
    "                outliers.append(outlier_info)\n",
    "                \n",
    "                # ì´ë¯¸ì§€ ê°ì²´ì— ì´ìƒì¹˜ ì •ë³´ ì—…ë°ì´íŠ¸\n",
    "                images[i].quality_score = quality_results[i]['overall_quality_score']\n",
    "        \n",
    "        return outliers\n",
    "    \n",
    "    def _determine_outlier_reason(self, quality_metrics: dict) -> str:\n",
    "        \"\"\"ì´ìƒì¹˜ ì›ì¸ ë¶„ì„\"\"\"\n",
    "        \n",
    "        reasons = []\n",
    "        \n",
    "        if quality_metrics['blur_score'] < 0.3:\n",
    "            reasons.append(\"ì‹¬í•œ ë¸”ëŸ¬\")\n",
    "        \n",
    "        if quality_metrics['brightness_score'] < 0.3:\n",
    "            reasons.append(\"ë„ˆë¬´ ì–´ë‘ì›€\")\n",
    "        elif quality_metrics['brightness_score'] < 0.4 and quality_metrics['brightness_score'] > 0.8:\n",
    "            reasons.append(\"ë„ˆë¬´ ë°ìŒ\")\n",
    "        \n",
    "        if quality_metrics['contrast_score'] < 0.3:\n",
    "            reasons.append(\"ë‚®ì€ ëŒ€ë¹„\")\n",
    "        \n",
    "        if quality_metrics['noise_level'] > 0.7:\n",
    "            reasons.append(\"ë†’ì€ ë…¸ì´ì¦ˆ\")\n",
    "        \n",
    "        if quality_metrics['vegetation_coverage'] < 0.1:\n",
    "            reasons.append(\"ì‹ìƒ ë¶€ì¡±\")\n",
    "        \n",
    "        if quality_metrics['compression_artifacts'] > 0.5:\n",
    "            reasons.append(\"ì••ì¶• ì•„í‹°íŒ©íŠ¸\")\n",
    "        \n",
    "        return \", \".join(reasons) if reasons else \"ì¢…í•©ì  ì´ìƒì¹˜\"\n",
    "    \n",
    "    def _analyze_label_quality(self, db: Session, dataset_id: str) -> dict:\n",
    "        \"\"\"ë¼ë²¨ í’ˆì§ˆ ë¶„ì„\"\"\"\n",
    "        \n",
    "        # ë¼ë²¨ì´ ìˆëŠ” ì´ë¯¸ì§€ë“¤ ì¡°íšŒ\n",
    "        labeled_images = db.query(AnnotatedImage).filter(\n",
    "            AnnotatedImage.dataset_id == dataset_id,\n",
    "            AnnotatedImage.annotation_count > 0\n",
    "        ).all()\n",
    "        \n",
    "        if len(labeled_images) < 10:\n",
    "            return {\n",
    "                'consistency_score': 1.0,\n",
    "                'suspected_errors': 0,\n",
    "                'analysis': 'ë¼ë²¨ëœ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ í’ˆì§ˆ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤'\n",
    "            }\n",
    "        \n",
    "        # í´ë˜ìŠ¤ë³„ ì–´ë…¸í…Œì´ì…˜ í†µê³„\n",
    "        class_stats = {}\n",
    "        all_annotations = []\n",
    "        \n",
    "        for image in labeled_images:\n",
    "            annotations = db.query(Annotation).filter(\n",
    "                Annotation.image_id == image.id\n",
    "            ).all()\n",
    "            \n",
    "            for ann in annotations:\n",
    "                class_name = ann.class_name\n",
    "                if class_name not in class_stats:\n",
    "                    class_stats[class_name] = {\n",
    "                        'count': 0,\n",
    "                        'bbox_sizes': [],\n",
    "                        'confidences': []\n",
    "                    }\n",
    "                \n",
    "                class_stats[class_name]['count'] += 1\n",
    "                \n",
    "                if ann.bbox_w and ann.bbox_h:\n",
    "                    bbox_area = ann.bbox_w * ann.bbox_h\n",
    "                    class_stats[class_name]['bbox_sizes'].append(bbox_area)\n",
    "                \n",
    "                if ann.confidence:\n",
    "                    class_stats[class_name]['confidences'].append(ann.confidence)\n",
    "                \n",
    "                all_annotations.append(ann)\n",
    "        \n",
    "        # ë¼ë²¨ ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚°\n",
    "        consistency_score = self._calculate_label_consistency(class_stats)\n",
    "        \n",
    "        # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë¼ë²¨ íƒì§€\n",
    "        suspected_errors = self._detect_label_errors(class_stats, all_annotations)\n",
    "        \n",
    "        return {\n",
    "            'consistency_score': consistency_score,\n",
    "            'suspected_errors': len(suspected_errors),\n",
    "            'class_distribution': {k: v['count'] for k, v in class_stats.items()},\n",
    "            'error_details': suspected_errors\n",
    "        }\n",
    "    \n",
    "    def _calculate_label_consistency(self, class_stats: dict) -> float:\n",
    "        \"\"\"ë¼ë²¨ ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚°\"\"\"\n",
    "        \n",
    "        consistency_scores = []\n",
    "        \n",
    "        for class_name, stats in class_stats.items():\n",
    "            if len(stats['bbox_sizes']) > 1:\n",
    "                # ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸°ì˜ ì¼ê´€ì„±\n",
    "                bbox_cv = np.std(stats['bbox_sizes']) / (np.mean(stats['bbox_sizes']) + 1e-8)\n",
    "                bbox_consistency = max(0.0, 1.0 - bbox_cv)  # ë³€ë™ê³„ìˆ˜ê°€ ë‚®ì„ìˆ˜ë¡ ì¼ê´€ì„± ë†’ìŒ\n",
    "                consistency_scores.append(bbox_consistency)\n",
    "            \n",
    "            if len(stats['confidences']) > 1:\n",
    "                # ì‹ ë¢°ë„ì˜ ì¼ê´€ì„±\n",
    "                conf_consistency = 1.0 - np.std(stats['confidences'])\n",
    "                consistency_scores.append(max(0.0, conf_consistency))\n",
    "        \n",
    "        return float(np.mean(consistency_scores)) if consistency_scores else 1.0\n",
    "    \n",
    "    def _detect_label_errors(self, class_stats: dict, annotations: List[Annotation]) -> List[dict]:\n",
    "        \"\"\"ë¼ë²¨ ì˜¤ë¥˜ íƒì§€\"\"\"\n",
    "        \n",
    "        suspected_errors = []\n",
    "        \n",
    "        for ann in annotations:\n",
    "            class_name = ann.class_name\n",
    "            \n",
    "            # ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸° ì´ìƒì¹˜ ê²€ì‚¬\n",
    "            if ann.bbox_w and ann.bbox_h:\n",
    "                bbox_area = ann.bbox_w * ann.bbox_h\n",
    "                class_bbox_sizes = class_stats[class_name]['bbox_sizes']\n",
    "                \n",
    "                if len(class_bbox_sizes) > 5:\n",
    "                    q1, q3 = np.percentile(class_bbox_sizes, [25, 75])\n",
    "                    iqr = q3 - q1\n",
    "                    lower_bound = q1 - 3 * iqr\n",
    "                    upper_bound = q3 + 3 * iqr\n",
    "                    \n",
    "                    if bbox_area < lower_bound or bbox_area > upper_bound:\n",
    "                        suspected_errors.append({\n",
    "                            'annotation_id': ann.id,\n",
    "                            'image_id': ann.image_id,\n",
    "                            'class_name': class_name,\n",
    "                            'error_type': 'unusual_bbox_size',\n",
    "                            'bbox_area': bbox_area,\n",
    "                            'expected_range': [lower_bound, upper_bound]\n",
    "                        })\n",
    "            \n",
    "            # ì‹ ë¢°ë„ ì´ìƒì¹˜ ê²€ì‚¬\n",
    "            if ann.confidence and ann.confidence < 0.5:\n",
    "                suspected_errors.append({\n",
    "                    'annotation_id': ann.id,\n",
    "                    'image_id': ann.image_id,\n",
    "                    'class_name': class_name,\n",
    "                    'error_type': 'low_confidence',\n",
    "                    'confidence': ann.confidence\n",
    "                })\n",
    "        \n",
    "        return suspected_errors\n",
    "    \n",
    "    def _calculate_quality_statistics(self, quality_results: List[dict]) -> dict:\n",
    "        \"\"\"í’ˆì§ˆ í†µê³„ ê³„ì‚°\"\"\"\n",
    "        \n",
    "        if not quality_results:\n",
    "            return {\n",
    "                'excellent_count': 0, 'good_count': 0, 'acceptable_count': 0,\n",
    "                'poor_count': 0, 'rejected_count': 0,\n",
    "                'average_quality_score': 0.0, 'quality_std_dev': 0.0,\n",
    "                'distribution': {}\n",
    "            }\n",
    "        \n",
    "        # í’ˆì§ˆ ìƒíƒœë³„ ê°œìˆ˜\n",
    "        status_counts = {\n",
    "            QualityStatus.EXCELLENT: 0,\n",
    "            QualityStatus.GOOD: 0,\n",
    "            QualityStatus.ACCEPTABLE: 0,\n",
    "            QualityStatus.POOR: 0,\n",
    "            QualityStatus.REJECTED: 0\n",
    "        }\n",
    "        \n",
    "        quality_scores = []\n",
    "        \n",
    "        for result in quality_results:\n",
    "            status = result['quality_status']\n",
    "            status_counts[status] += 1\n",
    "            quality_scores.append(result['overall_quality_score'])\n",
    "        \n",
    "        return {\n",
    "            'excellent_count': status_counts[QualityStatus.EXCELLENT],\n",
    "            'good_count': status_counts[QualityStatus.GOOD],\n",
    "            'acceptable_count': status_counts[QualityStatus.ACCEPTABLE],\n",
    "            'poor_count': status_counts[QualityStatus.POOR],\n",
    "            'rejected_count': status_counts[QualityStatus.REJECTED],\n",
    "            'average_quality_score': float(np.mean(quality_scores)),\n",
    "            'quality_std_dev': float(np.std(quality_scores)),\n",
    "            'distribution': {status.value: count for status, count in status_counts.items()}\n",
    "        }\n",
    "    \n",
    "    def _generate_recommendations(self, quality_stats: dict, outliers: List[dict], \n",
    "                                 label_quality: dict) -> List[str]:\n",
    "        \"\"\"í’ˆì§ˆ ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±\"\"\"\n",
    "        \n",
    "        recommendations = []\n",
    "        \n",
    "        # ì „ë°˜ì  í’ˆì§ˆ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­\n",
    "        avg_quality = quality_stats['average_quality_score']\n",
    "        if avg_quality < 0.6:\n",
    "            recommendations.append(\"ë°ì´í„°ì…‹ì˜ ì „ë°˜ì ì¸ í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ ìˆ˜ì§‘ ê³¼ì •ì„ ê°œì„ í•˜ì„¸ìš”.\")\n",
    "        \n",
    "        # í’ˆì§ˆ ë¶„í¬ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­\n",
    "        total_images = sum(quality_stats['distribution'].values())\n",
    "        poor_ratio = (quality_stats['poor_count'] + quality_stats['rejected_count']) / total_images\n",
    "        \n",
    "        if poor_ratio > 0.2:\n",
    "            recommendations.append(f\"ì „ì²´ì˜ {poor_ratio:.1%}ê°€ í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤. í•´ë‹¹ ì´ë¯¸ì§€ë“¤ì„ ì œê±°í•˜ê±°ë‚˜ ì¬ìˆ˜ì§‘í•˜ì„¸ìš”.\")\n",
    "        \n",
    "        # ì´ìƒì¹˜ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­\n",
    "        if len(outliers) > 0:\n",
    "            outlier_ratio = len(outliers) / total_images\n",
    "            recommendations.append(f\"{len(outliers)}ê°œì˜ ì´ìƒì¹˜ê°€ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤ ({outlier_ratio:.1%}). ìˆ˜ë™ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "            \n",
    "            # ì£¼ìš” ì´ìƒì¹˜ ì›ì¸ ë¶„ì„\n",
    "            reasons = [outlier['reason'] for outlier in outliers]\n",
    "            common_reasons = pd.Series(reasons).value_counts().head(3)\n",
    "            \n",
    "            for reason, count in common_reasons.items():\n",
    "                recommendations.append(f\"ì£¼ìš” ì´ìƒì¹˜ ì›ì¸: {reason} ({count}ê°œ)\")\n",
    "        \n",
    "        # ë¼ë²¨ í’ˆì§ˆ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­\n",
    "        if label_quality['consistency_score'] < 0.7:\n",
    "            recommendations.append(\"ë¼ë²¨ë§ ì¼ê´€ì„±ì´ ë‚®ìŠµë‹ˆë‹¤. ë¼ë²¨ë§ ê°€ì´ë“œë¼ì¸ì„ ì ê²€í•˜ì„¸ìš”.\")\n",
    "        \n",
    "        if label_quality['suspected_errors'] > 0:\n",
    "            recommendations.append(f\"{label_quality['suspected_errors']}ê°œì˜ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë¼ë²¨ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ë™ ê²€ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "        \n",
    "        # í´ë˜ìŠ¤ ë¶ˆê· í˜• ê²€ì‚¬\n",
    "        if 'class_distribution' in label_quality:\n",
    "            class_counts = list(label_quality['class_distribution'].values())\n",
    "            if class_counts:\n",
    "                imbalance_ratio = max(class_counts) / min(class_counts)\n",
    "                if imbalance_ratio > 10:\n",
    "                    recommendations.append(f\"í´ë˜ìŠ¤ ë¶ˆê· í˜•ì´ ì‹¬í•©ë‹ˆë‹¤ (ë¹„ìœ¨: {imbalance_ratio:.1f}:1). ë°ì´í„° ì¦ê°•ì´ë‚˜ ì¶”ê°€ ìˆ˜ì§‘ì„ ê³ ë ¤í•˜ì„¸ìš”.\")\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "\n",
    "# ì „ì—­ ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ì ì¸ìŠ¤í„´ìŠ¤\n",
    "quality_manager = DataQualityManager(\n",
    "    quality_threshold=settings.QUALITY_SCORE_THRESHOLD,\n",
    "    outlier_contamination=settings.OUTLIER_CONTAMINATION\n",
    ")\n",
    "\n",
    "print(\"âœ… ìë™ ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„ ì™„ë£Œ\")\n",
    "print(f\"ğŸ” í’ˆì§ˆ ì„ê³„ê°’: {settings.QUALITY_SCORE_THRESHOLD}\")\n",
    "print(f\"ğŸ“Š ì´ìƒì¹˜ ë¹„ìœ¨: {settings.OUTLIER_CONTAMINATION}\")\n",
    "print(f\"ğŸ”§ ë¶„ì„ í•­ëª©: ë¸”ëŸ¬, ë°ê¸°, ëŒ€ë¹„, ë…¸ì´ì¦ˆ, ì‹ìƒí”¼ë³µ, ë¼ë²¨ ì¼ê´€ì„±\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸŒ¾ 7. ë†ì—… íŠ¹í™” ë°ì´í„° ì¦ê°• ì‹œìŠ¤í…œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgriculturalDataAugmentation:\n",
    "    \"\"\"ë†ì—… íŠ¹í™” ë°ì´í„° ì¦ê°• ì‹œìŠ¤í…œ\"\"\"\n",
    "    \n",
    "    def __init__(self, augmentation_factor: int = 3):\n",
    "        self.augmentation_factor = augmentation_factor\n",
    "        self.seasonal_characteristics = settings.SEASONAL_CHARACTERISTICS\n",
    "        \n",
    "        # ê¸°ë³¸ ì¦ê°• íŒŒì´í”„ë¼ì¸\n",
    "        self.basic_transform = A.Compose([\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.Flip(p=0.5),\n",
    "            A.Transpose(p=0.3),\n",
    "            A.OneOf([\n",
    "                A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "                A.GaussianBlur(blur_limit=(3, 7), p=0.3),\n",
    "                A.MotionBlur(blur_limit=7, p=0.3),\n",
    "            ], p=0.5),\n",
    "            A.OneOf([\n",
    "                A.OpticalDistortion(p=0.3),\n",
    "                A.GridDistortion(p=0.3),\n",
    "                A.ElasticTransform(p=0.3),\n",
    "            ], p=0.3),\n",
    "        ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "        \n",
    "        # ìƒ‰ìƒ ì¦ê°• íŒŒì´í”„ë¼ì¸\n",
    "        self.color_transform = A.Compose([\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.8),\n",
    "            A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.8),\n",
    "            A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n",
    "            A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),\n",
    "        ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "    \n",
    "    def augment_dataset(self, db: Session, dataset_id: str, \n",
    "                       augmentation_types: List[str] = None) -> dict:\n",
    "        \"\"\"ë°ì´í„°ì…‹ ì¦ê°• ìˆ˜í–‰\"\"\"\n",
    "        \n",
    "        if augmentation_types is None:\n",
    "            augmentation_types = ['geometric', 'color', 'weather', 'seasonal']\n",
    "        \n",
    "        # ì›ë³¸ ì´ë¯¸ì§€ë“¤ ì¡°íšŒ (ì¦ê°•ëœ ì´ë¯¸ì§€ ì œì™¸)\n",
    "        original_images = db.query(AnnotatedImage).filter(\n",
    "            AnnotatedImage.dataset_id == dataset_id,\n",
    "            AnnotatedImage.is_augmented == False,\n",
    "            AnnotatedImage.annotation_count > 0  # ë¼ë²¨ì´ ìˆëŠ” ì´ë¯¸ì§€ë§Œ\n",
    "        ).all()\n",
    "        \n",
    "        if not original_images:\n",
    "            return {\"error\": \"ì¦ê°•í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤\"}\n",
    "        \n",
    "        logger.info(f\"ë°ì´í„° ì¦ê°• ì‹œì‘: {len(original_images)}ê°œ ì›ë³¸ ì´ë¯¸ì§€\")\n",
    "        \n",
    "        augmented_count = 0\n",
    "        failed_count = 0\n",
    "        augmentation_results = {}\n",
    "        \n",
    "        # ì¦ê°• ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "        dataset = db.query(Dataset).filter(Dataset.id == dataset_id).first()\n",
    "        if not dataset:\n",
    "            return {\"error\": \"ë°ì´í„°ì…‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\"}\n",
    "        \n",
    "        augment_dir = Path(settings.AUGMENTATION_PATH) / dataset.name\n",
    "        augment_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for image in original_images:\n",
    "            try:\n",
    "                # ì´ë¯¸ì§€ë³„ ì¦ê°• ìˆ˜í–‰\n",
    "                image_results = self._augment_single_image(\n",
    "                    db, image, augment_dir, augmentation_types\n",
    "                )\n",
    "                \n",
    "                augmented_count += image_results['augmented_count']\n",
    "                failed_count += image_results['failed_count']\n",
    "                \n",
    "                # ì¦ê°• íƒ€ì…ë³„ í†µê³„\n",
    "                for aug_type, count in image_results['type_counts'].items():\n",
    "                    augmentation_results[aug_type] = augmentation_results.get(aug_type, 0) + count\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"ì´ë¯¸ì§€ {image.filename} ì¦ê°• ì‹¤íŒ¨: {e}\")\n",
    "                failed_count += 1\n",
    "                continue\n",
    "        \n",
    "        # ë°ì´í„°ì…‹ ì¦ê°• ì •ë³´ ì—…ë°ì´íŠ¸\n",
    "        dataset.augmentation_enabled = True\n",
    "        dataset.augmentation_factor = self.augmentation_factor\n",
    "        dataset.augmentation_types = augmentation_types\n",
    "        \n",
    "        db.commit()\n",
    "        \n",
    "        result = {\n",
    "            'original_images': len(original_images),\n",
    "            'total_augmented': augmented_count,\n",
    "            'failed_augmentations': failed_count,\n",
    "            'augmentation_factor_achieved': augmented_count / len(original_images) if original_images else 0,\n",
    "            'augmentation_types_used': augmentation_types,\n",
    "            'type_statistics': augmentation_results,\n",
    "            'output_directory': str(augment_dir)\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"ë°ì´í„° ì¦ê°• ì™„ë£Œ: {result}\")\n",
    "        return result\n",
    "    \n",
    "    def _augment_single_image(self, db: Session, image: AnnotatedImage, \n",
    "                             output_dir: Path, augmentation_types: List[str]) -> dict:\n",
    "        \"\"\"ë‹¨ì¼ ì´ë¯¸ì§€ ì¦ê°•\"\"\"\n",
    "        \n",
    "        # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ\n",
    "        img = cv2.imread(image.file_path)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image.file_path}\")\n",
    "        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # ì–´ë…¸í…Œì´ì…˜ ë¡œë“œ\n",
    "        annotations = db.query(Annotation).filter(\n",
    "            Annotation.image_id == image.id\n",
    "        ).all()\n",
    "        \n",
    "        # YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "        bboxes = []\n",
    "        class_labels = []\n",
    "        \n",
    "        for ann in annotations:\n",
    "            if ann.bbox_x is not None and ann.bbox_y is not None:\n",
    "                # YOLO í˜•ì‹: [center_x, center_y, width, height]\n",
    "                bboxes.append([ann.bbox_x, ann.bbox_y, ann.bbox_w, ann.bbox_h])\n",
    "                class_labels.append(ann.class_id)\n",
    "        \n",
    "        augmented_count = 0\n",
    "        failed_count = 0\n",
    "        type_counts = {}\n",
    "        \n",
    "        # ì¦ê°• íƒ€ì…ë³„ë¡œ ìˆ˜í–‰\n",
    "        for aug_type in augmentation_types:\n",
    "            try:\n",
    "                # íƒ€ì…ë³„ ì¦ê°• ìˆ˜í–‰\n",
    "                augmented_results = self._apply_augmentation_type(\n",
    "                    img, bboxes, class_labels, aug_type, image\n",
    "                )\n",
    "                \n",
    "                # ì¦ê°•ëœ ì´ë¯¸ì§€ë“¤ ì €ì¥\n",
    "                for i, (aug_img, aug_bboxes, aug_params) in enumerate(augmented_results):\n",
    "                    try:\n",
    "                        # íŒŒì¼ëª… ìƒì„±\n",
    "                        base_name = Path(image.filename).stem\n",
    "                        ext = Path(image.filename).suffix\n",
    "                        aug_filename = f\"{base_name}_aug_{aug_type}_{i:02d}{ext}\"\n",
    "                        aug_filepath = output_dir / aug_filename\n",
    "                        \n",
    "                        # ì´ë¯¸ì§€ ì €ì¥\n",
    "                        aug_img_bgr = cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR)\n",
    "                        cv2.imwrite(str(aug_filepath), aug_img_bgr)\n",
    "                        \n",
    "                        # ë°ì´í„°ë² ì´ìŠ¤ì— ì¦ê°•ëœ ì´ë¯¸ì§€ ì •ë³´ ì €ì¥\n",
    "                        aug_image = self._save_augmented_image(\n",
    "                            db, image, aug_filepath, aug_type, aug_params\n",
    "                        )\n",
    "                        \n",
    "                        # ì¦ê°•ëœ ì–´ë…¸í…Œì´ì…˜ ì €ì¥\n",
    "                        self._save_augmented_annotations(\n",
    "                            db, aug_image, aug_bboxes, class_labels, annotations\n",
    "                        )\n",
    "                        \n",
    "                        augmented_count += 1\n",
    "                        type_counts[aug_type] = type_counts.get(aug_type, 0) + 1\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"ì¦ê°•ëœ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "                        failed_count += 1\n",
    "                        continue\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"ì¦ê°• íƒ€ì… {aug_type} ì‹¤íŒ¨: {e}\")\n",
    "                failed_count += 1\n",
    "                continue\n",
    "        \n",
    "        return {\n",
    "            'augmented_count': augmented_count,\n",
    "            'failed_count': failed_count,\n",
    "            'type_counts': type_counts\n",
    "        }\n",
    "    \n",
    "    def _apply_augmentation_type(self, img: np.ndarray, bboxes: List[List[float]], \n",
    "                                class_labels: List[int], aug_type: str, \n",
    "                                original_image: AnnotatedImage) -> List[Tuple[np.ndarray, List[List[float]], dict]]:\n",
    "        \"\"\"ì¦ê°• íƒ€ì…ë³„ ì ìš©\"\"\"\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        if aug_type == 'geometric':\n",
    "            results.extend(self._apply_geometric_augmentation(img, bboxes, class_labels))\n",
    "        \n",
    "        elif aug_type == 'color':\n",
    "            results.extend(self._apply_color_augmentation(img, bboxes, class_labels))\n",
    "        \n",
    "        elif aug_type == 'weather':\n",
    "            results.extend(self._apply_weather_augmentation(img, bboxes, class_labels))\n",
    "        \n",
    "        elif aug_type == 'seasonal':\n",
    "            results.extend(self._apply_seasonal_augmentation(img, bboxes, class_labels, original_image))\n",
    "        \n",
    "        elif aug_type == 'noise':\n",
    "            results.extend(self._apply_noise_augmentation(img, bboxes, class_labels))\n",
    "        \n",
    "        else:\n",
    "            logger.warning(f\"ì§€ì›ë˜ì§€ ì•ŠëŠ” ì¦ê°• íƒ€ì…: {aug_type}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _apply_geometric_augmentation(self, img: np.ndarray, bboxes: List[List[float]], \n",
    "                                     class_labels: List[int]) -> List[Tuple[np.ndarray, List[List[float]], dict]]:\n",
    "        \"\"\"ê¸°í•˜í•™ì  ì¦ê°• ì ìš©\"\"\"\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for _ in range(2):  # 2ê°œì˜ ê¸°í•˜í•™ì  ë³€í˜• ìƒì„±\n",
    "            try:\n",
    "                transformed = self.basic_transform(\n",
    "                    image=img, \n",
    "                    bboxes=bboxes, \n",
    "                    class_labels=class_labels\n",
    "                )\n",
    "                \n",
    "                results.append((\n",
    "                    transformed['image'],\n",
    "                    transformed['bboxes'],\n",
    "                    {'type': 'geometric', 'method': 'albumentations_basic'}\n",
    "                ))\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"ê¸°í•˜í•™ì  ì¦ê°• ì‹¤íŒ¨: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _apply_color_augmentation(self, img: np.ndarray, bboxes: List[List[float]], \n",
    "                                 class_labels: List[int]) -> List[Tuple[np.ndarray, List[List[float]], dict]]:\n",
    "        \"\"\"ìƒ‰ìƒ ì¦ê°• ì ìš©\"\"\"\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for _ in range(2):  # 2ê°œì˜ ìƒ‰ìƒ ë³€í˜• ìƒì„±\n",
    "            try:\n",
    "                transformed = self.color_transform(\n",
    "                    image=img,\n",
    "                    bboxes=bboxes,\n",
    "                    class_labels=class_labels\n",
    "                )\n",
    "                \n",
    "                results.append((\n",
    "                    transformed['image'],\n",
    "                    transformed['bboxes'],\n",
    "                    {'type': 'color', 'method': 'albumentations_color'}\n",
    "                ))\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"ìƒ‰ìƒ ì¦ê°• ì‹¤íŒ¨: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _apply_weather_augmentation(self, img: np.ndarray, bboxes: List[List[float]], \n",
    "                                   class_labels: List[int]) -> List[Tuple[np.ndarray, List[List[float]], dict]]:\n",
    "        \"\"\"ë‚ ì”¨ ì¡°ê±´ ì¦ê°• ì ìš©\"\"\"\n",
    "        \n",
    "        results = []\n",
    "        weather_conditions = ['sunny', 'cloudy', 'rainy', 'foggy']\n",
    "        \n",
    "        for condition in np.random.choice(weather_conditions, 2, replace=False):\n",
    "            try:\n",
    "                augmented_img = self._simulate_weather_condition(img, condition)\n",
    "                \n",
    "                results.append((\n",
    "                    augmented_img,\n",
    "                    bboxes,  # ë‚ ì”¨ ë³€í™”ëŠ” ë°”ìš´ë”© ë°•ìŠ¤ì— ì˜í–¥ ì—†ìŒ\n",
    "                    {'type': 'weather', 'condition': condition}\n",
    "                ))\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"ë‚ ì”¨ ì¦ê°• ì‹¤íŒ¨ ({condition}): {e}\")\n",
    "                continue\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _apply_seasonal_augmentation(self, img: np.ndarray, bboxes: List[List[float]], \n",
    "                                    class_labels: List[int], \n",
    "                                    original_image: AnnotatedImage) -> List[Tuple[np.ndarray, List[List[float]], dict]]:\n",
    "        \"\"\"ê³„ì ˆë³„ ì¦ê°• ì ìš©\"\"\"\n",
    "        \n",
    "        results = []\n",
    "        current_season = original_image.season or 'summer'\n",
    "        other_seasons = [s for s in ['spring', 'summer', 'autumn', 'winter'] if s != current_season]\n",
    "        \n",
    "        for season in np.random.choice(other_seasons, min(2, len(other_seasons)), replace=False):\n",
    "            try:\n",
    "                augmented_img = self._simulate_seasonal_condition(img, season)\n",
    "                \n",
    "                results.append((\n",
    "                    augmented_img,\n",
    "                    bboxes,\n",
    "                    {'type': 'seasonal', 'season': season, 'original_season': current_season}\n",
    "                ))\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"ê³„ì ˆ ì¦ê°• ì‹¤íŒ¨ ({season}): {e}\")\n",
    "                continue\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _apply_noise_augmentation(self, img: np.ndarray, bboxes: List[List[float]], \n",
    "                                 class_labels: List[int]) -> List[Tuple[np.ndarray, List[List[float]], dict]]:\n",
    "        \"\"\"ë…¸ì´ì¦ˆ ì¦ê°• ì ìš©\"\"\"\n",
    "        \n",
    "        results = []\n",
    "        noise_types = ['gaussian', 'speckle', 'salt_pepper']\n",
    "        \n",
    "        for noise_type in np.random.choice(noise_types, 2, replace=False):\n",
    "            try:\n",
    "                augmented_img = self._add_noise(img, noise_type)\n",
    "                \n",
    "                results.append((\n",
    "                    augmented_img,\n",
    "                    bboxes,\n",
    "                    {'type': 'noise', 'noise_type': noise_type}\n",
    "                ))\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"ë…¸ì´ì¦ˆ ì¦ê°• ì‹¤íŒ¨ ({noise_type}): {e}\")\n",
    "                continue\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _simulate_weather_condition(self, img: np.ndarray, condition: str) -> np.ndarray:\n",
    "        \"\"\"ë‚ ì”¨ ì¡°ê±´ ì‹œë®¬ë ˆì´ì…˜\"\"\"\n",
    "        \n",
    "        img_float = img.astype(np.float32) / 255.0\n",
    "        \n",
    "        if condition == 'sunny':\n",
    "            # ë°ê¸° ì¦ê°€, ëŒ€ë¹„ ì¦ê°€\n",
    "            img_float = np.clip(img_float * 1.2 + 0.1, 0, 1)\n",
    "            \n",
    "        elif condition == 'cloudy':\n",
    "            # ë°ê¸° ê°ì†Œ, ëŒ€ë¹„ ê°ì†Œ\n",
    "            img_float = np.clip(img_float * 0.8 - 0.05, 0, 1)\n",
    "            \n",
    "        elif condition == 'rainy':\n",
    "            # ì–´ë‘¡ê²Œ, ë¬¼ë°©ìš¸ íš¨ê³¼\n",
    "            img_float = np.clip(img_float * 0.7, 0, 1)\n",
    "            \n",
    "            # ê°„ë‹¨í•œ ë¹—ë°©ìš¸ íš¨ê³¼\n",
    "            h, w = img_float.shape[:2]\n",
    "            for _ in range(np.random.randint(50, 150)):\n",
    "                x = np.random.randint(0, w)\n",
    "                y = np.random.randint(0, h)\n",
    "                radius = np.random.randint(1, 3)\n",
    "                \n",
    "                # ì‘ì€ ì›í˜• ë°ì€ ì  ì¶”ê°€\n",
    "                cv2.circle(img_float, (x, y), radius, (1.0, 1.0, 1.0), -1)\n",
    "            \n",
    "        elif condition == 'foggy':\n",
    "            # ì•ˆê°œ íš¨ê³¼ (ë°ì€ ë…¸ì´ì¦ˆ ì¶”ê°€)\n",
    "            fog = np.random.normal(0.7, 0.1, img_float.shape)\n",
    "            fog = np.clip(fog, 0, 1)\n",
    "            \n",
    "            alpha = 0.3  # ì•ˆê°œ ê°•ë„\n",
    "            img_float = img_float * (1 - alpha) + fog * alpha\n",
    "        \n",
    "        return np.clip(img_float * 255, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    def _simulate_seasonal_condition(self, img: np.ndarray, season: str) -> np.ndarray:\n",
    "        \"\"\"ê³„ì ˆë³„ ì¡°ê±´ ì‹œë®¬ë ˆì´ì…˜\"\"\"\n",
    "        \n",
    "        if season not in self.seasonal_characteristics:\n",
    "            return img\n",
    "        \n",
    "        char = self.seasonal_characteristics[season]\n",
    "        img_float = img.astype(np.float32) / 255.0\n",
    "        \n",
    "        # ë°ê¸° ì¡°ì •\n",
    "        brightness_factor = np.random.uniform(*char['brightness_factor'])\n",
    "        img_float = img_float * brightness_factor\n",
    "        \n",
    "        # ë…¹ìƒ‰ ì±„ë„ ì¡°ì • (ì‹ìƒ ë³€í™”)\n",
    "        green_factor = np.random.uniform(*char['green_enhancement'])\n",
    "        img_float[:, :, 1] = img_float[:, :, 1] * green_factor\n",
    "        \n",
    "        # í† ì–‘ ê°€ì‹œì„± ì¡°ì • (ê°ˆìƒ‰ ê³„ì—´ ê°•ì¡°/ì–µì œ)\n",
    "        soil_factor = np.random.uniform(*char['soil_visibility'])\n",
    "        \n",
    "        # HSVë¡œ ë³€í™˜í•˜ì—¬ ê°ˆìƒ‰ ê³„ì—´ ì¡°ì •\n",
    "        hsv = cv2.cvtColor(img_float, cv2.COLOR_RGB2HSV)\n",
    "        \n",
    "        # ê°ˆìƒ‰ ê³„ì—´ (hue 10-30ë„ ë²”ìœ„) ì¡°ì •\n",
    "        brown_mask = (hsv[:, :, 0] >= 10/360) & (hsv[:, :, 0] <= 30/360)\n",
    "        hsv[:, :, 2][brown_mask] = hsv[:, :, 2][brown_mask] * soil_factor\n",
    "        \n",
    "        img_float = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "        \n",
    "        # ê³„ì ˆë³„ ìƒ‰ì¡° ì¡°ì •\n",
    "        if season == 'autumn':\n",
    "            # ê°€ì„: í™©ìƒ‰/ì£¼í™©ìƒ‰ ê°•ì¡°\n",
    "            img_float[:, :, 0] = np.clip(img_float[:, :, 0] * 1.1, 0, 1)  # ë¹¨ê°• ì•½ê°„ ì¦ê°€\n",
    "            img_float[:, :, 1] = np.clip(img_float[:, :, 1] * 1.05, 0, 1)  # ë…¹ìƒ‰ ì•½ê°„ ì¦ê°€\n",
    "            \n",
    "        elif season == 'winter':\n",
    "            # ê²¨ìš¸: ì±„ë„ ê°ì†Œ, ì²­ìƒ‰ì¡°\n",
    "            img_float = img_float * 0.9  # ì „ì²´ì ìœ¼ë¡œ ì–´ë‘¡ê²Œ\n",
    "            img_float[:, :, 2] = np.clip(img_float[:, :, 2] * 1.05, 0, 1)  # íŒŒë‘ ì•½ê°„ ì¦ê°€\n",
    "        \n",
    "        return np.clip(img_float * 255, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    def _add_noise(self, img: np.ndarray, noise_type: str) -> np.ndarray:\n",
    "        \"\"\"ë…¸ì´ì¦ˆ ì¶”ê°€\"\"\"\n",
    "        \n",
    "        img_float = img.astype(np.float32) / 255.0\n",
    "        \n",
    "        if noise_type == 'gaussian':\n",
    "            # ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ\n",
    "            noise = np.random.normal(0, 0.02, img_float.shape)\n",
    "            img_float = img_float + noise\n",
    "            \n",
    "        elif noise_type == 'speckle':\n",
    "            # ìŠ¤í˜í´ ë…¸ì´ì¦ˆ\n",
    "            noise = np.random.normal(0, 0.05, img_float.shape)\n",
    "            img_float = img_float + img_float * noise\n",
    "            \n",
    "        elif noise_type == 'salt_pepper':\n",
    "            # ì†Œê¸ˆ-í›„ì¶” ë…¸ì´ì¦ˆ\n",
    "            prob = 0.01  # ë…¸ì´ì¦ˆ í™•ë¥ \n",
    "            \n",
    "            # ì†Œê¸ˆ ë…¸ì´ì¦ˆ (í°ìƒ‰ í”½ì…€)\n",
    "            salt_mask = np.random.random(img_float.shape[:2]) < prob/2\n",
    "            img_float[salt_mask] = 1.0\n",
    "            \n",
    "            # í›„ì¶” ë…¸ì´ì¦ˆ (ê²€ì€ìƒ‰ í”½ì…€)\n",
    "            pepper_mask = np.random.random(img_float.shape[:2]) < prob/2\n",
    "            img_float[pepper_mask] = 0.0\n",
    "        \n",
    "        return np.clip(img_float * 255, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    def _save_augmented_image(self, db: Session, original_image: AnnotatedImage, \n",
    "                             aug_filepath: Path, aug_type: str, aug_params: dict) -> AnnotatedImage:\n",
    "        \"\"\"ì¦ê°•ëœ ì´ë¯¸ì§€ ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥\"\"\"\n",
    "        \n",
    "        # íŒŒì¼ í¬ê¸° ê³„ì‚°\n",
    "        file_size = aug_filepath.stat().st_size\n",
    "        \n",
    "        # ì¦ê°•ëœ ì´ë¯¸ì§€ ê°ì²´ ìƒì„±\n",
    "        augmented_image = AnnotatedImage(\n",
    "            dataset_id=original_image.dataset_id,\n",
    "            filename=aug_filepath.name,\n",
    "            file_path=str(aug_filepath),\n",
    "            file_size=file_size,\n",
    "            width=original_image.width,\n",
    "            height=original_image.height,\n",
    "            channels=original_image.channels,\n",
    "            \n",
    "            # ì§€ë¦¬ì •ë³´ ë³µì‚¬\n",
    "            latitude=original_image.latitude,\n",
    "            longitude=original_image.longitude,\n",
    "            crs=original_image.crs,\n",
    "            bounds=original_image.bounds,\n",
    "            \n",
    "            # ì‹œê°„ ì •ë³´ ë³µì‚¬\n",
    "            capture_date=original_image.capture_date,\n",
    "            season=aug_params.get('season', original_image.season),\n",
    "            \n",
    "            # í™˜ê²½ ì •ë³´ (ì¦ê°•ì— ë”°ë¼ ìˆ˜ì •)\n",
    "            weather_condition=aug_params.get('condition', original_image.weather_condition),\n",
    "            lighting_condition=original_image.lighting_condition,\n",
    "            soil_type=original_image.soil_type,\n",
    "            \n",
    "            # ì¦ê°• ì •ë³´\n",
    "            is_augmented=True,\n",
    "            parent_image_id=original_image.id,\n",
    "            augmentation_type=AugmentationType(aug_type),\n",
    "            augmentation_parameters=aug_params,\n",
    "            \n",
    "            # í’ˆì§ˆ ì •ë³´ëŠ” ë‚˜ì¤‘ì— ê³„ì‚°\n",
    "            annotation_count=original_image.annotation_count,\n",
    "            is_validated=False\n",
    "        )\n",
    "        \n",
    "        db.add(augmented_image)\n",
    "        db.flush()  # ID ìƒì„±\n",
    "        \n",
    "        return augmented_image\n",
    "    \n",
    "    def _save_augmented_annotations(self, db: Session, augmented_image: AnnotatedImage,\n",
    "                                   aug_bboxes: List[List[float]], class_labels: List[int],\n",
    "                                   original_annotations: List[Annotation]):\n",
    "        \"\"\"ì¦ê°•ëœ ì–´ë…¸í…Œì´ì…˜ ì €ì¥\"\"\"\n",
    "        \n",
    "        for i, (bbox, class_id) in enumerate(zip(aug_bboxes, class_labels)):\n",
    "            if i < len(original_annotations):\n",
    "                original_ann = original_annotations[i]\n",
    "                \n",
    "                augmented_annotation = Annotation(\n",
    "                    image_id=augmented_image.id,\n",
    "                    class_id=class_id,\n",
    "                    class_name=original_ann.class_name,\n",
    "                    annotation_type=original_ann.annotation_type,\n",
    "                    \n",
    "                    # ë³€í™˜ëœ ë°”ìš´ë”© ë°•ìŠ¤\n",
    "                    bbox_x=bbox[0],\n",
    "                    bbox_y=bbox[1],\n",
    "                    bbox_w=bbox[2],\n",
    "                    bbox_h=bbox[3],\n",
    "                    \n",
    "                    # ê¸°íƒ€ ì •ë³´ ë³µì‚¬\n",
    "                    confidence=original_ann.confidence,\n",
    "                    is_difficult=original_ann.is_difficult,\n",
    "                    is_crowd=original_ann.is_crowd,\n",
    "                    annotator_id=original_ann.annotator_id,\n",
    "                    annotation_tool=\"data_augmentation\"\n",
    "                )\n",
    "                \n",
    "                db.add(augmented_annotation)\n",
    "        \n",
    "        # ì¦ê°•ëœ ì´ë¯¸ì§€ì˜ ì–´ë…¸í…Œì´ì…˜ ê°œìˆ˜ ì—…ë°ì´íŠ¸\n",
    "        augmented_image.annotation_count = len(aug_bboxes)\n",
    "\n",
    "\n",
    "# ì „ì—­ ë†ì—… íŠ¹í™” ë°ì´í„° ì¦ê°• ì¸ìŠ¤í„´ìŠ¤\n",
    "agricultural_augmentation = AgriculturalDataAugmentation(\n",
    "    augmentation_factor=settings.AUGMENTATION_FACTOR\n",
    ")\n",
    "\n",
    "print(\"âœ… ë†ì—… íŠ¹í™” ë°ì´í„° ì¦ê°• ì‹œìŠ¤í…œ êµ¬í˜„ ì™„ë£Œ\")\n",
    "print(f\"ğŸ”¢ ì¦ê°• ë°°ìˆ˜: {settings.AUGMENTATION_FACTOR}\")\n",
    "print(f\"ğŸŒˆ ì§€ì› ì¦ê°•: geometric, color, weather, seasonal, noise\")\n",
    "print(f\"ğŸŒ¾ ë†ì—… íŠ¹í™”: ê³„ì ˆ ë³€í™”, ë‚ ì”¨ ì¡°ê±´, ì‹ìƒ ìƒíƒœ ì‹œë®¬ë ˆì´ì…˜\")"
   ]
  }\n ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}