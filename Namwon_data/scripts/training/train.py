#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê°€ì¥ìë¦¬ ìµœì í™” YOLO ì„¸ê·¸ë©˜í…Œì´ì…˜ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
100 ì—í­ í•™ìŠµìœ¼ë¡œ ê°€ì¥ìë¦¬ ê²€ì¶œ ë¬¸ì œ ê·¼ë³¸ í•´ê²°
"""

import os
import shutil
from pathlib import Path
import yaml
from ultralytics import YOLO
import torch
import numpy as np
from datetime import datetime
import gc
import json
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

# ì‹¤ì œ ë°ì´í„° í†µê³„
ACTUAL_DATA_STATS = {
    'IRG(ìƒì‚°ê¸°)': {'images': 3531, 'objects': 4293, 'train': 2633, 'val': 434, 'test': 464},
    'í˜¸ë°€(ìƒì‚°ê¸°)': {'images': 1685, 'objects': 2014, 'train': 1299, 'val': 212, 'test': 174},
    'ì˜¥ìˆ˜ìˆ˜(ìƒì‚°ê¸°)': {'images': 2738, 'objects': 3025, 'train': 2177, 'val': 282, 'test': 279},
    'ìˆ˜ë‹¨ê·¸ë¼ìŠ¤(ìƒì‚°ê¸°)': {'images': 1596, 'objects': 1722, 'train': 1267, 'val': 165, 'test': 164}
}

def optimize_gpu_memory():
    """RTX A6000 48GB GPU ë©”ëª¨ë¦¬ ìµœì í™”"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        gc.collect()
        
        try:
            torch.cuda.set_per_process_memory_fraction(0.95)  # 95% ë©”ëª¨ë¦¬ í™œìš©
        except:
            pass
            
        torch.backends.cudnn.benchmark = True
        
        # TF32 ì„¤ì •
        if hasattr(torch.backends.cuda, 'matmul'):
            if hasattr(torch.backends.cuda.matmul, 'allow_tf32'):
                torch.backends.cuda.matmul.allow_tf32 = True
        if hasattr(torch.backends.cudnn, 'allow_tf32'):
            torch.backends.cudnn.allow_tf32 = True
        
        # ê³ ì„±ëŠ¥ ëª¨ë“œ
        try:
            if hasattr(torch, 'set_float32_matmul_precision'):
                torch.set_float32_matmul_precision('high')
        except:
            pass
        
        print(f"ğŸ® RTX A6000 GPU ìµœì í™” ì™„ë£Œ")
        print(f"   - ì´ ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
        print(f"   - CUDA ë²„ì „: {torch.version.cuda}")
        print(f"   - cuDNN ë²„ì „: {torch.backends.cudnn.version()}")

def calculate_class_weights():
    """í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ë¥¼ ìœ„í•œ ê°€ì¤‘ì¹˜ ê³„ì‚°"""
    
    total_objects = sum(stats['objects'] for stats in ACTUAL_DATA_STATS.values())
    class_weights = {}
    
    print("\nâš–ï¸ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°:")
    for idx, (class_name, stats) in enumerate(ACTUAL_DATA_STATS.items()):
        weight = total_objects / (4 * stats['objects'])
        weight = min(max(weight, 0.5), 2.0)
        weight = float(weight)
        class_weights[idx] = round(weight, 3)
        print(f"   - {class_name}: {weight:.3f} (ê°ì²´ ìˆ˜: {stats['objects']})")
    
    return class_weights

def prepare_dataset():
    """ë°ì´í„°ì…‹ ì¤€ë¹„ (ê¸°ì¡´ ë°ì´í„°ì…‹ ì¬ì‚¬ìš©)"""
    
    target_dir = Path('production_dataset_balanced')
    yaml_path = target_dir / 'dataset.yaml'
    
    # ê¸°ì¡´ ë°ì´í„°ì…‹ í™•ì¸
    if not target_dir.exists() or not yaml_path.exists():
        print("âŒ ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ì…‹ì„ ìƒì„±í•˜ì„¸ìš”.")
        return None, None, None
    
    print("\nâœ… ê¸°ì¡´ ë°ì´í„°ì…‹ ì‚¬ìš©")
    
    # í†µê³„ ë¡œë“œ
    with open(target_dir / 'dataset_stats.json', 'r') as f:
        stats = json.load(f)
        train_size = stats['train_images']
        val_size = stats['val_images']
        test_size = stats['test_images']
    
    print(f"   - Train: {train_size}ê°œ")
    print(f"   - Val: {val_size}ê°œ")
    print(f"   - Test: {test_size}ê°œ")
    
    class_weights = calculate_class_weights()
    
    return yaml_path, train_size, class_weights

def train_edge_optimized_model():
    """ê°€ì¥ìë¦¬ ìµœì í™” 100 ì—í­ í•™ìŠµ"""
    
    print("\n" + "="*70)
    print("ğŸš€ ê°€ì¥ìë¦¬ ìµœì í™” YOLO ì„¸ê·¸ë©˜í…Œì´ì…˜ í•™ìŠµ (100 ì—í­)")
    print("="*70)
    
    # GPU ë©”ëª¨ë¦¬ ìµœì í™”
    optimize_gpu_memory()
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ğŸ–¥ï¸  ë””ë°”ì´ìŠ¤: {device}")
    
    if device == 'cuda':
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"ğŸ® GPU: {gpu_name}")
        print(f"ğŸ’¾ ë©”ëª¨ë¦¬: {gpu_memory:.1f}GB")
    
    # ë°ì´í„°ì…‹ ì¤€ë¹„
    yaml_path, train_size, class_weights = prepare_dataset()
    if yaml_path is None:
        return None
    
    # ë°°ì¹˜ í¬ê¸° ì„¤ì •
    batch_size = 8  # ì•ˆì •ì ì¸ í¬ê¸° ìœ ì§€
    
    # ëª¨ë¸ ë¡œë“œ - ì´ì „ best ëª¨ë¸ì—ì„œ ì‹œì‘ (ìˆìœ¼ë©´)
    best_model_path = 'runs/quick_test/quick_test_5ep_20250930_0135/weights/best.pt'
    if Path(best_model_path).exists():
        print(f"\nğŸ“¦ ì´ì „ best ëª¨ë¸ì—ì„œ ì‹œì‘: {best_model_path}")
        model = YOLO(best_model_path)
    else:
        print(f"\nğŸ“¦ YOLO11x-seg ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë¡œë“œ")
        model = YOLO('yolo11x-seg.pt')
    
    # í•™ìŠµ ì„¤ì •
    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    run_name = f'edge_optimized_100ep_{timestamp}'
    
    print(f"\nâš™ï¸  ê°€ì¥ìë¦¬ ìµœì í™” í•™ìŠµ ì„¤ì •:")
    print(f"   ğŸ“Š ë°ì´í„°ì…‹: {train_size}ê°œ í•™ìŠµ ì´ë¯¸ì§€")
    print(f"   ğŸ”„ ì—í­: 100")
    print(f"   ğŸ“¦ ë°°ì¹˜ í¬ê¸°: {batch_size}")
    print(f"   ğŸ“ ì´ë¯¸ì§€ í¬ê¸°: 1024x1024")
    print(f"   ğŸ¯ ì´ˆê¸° í•™ìŠµë¥ : 0.001")
    print(f"   ğŸ“Œ Mosaic: 0.3 (ê°ì†Œ)")
    print(f"   ğŸ”§ Close Mosaic: ë§ˆì§€ë§‰ 30 ì—í­")
    print(f"   âš¡ Mixed Precision: í™œì„±í™”")
    
    # ê°€ì¥ìë¦¬ ìµœì í™” í•™ìŠµ íŒŒë¼ë¯¸í„°
    training_args = {
        'data': str(yaml_path),
        'epochs': 100,  # 100 ì—í­
        'batch': batch_size,
        'imgsz': 1024,  # ê³ ì •
        'device': device,
        'project': 'runs/edge_optimized',
        'name': run_name,
        'save': True,
        'save_period': 10,  # 10 ì—í­ë§ˆë‹¤ ì €ì¥
        'val': True,
        'plots': True,
        'verbose': True,
        'exist_ok': True,
        
        # í•™ìŠµë¥  ì„¤ì • (ì•ˆì •ì )
        'patience': 20,  # ì¡°ê¸° ì¢…ë£Œ ì—¬ìœ 
        'lr0': 0.001,  # 0.002 â†’ 0.001 (ë” ì•ˆì •ì )
        'lrf': 0.01,  # ìµœì¢… í•™ìŠµë¥  (0.001ì˜ 1%)
        'momentum': 0.937,
        'weight_decay': 0.0005,
        'warmup_epochs': 3,  # ì›Œë°ì—…
        'warmup_momentum': 0.8,
        'warmup_bias_lr': 0.05,
        
        # ì†ì‹¤ ê°€ì¤‘ì¹˜ (ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¤‘ìš”)
        'box': 5.0,
        'cls': 0.8,
        'dfl': 1.2,
        
        # ì„¸ê·¸ë©˜í…Œì´ì…˜ ìµœì í™”
        'overlap_mask': True,
        'mask_ratio': 4,  # ê³ í•´ìƒë„ ë§ˆìŠ¤í¬
        
        # ê°€ì¥ìë¦¬ í•™ìŠµì„ ìœ„í•œ ë°ì´í„° ì¦ê°•
        'hsv_h': 0.015,  # ìƒ‰ì¡° ë³€í™”
        'hsv_s': 0.5,    # ì±„ë„ ë³€í™”
        'hsv_v': 0.3,    # ëª…ë„ ë³€í™”
        'degrees': 5.0,   # íšŒì „
        'translate': 0.1,  # ì´ë™
        'scale': 0.3,     # ìŠ¤ì¼€ì¼
        'shear': 1.0,     # ì „ë‹¨
        'perspective': 0.0,  # ì›ê·¼ ì—†ìŒ
        'flipud': 0.3,    # ìƒí•˜ ë°˜ì „
        'fliplr': 0.5,    # ì¢Œìš° ë°˜ì „
        
        # í•µì‹¬: Mosaic ê°ì†Œ (ê°€ì¥ìë¦¬ í•™ìŠµ ê°œì„ )
        'mosaic': 0.3,  # 0.7 â†’ 0.3 (ëŒ€í­ ê°ì†Œ)
        'mixup': 0.1,   # 0.15 â†’ 0.1
        
        # Copy-Paste ì¦ê°€ (ê°€ì¥ìë¦¬ í•™ìŠµ ê°•í™”)
        'copy_paste': 0.4,  # 0.15 â†’ 0.4 (ì¦ê°€)
        
        # Auto augment
        'auto_augment': None,  # ë¹„í™œì„±í™”
        'erasing': 0.2,  # Random Erasing
        
        # ëª¨ìì´í¬ ì¡°ê¸° ì¢…ë£Œ (ê°€ì¥ìë¦¬ ì§‘ì¤‘)
        'close_mosaic': 30,  # ë§ˆì§€ë§‰ 30 ì—í­ì€ mosaic ì—†ì´
        
        # ì„±ëŠ¥ ìµœì í™”
        'cache': 'ram',  # RAM ìºì‹±
        'amp': True,     # Mixed Precision
        'workers': 16,   # ë°ì´í„° ë¡œë” ì›Œì»¤
        'nbs': 64,       # ëª…ëª© ë°°ì¹˜ í¬ê¸°
        'seed': 42,
        'deterministic': False,  # ì†ë„ ìš°ì„ 
        
        # ê°€ì¥ìë¦¬ í•™ìŠµ ê°œì„ ì„ ìœ„í•œ ì¶”ê°€ ì„¤ì •
        'rect': False,  # ì§ì‚¬ê°í˜• í›ˆë ¨ ë¹„í™œì„±í™” (ì „ì²´ ì´ë¯¸ì§€ ì‚¬ìš©)
        'cos_lr': True,  # ì½”ì‚¬ì¸ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„
        'dropout': 0.0,  # ë“œë¡­ì•„ì›ƒ ì—†ìŒ
        
        # ì˜µí‹°ë§ˆì´ì €
        'optimizer': 'AdamW',  # SGD â†’ AdamW (ë” ë‚˜ì€ ìˆ˜ë ´)
        
        # ì¶”ê°€ ì•ˆì •í™”
        'single_cls': False,
        'multi_scale': False,  # ë‹¨ì¼ ìŠ¤ì¼€ì¼ ìœ ì§€
        'fraction': 1.0,  # ì „ì²´ ë°ì´í„° ì‚¬ìš©
    }
    
    print(f"\nğŸ“Œ ê°€ì¥ìë¦¬ í•™ìŠµ ê°•í™” ì „ëµ:")
    print(f"   1. Mosaic 0.3ìœ¼ë¡œ ê°ì†Œ (ê°€ì¥ìë¦¬ ë³´ì¡´)")
    print(f"   2. Copy-Paste 0.4ë¡œ ì¦ê°€ (ê°€ì¥ìë¦¬ ë³€í˜•)")
    print(f"   3. ë§ˆì§€ë§‰ 30 ì—í­ Mosaic ì—†ì´ (ê°€ì¥ìë¦¬ ì§‘ì¤‘)")
    print(f"   4. rect=False (íŒ¨ë”© ì—†ì´ ì „ì²´ ì´ë¯¸ì§€)")
    print(f"   5. mask_ratio=4 (ê³ í•´ìƒë„ ë§ˆìŠ¤í¬)")
    print(f"   6. AdamW ì˜µí‹°ë§ˆì´ì € (ì •ë°€ ìˆ˜ë ´)")
    
    print("\nğŸƒâ€â™‚ï¸ í•™ìŠµ ì‹œì‘...")
    print("   ğŸ’¡ TensorBoard: tensorboard --logdir runs/edge_optimized")
    
    try:
        # í•™ìŠµ ì‹¤í–‰
        results = model.train(**training_args)
        
        print(f"\nâœ… í•™ìŠµ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼: runs/edge_optimized/{run_name}")
        
        # ìµœì¢… ê²€ì¦
        print("\nğŸ“Š ìµœì¢… ê²€ì¦...")
        final_val = model.val(
            data=str(yaml_path),
            split='val',
            batch=16,
            conf=0.25,
            device=device
        )
        
        print(f"\nğŸ“ˆ ìµœì¢… ì„±ëŠ¥:")
        print(f"   Box mAP50: {final_val.box.map50:.3f}")
        print(f"   Box mAP50-95: {final_val.box.map:.3f}")
        if hasattr(final_val, 'seg'):
            print(f"   Mask mAP50: {final_val.seg.map50:.3f}")
            print(f"   Mask mAP50-95: {final_val.seg.map:.3f}")
        
        # Test ì„¸íŠ¸ í‰ê°€
        print("\nğŸ“Š Test ì„¸íŠ¸ í‰ê°€...")
        test_val = model.val(
            data=str(yaml_path),
            split='test',
            batch=16,
            conf=0.25,
            device=device
        )
        
        print(f"\nğŸ“ˆ Test ì„¸íŠ¸ ì„±ëŠ¥:")
        print(f"   Box mAP50: {test_val.box.map50:.3f}")
        print(f"   Mask mAP50: {test_val.seg.map50:.3f}")
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del model
        torch.cuda.empty_cache()
        gc.collect()
        
        return run_name, class_weights
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ì ì¤‘ë‹¨")
        print("   ì¤‘ê°„ ì²´í¬í¬ì¸íŠ¸ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return None, None
        
    except torch.cuda.OutOfMemoryError:
        print("âŒ GPU ë©”ëª¨ë¦¬ ë¶€ì¡±!")
        print("ğŸ’¡ ë°°ì¹˜ í¬ê¸°ë¥¼ 4ë¡œ ì¤„ì—¬ì„œ ì¬ì‹œë„í•˜ì„¸ìš”.")
        return None, None
        
    except Exception as e:
        print(f"âŒ í•™ìŠµ ì¤‘ ì˜¤ë¥˜: {e}")
        raise

def verify_edge_performance(run_name):
    """ê°€ì¥ìë¦¬ ì„±ëŠ¥ ê²€ì¦"""
    
    print("\n" + "="*60)
    print("ğŸ” ê°€ì¥ìë¦¬ ì„±ëŠ¥ ê²€ì¦")
    print("="*60)
    
    model_path = f'runs/edge_optimized/{run_name}/weights/best.pt'
    
    if not Path(model_path).exists():
        print(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
        return
    
    # ëª¨ë¸ ë¡œë“œ
    model = YOLO(model_path)
    
    # Test ì´ë¯¸ì§€ë¡œ ê°€ì¥ìë¦¬ í…ŒìŠ¤íŠ¸
    test_images = list(Path('production_dataset_balanced/images/test').glob('*.jpg'))[:5]
    
    print(f"\nğŸ“· {len(test_images)}ê°œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¡œ ê°€ì¥ìë¦¬ ê²€ì¦...")
    
    for img_path in test_images:
        results = model.predict(
            source=str(img_path),
            conf=0.25,
            imgsz=1024,
            save=True,
            save_txt=True,
            project=f'runs/edge_optimized/{run_name}',
            name='edge_test',
            exist_ok=True
        )
        
        # ê°€ì¥ìë¦¬ í”½ì…€ í™•ì¸ (ê°„ë‹¨í•œ ì²´í¬)
        if results[0].masks is not None:
            mask = results[0].masks.data[0].cpu().numpy()
            h, w = mask.shape
            
            # ê°€ì¥ìë¦¬ 10í”½ì…€ ì˜ì—­ ì²´í¬
            edge_coverage = {
                'top': np.mean(mask[:10, :] > 0.5) * 100,
                'bottom': np.mean(mask[-10:, :] > 0.5) * 100,
                'left': np.mean(mask[:, :10] > 0.5) * 100,
                'right': np.mean(mask[:, -10:] > 0.5) * 100
            }
            
            avg_edge = np.mean(list(edge_coverage.values()))
            print(f"   {img_path.name}: ê°€ì¥ìë¦¬ ì»¤ë²„ë¦¬ì§€ {avg_edge:.1f}%")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("\n" + "="*80)
    print("ğŸŒ¾ ê°€ì¥ìë¦¬ ìµœì í™” YOLO ì„¸ê·¸ë©˜í…Œì´ì…˜ í•™ìŠµ")
    print("="*80)
    print("ğŸ“Š ë°ì´í„°: 9,550ê°œ ì´ë¯¸ì§€")
    print("ğŸ® í™˜ê²½: RTX A6000 48GB GPU")
    print("ğŸ¯ ëª©í‘œ: ê°€ì¥ìë¦¬ ê²€ì¶œ ë¬¸ì œ ê·¼ë³¸ í•´ê²°")
    print("â° ì˜ˆìƒ ì‹œê°„: ì•½ 10-15ì‹œê°„ (100 ì—í­)")
    print("="*80)
    
    try:
        # 1. í•™ìŠµ ì‹¤í–‰
        run_name, class_weights = train_edge_optimized_model()
        
        if run_name:
            # 2. ê°€ì¥ìë¦¬ ì„±ëŠ¥ ê²€ì¦
            verify_edge_performance(run_name)
            
            # 3. ìµœì¢… ìš”ì•½
            print("\n" + "="*80)
            print("ğŸŠ í•™ìŠµ ì™„ë£Œ ìš”ì•½")
            print("="*80)
            print(f"âœ… ëª¨ë¸: runs/edge_optimized/{run_name}/weights/best.pt")
            print(f"ğŸ“Š ì˜ˆìƒ ì„±ëŠ¥:")
            print(f"   - mAP50: >97%")
            print(f"   - ê°€ì¥ìë¦¬ ê²€ì¶œ: í¬ê²Œ ê°œì„ ")
            print(f"   - ì¶”ë¡  ì†ë„: 30-40 FPS")
            print(f"\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
            print(f"   1. Test ì„¸íŠ¸ë¡œ ê°€ì¥ìë¦¬ ê²€ì¦")
            print(f"   2. ì‹¤ì œ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸")
            print(f"   3. í•„ìš”ì‹œ ì¶”ê°€ ë¯¸ì„¸ì¡°ì •")
            print(f"   4. í”„ë¡œë•ì…˜ ë°°í¬")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ì ì¤‘ë‹¨")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
    finally:
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        gc.collect()
        print("\nğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")

if __name__ == "__main__":
    main()