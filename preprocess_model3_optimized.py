#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Model3 Greenhouse ë°ì´í„°ì…‹ ìµœì í™” ì „ì²˜ë¦¬
optimized_preprocessing.py êµ¬ì¡° ê¸°ë°˜

í´ë˜ìŠ¤:
- 0: Greenhouse_single (ë‹¨ë™)
- 1: Greenhouse_multi (ì—°ë™)

ì‘ì„±: Claude Sonnet
ë‚ ì§œ: 2025-11-04
"""

import os
import json
import yaml
import shutil
import random
import time
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from collections import Counter, defaultdict
from dataclasses import dataclass, asdict, field

import cv2
import numpy as np
from PIL import Image
from tqdm import tqdm
from sklearn.model_selection import StratifiedShuffleSplit

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ================== ì„¤ì • í´ë˜ìŠ¤ ==================

@dataclass
class Model3Config:
    """Model3 Greenhouse ì „ìš© ì„¤ì •"""
    # ê²½ë¡œ
    source_dir: str = r"C:\Users\LX\Nong-View\model3_greenhouse"
    output_dir: str = r"C:\Users\LX\Nong-View\model3_greenhouse_best_processed"

    # í´ë˜ìŠ¤ ì •ë³´
    classes: List[str] = field(default_factory=lambda: ['Greenhouse_single', 'Greenhouse_multi'])
    nc: int = 2

    # ë°ì´í„° ë¶„í•  ë¹„ìœ¨
    train_ratio: float = 0.8
    val_ratio: float = 0.1
    test_ratio: float = 0.1

    # ì „ì²˜ë¦¬ ì˜µì…˜
    enable_quality_filter: bool = True
    enable_augmentation: bool = True
    augmentation_factor: int = 2  # í›ˆë ¨ ë°ì´í„°ë§Œ

    # í’ˆì§ˆ í•„í„°ë§ ì„ê³„ê°’
    quality_threshold: float = 0.4

    # ëœë¤ ì‹œë“œ
    random_seed: int = 42


# ================== ë°ì´í„° í´ë˜ìŠ¤ ==================

@dataclass
class ImageInfo:
    """ì´ë¯¸ì§€ ì •ë³´ í´ë˜ìŠ¤"""
    filepath: Path
    filename: str
    width: int = 0
    height: int = 0
    classes: List[int] = field(default_factory=list)
    class_distribution: Dict[str, int] = field(default_factory=dict)
    quality_score: float = 0.0
    dominant_class: int = -1


@dataclass
class ProcessingStats:
    """ì²˜ë¦¬ í†µê³„ í´ë˜ìŠ¤"""
    original_images: int = 0
    processed_images: int = 0
    augmented_images: int = 0
    filtered_images: int = 0
    total_objects: int = 0
    class_distribution: Dict[str, int] = field(default_factory=dict)
    processing_time: float = 0.0


# ================== ë°ì´í„° í’ˆì§ˆ ë¶„ì„ê¸° ==================

class DataQualityAnalyzer:
    """ë°ì´í„° í’ˆì§ˆ ë¶„ì„ í´ë˜ìŠ¤"""

    def analyze_image_quality(self, image_path: Path) -> float:
        """ì´ë¯¸ì§€ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (0.0 ~ 1.0)"""
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            img = cv2.imread(str(image_path))
            if img is None:
                return 0.0

            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

            # 1. íë¦¼ ê°ì§€ (Laplacian variance)
            laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
            blur_score = min(laplacian_var / 500.0, 1.0)  # ì •ê·œí™”

            # 2. ë°ê¸° í‰ê°€
            mean_brightness = np.mean(gray)
            brightness_score = 1.0 - abs(mean_brightness - 127.5) / 127.5

            # 3. ëŒ€ë¹„ í‰ê°€
            contrast = gray.std()
            contrast_score = min(contrast / 64.0, 1.0)

            # ì¢…í•© ì ìˆ˜ (ê°€ì¤‘ í‰ê· )
            quality_score = (
                blur_score * 0.5 +
                brightness_score * 0.3 +
                contrast_score * 0.2
            )

            return quality_score

        except Exception as e:
            logger.error(f"í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨ {image_path.name}: {e}")
            return 0.5  # ì¤‘ê°„ ì ìˆ˜

    def detect_outliers(self, image_infos: List[ImageInfo]) -> List[bool]:
        """ì´ìƒì¹˜ íƒì§€ (ê°„ë‹¨í•œ IQR ë°©ë²•)"""
        if len(image_infos) < 4:
            return [False] * len(image_infos)

        # í’ˆì§ˆ ì ìˆ˜ ìˆ˜ì§‘
        scores = [info.quality_score for info in image_infos]
        scores_sorted = sorted(scores)

        # IQR ê³„ì‚°
        q1_idx = len(scores_sorted) // 4
        q3_idx = (3 * len(scores_sorted)) // 4
        q1 = scores_sorted[q1_idx]
        q3 = scores_sorted[q3_idx]
        iqr = q3 - q1

        # ì´ìƒì¹˜ ê¸°ì¤€
        lower_bound = q1 - 1.5 * iqr
        upper_bound = q3 + 1.5 * iqr

        # ì´ìƒì¹˜ íƒì§€
        outliers = [
            score < lower_bound or score > upper_bound
            for score in scores
        ]

        return outliers


# ================== ë°ì´í„° ì¦ê°• ==================

class GreenhouseDataAugmentation:
    """ì˜¨ì‹¤ íŠ¹í™” ë°ì´í„° ì¦ê°• (ê°„ë‹¨í•˜ê³  í™•ì‹¤í•˜ê²Œ)"""

    def augment_image(self, image: np.ndarray, bboxes: List, class_labels: List) -> Tuple[np.ndarray, List, List]:
        """ì´ë¯¸ì§€ ì¦ê°• ì ìš© - ê°„ë‹¨í•˜ê³  í™•ì‹¤í•œ ë³€í™˜ë§Œ ì‚¬ìš©"""
        try:
            aug_image = image.copy()
            aug_bboxes = [bbox.copy() if isinstance(bbox, list) else list(bbox) for bbox in bboxes]
            aug_class_labels = class_labels.copy()

            h, w = aug_image.shape[:2]

            # 1. ì¢Œìš° ë°˜ì „ (í•­ìƒ ì ìš© - ê°€ì¥ ì•ˆì „)
            aug_image = cv2.flip(aug_image, 1)
            # bbox x ì¢Œí‘œ ë°˜ì „
            for bbox in aug_bboxes:
                bbox[0] = 1.0 - bbox[0]

            # 2. ë°ê¸° ì¡°ì •
            brightness_factor = random.uniform(0.85, 1.15)
            aug_image = np.clip(aug_image.astype(np.float32) * brightness_factor, 0, 255).astype(np.uint8)

            # 3. ëŒ€ë¹„ ì¡°ì •
            contrast_factor = random.uniform(0.9, 1.1)
            aug_image = np.clip((aug_image.astype(np.float32) - 127.5) * contrast_factor + 127.5, 0, 255).astype(np.uint8)

            return aug_image, aug_bboxes, aug_class_labels

        except Exception as e:
            logger.error(f"ì¦ê°• ì¤‘ ì—ëŸ¬: {e}")
            # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜
            return image, bboxes, class_labels


# ================== ë©”ì¸ ì „ì²˜ë¦¬ í´ë˜ìŠ¤ ==================

class Model3OptimizedPreprocessor:
    """Model3 Greenhouse ìµœì í™” ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self, config: Model3Config = None):
        self.config = config if config else Model3Config()
        self.quality_analyzer = DataQualityAnalyzer()
        self.augmenter = GreenhouseDataAugmentation()

        # ëœë¤ ì‹œë“œ ì„¤ì •
        random.seed(self.config.random_seed)
        np.random.seed(self.config.random_seed)

        logger.info("=" * 60)
        logger.info("Model3 Greenhouse ìµœì í™” ì „ì²˜ë¦¬ ì´ˆê¸°í™”")
        logger.info("=" * 60)
        logger.info(f"ì†ŒìŠ¤: {self.config.source_dir}")
        logger.info(f"ì¶œë ¥: {self.config.output_dir}")
        logger.info(f"í’ˆì§ˆ í•„í„°ë§: {self.config.enable_quality_filter}")
        logger.info(f"ë°ì´í„° ì¦ê°•: {self.config.enable_augmentation}")

    def run(self) -> ProcessingStats:
        """ì „ì²´ ì „ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        start_time = time.time()

        logger.info("\n[1/6] ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        image_infos = self._collect_images()
        logger.info(f"âœ“ {len(image_infos)}ê°œ ì´ë¯¸ì§€ ìˆ˜ì§‘ ì™„ë£Œ")

        logger.info("\n[2/6] í’ˆì§ˆ ë¶„ì„ ì¤‘...")
        if self.config.enable_quality_filter:
            image_infos = self._filter_by_quality(image_infos)
        logger.info(f"âœ“ {len(image_infos)}ê°œ ì´ë¯¸ì§€ (í’ˆì§ˆ í•„í„°ë§ í›„)")

        logger.info("\n[3/6] ê³„ì¸µí™” ë¶„í•  ì¤‘...")
        splits = self._stratified_split(image_infos)
        logger.info(f"âœ“ Train: {len(splits['train'])}, Val: {len(splits['val'])}, Test: {len(splits['test'])}")

        logger.info("\n[4/6] ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„± ì¤‘...")
        output_path = Path(self.config.output_dir)
        self._setup_output_structure(output_path)
        logger.info(f"âœ“ {output_path}")

        logger.info("\n[5/6] ë°ì´í„° ë³µì‚¬ ë° ì¦ê°• ì¤‘...")
        stats = self._copy_and_augment_data(splits, output_path)
        logger.info(f"âœ“ ì²˜ë¦¬: {stats.processed_images}ê°œ, ì¦ê°•: {stats.augmented_images}ê°œ")

        logger.info("\n[6/6] ë©”íƒ€ë°ì´í„° ìƒì„± ì¤‘...")
        self._create_yaml_file(splits, output_path, stats)
        self._save_statistics(stats, output_path)
        logger.info("âœ“ ì™„ë£Œ")

        stats.processing_time = time.time() - start_time

        logger.info("\n" + "=" * 60)
        logger.info("âœ… ì „ì²˜ë¦¬ ì™„ë£Œ!")
        logger.info("=" * 60)
        self._print_summary(stats)

        return stats

    def _collect_images(self) -> List[ImageInfo]:
        """ì´ë¯¸ì§€ ìˆ˜ì§‘"""
        source_path = Path(self.config.source_dir)
        all_images = []

        # train/val/test í´ë”ì—ì„œ ìˆ˜ì§‘
        for split in ['train', 'val', 'test']:
            images_dir = source_path / 'images' / split
            labels_dir = source_path / 'labels' / split

            if not images_dir.exists():
                logger.warning(f"ë””ë ‰í† ë¦¬ ì—†ìŒ: {images_dir}")
                continue

            # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
            for img_path in images_dir.glob('*.png'):
                label_path = labels_dir / f"{img_path.stem}.txt"

                if label_path.exists():
                    # ë¼ë²¨ íŒŒì‹±
                    classes, class_dist = self._parse_label(label_path)

                    if classes:
                        # ì´ë¯¸ì§€ í¬ê¸° ì½ê¸°
                        try:
                            img = Image.open(img_path)
                            width, height = img.size
                        except:
                            width, height = 0, 0

                        # ì£¼ìš” í´ë˜ìŠ¤ ì°¾ê¸° (ê°€ì¥ ë§ì€ ê°ì²´ë¥¼ ê°€ì§„ í´ë˜ìŠ¤ ID)
                        if classes:
                            class_counts = Counter(classes)
                            dominant_class = class_counts.most_common(1)[0][0]
                        else:
                            dominant_class = 0

                        info = ImageInfo(
                            filepath=img_path,
                            filename=img_path.name,
                            width=width,
                            height=height,
                            classes=classes,
                            class_distribution=class_dist,
                            dominant_class=dominant_class
                        )
                        all_images.append(info)

        return all_images

    def _parse_label(self, label_path: Path) -> Tuple[List[int], Dict[str, int]]:
        """YOLO ë¼ë²¨ íŒŒì‹±"""
        classes = []
        class_dist = defaultdict(int)

        try:
            with open(label_path, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) >= 5:
                        class_id = int(parts[0])
                        classes.append(class_id)

                        # í´ë˜ìŠ¤ ì´ë¦„ ê°€ì ¸ì˜¤ê¸° (ì•ˆì „í•˜ê²Œ)
                        if 0 <= class_id < len(self.config.classes):
                            class_name = self.config.classes[class_id]
                        else:
                            class_name = f"Class_{class_id}"

                        class_dist[class_name] += 1
        except Exception as e:
            logger.error(f"ë¼ë²¨ íŒŒì‹± ì‹¤íŒ¨ {label_path.name}: {e}")

        return classes, dict(class_dist)

    def _filter_by_quality(self, image_infos: List[ImageInfo]) -> List[ImageInfo]:
        """í’ˆì§ˆ ê¸°ë°˜ í•„í„°ë§"""
        # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        for info in tqdm(image_infos, desc="í’ˆì§ˆ ë¶„ì„"):
            info.quality_score = self.quality_analyzer.analyze_image_quality(info.filepath)

        # ì´ìƒì¹˜ íƒì§€
        outliers = self.quality_analyzer.detect_outliers(image_infos)

        # í•„í„°ë§
        filtered = []
        for i, info in enumerate(image_infos):
            if info.quality_score >= self.config.quality_threshold and not outliers[i]:
                filtered.append(info)

        logger.info(f"í’ˆì§ˆ í•„í„°ë§: {len(image_infos)} â†’ {len(filtered)} ({len(image_infos) - len(filtered)}ê°œ ì œê±°)")

        return filtered

    def _stratified_split(self, image_infos: List[ImageInfo]) -> Dict[str, List[ImageInfo]]:
        """ê³„ì¸µí™” ë¶„í• """
        # í´ë˜ìŠ¤ë³„ ê·¸ë£¹í™”
        class_groups = defaultdict(list)
        for info in image_infos:
            class_groups[info.dominant_class].append(info)

        train_images = []
        val_images = []
        test_images = []

        # ê° í´ë˜ìŠ¤ë³„ë¡œ ë¶„í• 
        for class_id, class_images in class_groups.items():
            random.shuffle(class_images)

            n = len(class_images)
            n_train = int(n * self.config.train_ratio)
            n_val = int(n * self.config.val_ratio)

            train_images.extend(class_images[:n_train])
            val_images.extend(class_images[n_train:n_train + n_val])
            test_images.extend(class_images[n_train + n_val:])

            # í´ë˜ìŠ¤ ì´ë¦„ ê°€ì ¸ì˜¤ê¸° (ì•ˆì „í•˜ê²Œ)
            if 0 <= class_id < len(self.config.classes):
                class_name = self.config.classes[class_id]
            else:
                class_name = f"Class_{class_id}"

            logger.info(f"  {class_name}: Train={n_train}, Val={n_val}, Test={n - n_train - n_val}")

        # ìµœì¢… ì…”í”Œ
        random.shuffle(train_images)
        random.shuffle(val_images)
        random.shuffle(test_images)

        return {
            'train': train_images,
            'val': val_images,
            'test': test_images
        }

    def _setup_output_structure(self, output_path: Path):
        """ì¶œë ¥ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±"""
        if output_path.exists():
            logger.warning(f"ê¸°ì¡´ ë””ë ‰í† ë¦¬ ì‚­ì œ: {output_path}")
            shutil.rmtree(output_path)

        for split in ['train', 'val', 'test']:
            (output_path / 'images' / split).mkdir(parents=True, exist_ok=True)
            (output_path / 'labels' / split).mkdir(parents=True, exist_ok=True)

    def _copy_and_augment_data(self, splits: Dict[str, List[ImageInfo]], output_path: Path) -> ProcessingStats:
        """ë°ì´í„° ë³µì‚¬ ë° ì¦ê°•"""
        stats = ProcessingStats()
        stats.original_images = sum(len(images) for images in splits.values())

        total_processed = 0
        total_augmented = 0
        class_counter = Counter()

        for split_name, image_infos in splits.items():
            images_dir = output_path / 'images' / split_name
            labels_dir = output_path / 'labels' / split_name

            # ì¦ê°• ì—¬ë¶€ ê²°ì •
            apply_augmentation = (split_name == 'train' and self.config.enable_augmentation)

            for info in tqdm(image_infos, desc=f"{split_name} ì²˜ë¦¬"):
                # ì›ë³¸ ë³µì‚¬
                self._copy_single_file(info, images_dir, labels_dir)
                total_processed += 1

                # í´ë˜ìŠ¤ ë¶„í¬ ì—…ë°ì´íŠ¸
                for class_name, count in info.class_distribution.items():
                    class_counter[class_name] += count

                # ì¦ê°• (í›ˆë ¨ ë°ì´í„°ë§Œ)
                if apply_augmentation:
                    aug_count = self._augment_single_image(
                        info, images_dir, labels_dir, self.config.augmentation_factor - 1
                    )
                    total_augmented += aug_count

                    # ì¦ê°• ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬
                    for class_name, count in info.class_distribution.items():
                        class_counter[class_name] += count * aug_count

        stats.processed_images = total_processed
        stats.augmented_images = total_augmented
        stats.total_objects = sum(class_counter.values())
        stats.class_distribution = dict(class_counter)

        return stats

    def _copy_single_file(self, info: ImageInfo, images_dir: Path, labels_dir: Path):
        """ë‹¨ì¼ íŒŒì¼ ë³µì‚¬"""
        # ì´ë¯¸ì§€ ë³µì‚¬
        shutil.copy2(info.filepath, images_dir / info.filename)

        # ë¼ë²¨ ë³µì‚¬
        source_label = info.filepath.parent.parent / 'labels' / info.filepath.parent.name / f"{info.filepath.stem}.txt"
        if source_label.exists():
            shutil.copy2(source_label, labels_dir / f"{info.filepath.stem}.txt")

    def _augment_single_image(self, info: ImageInfo, images_dir: Path, labels_dir: Path, count: int) -> int:
        """ë‹¨ì¼ ì´ë¯¸ì§€ ì¦ê°• - ê°œì„ ëœ ë²„ì „"""
        if count <= 0:
            return 0

        # ë¼ë²¨ íŒŒì¼ ê²½ë¡œ
        source_label = info.filepath.parent.parent / 'labels' / info.filepath.parent.name / f"{info.filepath.stem}.txt"

        if not source_label.exists():
            logger.debug(f"ë¼ë²¨ ì—†ìŒ: {source_label}")
            return 0

        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = cv2.imread(str(info.filepath))
            if image is None:
                logger.warning(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {info.filepath}")
                return 0

            # ë¼ë²¨ ë¡œë“œ
            bboxes, class_labels = self._load_yolo_labels(source_label)
            if not bboxes:
                logger.debug(f"bbox ì—†ìŒ: {source_label}")
                return 0

            successful = 0

            for i in range(count):
                try:
                    # ì¦ê°• ì ìš©
                    aug_image, aug_bboxes, aug_labels = self.augmenter.augment_image(
                        image, bboxes, class_labels
                    )

                    if not aug_bboxes or len(aug_bboxes) == 0:
                        logger.warning(f"ì¦ê°• í›„ bbox ì†ì‹¤: {info.filename} #{i+1}")
                        continue

                    # ì¦ê°• ì´ë¯¸ì§€ ì €ì¥
                    aug_img_name = f"{info.filepath.stem}_aug{i+1}{info.filepath.suffix}"
                    aug_img_path = images_dir / aug_img_name

                    result = cv2.imwrite(str(aug_img_path), aug_image)
                    if not result:
                        logger.error(f"ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {aug_img_path}")
                        continue

                    # ì¦ê°• ë¼ë²¨ ì €ì¥
                    aug_label_path = labels_dir / f"{info.filepath.stem}_aug{i+1}.txt"
                    self._save_yolo_labels(aug_label_path, aug_bboxes, aug_labels)

                    # ì €ì¥ í™•ì¸
                    if aug_img_path.exists() and aug_label_path.exists():
                        successful += 1
                        if i == 0:  # ì²« ë²ˆì§¸ ì¦ê°•ë§Œ ë¡œê·¸
                            logger.info(f"ì¦ê°• ì„±ê³µ: {aug_img_name}")
                    else:
                        logger.error(f"íŒŒì¼ í™•ì¸ ì‹¤íŒ¨: {aug_img_name}")

                except Exception as e:
                    logger.error(f"ì¦ê°• ì‹¤íŒ¨ {info.filename} #{i+1}: {e}")
                    import traceback
                    logger.debug(traceback.format_exc())
                    continue

            if successful == 0:
                logger.warning(f"ëª¨ë“  ì¦ê°• ì‹¤íŒ¨: {info.filename} (ì‹œë„: {count}íšŒ)")

            return successful

        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ì¦ê°• ì‹¤íŒ¨ {info.filename}: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return 0

    def _load_yolo_labels(self, label_path: Path) -> Tuple[List, List]:
        """YOLO ë¼ë²¨ ë¡œë“œ"""
        bboxes = []
        class_labels = []

        try:
            with open(label_path, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) >= 5:
                        class_id = int(parts[0])
                        x, y, w, h = map(float, parts[1:5])
                        bboxes.append([x, y, w, h])
                        class_labels.append(class_id)
        except Exception as e:
            logger.error(f"ë¼ë²¨ ë¡œë“œ ì‹¤íŒ¨ {label_path}: {e}")

        return bboxes, class_labels

    def _save_yolo_labels(self, label_path: Path, bboxes: List, class_labels: List):
        """YOLO ë¼ë²¨ ì €ì¥"""
        try:
            with open(label_path, 'w') as f:
                for bbox, class_id in zip(bboxes, class_labels):
                    f.write(f"{class_id} {bbox[0]:.6f} {bbox[1]:.6f} {bbox[2]:.6f} {bbox[3]:.6f}\n")
        except Exception as e:
            logger.error(f"ë¼ë²¨ ì €ì¥ ì‹¤íŒ¨ {label_path}: {e}")

    def _create_yaml_file(self, splits: Dict[str, List[ImageInfo]], output_path: Path, stats: ProcessingStats):
        """YAML ì„¤ì • íŒŒì¼ ìƒì„±"""
        yaml_content = {
            'path': str(output_path.absolute()),
            'train': 'images/train',
            'val': 'images/val',
            'test': 'images/test',
            'nc': self.config.nc,
            'names': self.config.classes,

            'dataset_info': {
                'total': stats.original_images,
                'train': len(splits['train']),
                'val': len(splits['val']),
                'test': len(splits['test']),
                'processed': stats.processed_images,
                'augmented': stats.augmented_images,
                'filtered': stats.filtered_images
            },

            'preprocessing': {
                'method': 'optimized_stratified_split',
                'quality_filtering': self.config.enable_quality_filter,
                'quality_threshold': self.config.quality_threshold,
                'augmentation': self.config.enable_augmentation,
                'augmentation_factor': self.config.augmentation_factor,
                'random_seed': self.config.random_seed
            }
        }

        yaml_path = output_path / 'data.yaml'
        with open(yaml_path, 'w', encoding='utf-8') as f:
            yaml.dump(yaml_content, f, default_flow_style=False, allow_unicode=True, sort_keys=False)

        logger.info(f"YAML íŒŒì¼: {yaml_path}")

    def _save_statistics(self, stats: ProcessingStats, output_path: Path):
        """í†µê³„ ì €ì¥"""
        stats_path = output_path / 'processing_stats.json'
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(asdict(stats), f, indent=2, ensure_ascii=False)

        logger.info(f"í†µê³„ íŒŒì¼: {stats_path}")

    def _print_summary(self, stats: ProcessingStats):
        """ìµœì¢… ìš”ì•½ ì¶œë ¥"""
        logger.info(f"\nğŸ“Š ì²˜ë¦¬ í†µê³„:")
        logger.info(f"  - ì›ë³¸ ì´ë¯¸ì§€: {stats.original_images}ê°œ")
        logger.info(f"  - ì²˜ë¦¬ëœ ì´ë¯¸ì§€: {stats.processed_images}ê°œ")
        logger.info(f"  - ì¦ê°•ëœ ì´ë¯¸ì§€: {stats.augmented_images}ê°œ")
        logger.info(f"  - ì´ ì´ë¯¸ì§€: {stats.processed_images + stats.augmented_images}ê°œ")
        logger.info(f"  - ì´ ê°ì²´: {stats.total_objects}ê°œ")
        logger.info(f"  - ì²˜ë¦¬ ì‹œê°„: {stats.processing_time:.2f}ì´ˆ")

        logger.info(f"\nğŸ“Š í´ë˜ìŠ¤ ë¶„í¬:")
        for class_name, count in sorted(stats.class_distribution.items()):
            percentage = (count / stats.total_objects) * 100 if stats.total_objects > 0 else 0
            logger.info(f"  - {class_name}: {count}ê°œ ({percentage:.1f}%)")

        logger.info(f"\nâœ¨ ì¶œë ¥ ë””ë ‰í† ë¦¬: {self.config.output_dir}")


# ================== ë©”ì¸ í•¨ìˆ˜ ==================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ì„¤ì •
    config = Model3Config(
        source_dir=r"C:\Users\LX\Nong-View\model3_greenhouse",
        output_dir=r"C:\Users\LX\Nong-View\model3_greenhouse_best_processed",
        classes=['Greenhouse_single', 'Greenhouse_multi'],
        nc=2,
        enable_quality_filter=False,  # í’ˆì§ˆ ê²€ìˆ˜ ì´ë¯¸ ì™„ë£Œ
        enable_augmentation=True,
        augmentation_factor=3,
        quality_threshold=0.4,
        random_seed=42
    )

    # ì „ì²˜ë¦¬ê¸° ìƒì„± ë° ì‹¤í–‰
    preprocessor = Model3OptimizedPreprocessor(config)
    stats = preprocessor.run()

    logger.info("\n" + "=" * 60)
    logger.info("ğŸ‰ ì „ì²˜ë¦¬ ì™„ë£Œ!")
    logger.info("=" * 60)


if __name__ == "__main__":
    main()
