#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Model3 Greenhouse - YOLOv11-seg ì „ìš© ì „ì²˜ë¦¬
Segmentation (polygon) í˜•ì‹ ì§€ì›

ì‘ì„±: Claude Sonnet
ë‚ ì§œ: 2025-11-04
"""

import os
import json
import yaml
import shutil
import random
import time
import logging
from pathlib import Path
from typing import Dict, List, Tuple
from collections import Counter, defaultdict
from dataclasses import dataclass, asdict, field

import cv2
import numpy as np
from PIL import Image
from tqdm import tqdm

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.DEBUG,  # INFO -> DEBUGë¡œ ë³€ê²½í•˜ì—¬ ëª¨ë“  ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ================== ì„¤ì • ==================

@dataclass
class SegConfig:
    """Segmentation ì „ìš© ì„¤ì •"""
    source_dir: str = r"D:\Nong-View\model3_greenhouse"
    output_dir: str = r"D:\model3_greenhouse_seg_balanced_5000"

    # ì›ë³¸ í´ë˜ìŠ¤ ID: 9=ë‹¨ë™, 10=ì—°ë™
    original_class_ids: List[int] = field(default_factory=lambda: [9, 10])
    # YOLO í´ë˜ìŠ¤ëª… (0=ë‹¨ë™, 1=ì—°ë™ìœ¼ë¡œ ì¬ë§¤í•‘)
    classes: List[str] = field(default_factory=lambda: ['Greenhouse_single', 'Greenhouse_multi'])
    nc: int = 2

    train_ratio: float = 0.7
    val_ratio: float = 0.2
    test_ratio: float = 0.1

    enable_augmentation: bool = True
    augmentation_factor: int = 3
    balance_classes: bool = True  # í´ë˜ìŠ¤ ê· í˜• ë§ì¶”ê¸°
    target_train_per_class: int = 5000  # ê° í´ë˜ìŠ¤ë‹¹ train ëª©í‘œ

    random_seed: int = 42


@dataclass
class ImageInfo:
    """ì´ë¯¸ì§€ ì •ë³´"""
    filepath: Path
    filename: str
    classes: List[int] = field(default_factory=list)
    class_distribution: Dict[str, int] = field(default_factory=dict)
    dominant_class: int = 0


@dataclass
class ProcessingStats:
    """ì²˜ë¦¬ í†µê³„"""
    original_images: int = 0
    processed_images: int = 0
    augmented_images: int = 0
    total_objects: int = 0
    class_distribution: Dict[str, int] = field(default_factory=dict)
    processing_time: float = 0.0


# ================== ì¦ê°• í´ë˜ìŠ¤ ==================

class SegmentationAugmenter:
    """Segmentation ì „ìš© ì¦ê°• (ë‹¤ì–‘í•œ ê¸°ë²•)"""
    
    def __init__(self):
        self.aug_methods = [
            self.horizontal_flip,
            self.vertical_flip,
            self.rotate_90,
            self.rotate_180,
            self.brightness_contrast,
            self.add_noise,
            self.flip_brightness,
            self.rotate_contrast
        ]

    def augment_image_and_polygons(self, image: np.ndarray, polygons: List[List[float]],
                                   class_labels: List[int], method_idx: int = 0) -> Tuple[np.ndarray, List[List[float]], List[int]]:
        """ì´ë¯¸ì§€ì™€ polygon ì¦ê°•"""
        method = self.aug_methods[method_idx % len(self.aug_methods)]
        return method(image, polygons, class_labels)
    
    def horizontal_flip(self, image: np.ndarray, polygons: List[List[float]],
                       class_labels: List[int]) -> Tuple[np.ndarray, List[List[float]], List[int]]:
        """ì¢Œìš° ë°˜ì „"""
        try:
            aug_image = cv2.flip(image, 1)
            aug_polygons = []

            for poly in polygons:
                aug_poly = []
                for i in range(0, len(poly), 2):
                    x = poly[i]
                    y = poly[i + 1]
                    aug_poly.append(1.0 - x)
                    aug_poly.append(y)
                aug_polygons.append(aug_poly)

            return aug_image, aug_polygons, class_labels.copy()
        except Exception as e:
            logger.error(f"ì¦ê°• ì—ëŸ¬: {e}")
            return image, polygons, class_labels
    
    def vertical_flip(self, image: np.ndarray, polygons: List[List[float]],
                     class_labels: List[int]) -> Tuple[np.ndarray, List[List[float]], List[int]]:
        """ìƒí•˜ ë°˜ì „"""
        try:
            aug_image = cv2.flip(image, 0)
            aug_polygons = []

            for poly in polygons:
                aug_poly = []
                for i in range(0, len(poly), 2):
                    x = poly[i]
                    y = poly[i + 1]
                    aug_poly.append(x)
                    aug_poly.append(1.0 - y)
                aug_polygons.append(aug_poly)

            return aug_image, aug_polygons, class_labels.copy()
        except Exception as e:
            return image, polygons, class_labels
    
    def rotate_90(self, image: np.ndarray, polygons: List[List[float]],
                 class_labels: List[int]) -> Tuple[np.ndarray, List[List[float]], List[int]]:
        """90ë„ íšŒì „"""
        try:
            aug_image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)
            aug_polygons = []

            for poly in polygons:
                aug_poly = []
                for i in range(0, len(poly), 2):
                    x = poly[i]
                    y = poly[i + 1]
                    aug_poly.append(y)
                    aug_poly.append(1.0 - x)
                aug_polygons.append(aug_poly)

            return aug_image, aug_polygons, class_labels.copy()
        except Exception as e:
            return image, polygons, class_labels
    
    def rotate_180(self, image: np.ndarray, polygons: List[List[float]],
                  class_labels: List[int]) -> Tuple[np.ndarray, List[List[float]], List[int]]:
        """180ë„ íšŒì „"""
        try:
            aug_image = cv2.rotate(image, cv2.ROTATE_180)
            aug_polygons = []

            for poly in polygons:
                aug_poly = []
                for i in range(0, len(poly), 2):
                    x = poly[i]
                    y = poly[i + 1]
                    aug_poly.append(1.0 - x)
                    aug_poly.append(1.0 - y)
                aug_polygons.append(aug_poly)

            return aug_image, aug_polygons, class_labels.copy()
        except Exception as e:
            return image, polygons, class_labels
    
    def brightness_contrast(self, image: np.ndarray, polygons: List[List[float]],
                           class_labels: List[int]) -> Tuple[np.ndarray, List[List[float]], List[int]]:
        """ë°ê¸°/ëŒ€ë¹„ ì¡°ì •"""
        try:
            aug_image = image.copy()
            
            brightness = random.uniform(0.7, 1.3)
            aug_image = np.clip(aug_image.astype(np.float32) * brightness, 0, 255).astype(np.uint8)
            
            contrast = random.uniform(0.8, 1.2)
            aug_image = np.clip((aug_image.astype(np.float32) - 127.5) * contrast + 127.5, 0, 255).astype(np.uint8)

            return aug_image, [p.copy() for p in polygons], class_labels.copy()
        except Exception as e:
            return image, polygons, class_labels
    
    def add_noise(self, image: np.ndarray, polygons: List[List[float]],
                 class_labels: List[int]) -> Tuple[np.ndarray, List[List[float]], List[int]]:
        """ë…¸ì´ì¦ˆ ì¶”ê°€"""
        try:
            noise = np.random.normal(0, 10, image.shape).astype(np.int16)
            aug_image = np.clip(image.astype(np.int16) + noise, 0, 255).astype(np.uint8)
            return aug_image, [p.copy() for p in polygons], class_labels.copy()
        except Exception as e:
            return image, polygons, class_labels
    
    def flip_brightness(self, image: np.ndarray, polygons: List[List[float]],
                       class_labels: List[int]) -> Tuple[np.ndarray, List[List[float]], List[int]]:
        """ì¢Œìš°ë°˜ì „ + ë°ê¸°"""
        aug_img, aug_polys, aug_labels = self.horizontal_flip(image, polygons, class_labels)
        brightness = random.uniform(0.8, 1.2)
        aug_img = np.clip(aug_img.astype(np.float32) * brightness, 0, 255).astype(np.uint8)
        return aug_img, aug_polys, aug_labels
    
    def rotate_contrast(self, image: np.ndarray, polygons: List[List[float]],
                       class_labels: List[int]) -> Tuple[np.ndarray, List[List[float]], List[int]]:
        """íšŒì „ + ëŒ€ë¹„"""
        aug_img, aug_polys, aug_labels = self.rotate_180(image, polygons, class_labels)
        contrast = random.uniform(0.9, 1.1)
        aug_img = np.clip((aug_img.astype(np.float32) - 127.5) * contrast + 127.5, 0, 255).astype(np.uint8)
        return aug_img, aug_polys, aug_labels


# ================== ë©”ì¸ ì „ì²˜ë¦¬ í´ë˜ìŠ¤ ==================

class SegmentationPreprocessor:
    """YOLOv11-seg ì „ìš© ì „ì²˜ë¦¬"""

    def __init__(self, config: SegConfig):
        self.config = config
        self.augmenter = SegmentationAugmenter()

        random.seed(config.random_seed)
        np.random.seed(config.random_seed)

        logger.info("=" * 60)
        logger.info("YOLOv11-seg Segmentation ì „ì²˜ë¦¬ ì‹œì‘")
        logger.info("=" * 60)
        logger.info(f"ì†ŒìŠ¤: {config.source_dir}")
        logger.info(f"ì¶œë ¥: {config.output_dir}")
        logger.info(f"ì¦ê°•: {config.augmentation_factor}ë°°")

    def run(self) -> ProcessingStats:
        """ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        start_time = time.time()

        logger.info("\n[1/5] ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        image_infos = self._collect_images()
        logger.info(f"âœ“ {len(image_infos)}ê°œ ì´ë¯¸ì§€ ìˆ˜ì§‘")

        logger.info("\n[2/5] ê³„ì¸µí™” ë¶„í•  ì¤‘...")
        splits = self._stratified_split(image_infos)
        logger.info(f"âœ“ Train: {len(splits['train'])}, Val: {len(splits['val'])}, Test: {len(splits['test'])}")

        logger.info("\n[3/5] ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„± ì¤‘...")
        output_path = Path(self.config.output_dir)
        self._setup_output_structure(output_path)
        logger.info(f"âœ“ {output_path}")

        logger.info("\n[4/5] ë°ì´í„° ë³µì‚¬ ë° ì¦ê°• ì¤‘...")
        stats = self._copy_and_augment(splits, output_path)
        logger.info(f"âœ“ ì²˜ë¦¬: {stats.processed_images}ê°œ, ì¦ê°•: {stats.augmented_images}ê°œ")

        logger.info("\n[5/5] ë©”íƒ€ë°ì´í„° ìƒì„± ì¤‘...")
        self._create_yaml(splits, output_path, stats)
        self._save_stats(stats, output_path)
        logger.info("âœ“ ì™„ë£Œ")

        stats.processing_time = time.time() - start_time

        logger.info("\n" + "=" * 60)
        logger.info("âœ… ì „ì²˜ë¦¬ ì™„ë£Œ!")
        logger.info("=" * 60)
        self._print_summary(stats)

        return stats

    def _collect_images(self) -> List[ImageInfo]:
        """ì´ë¯¸ì§€ ìˆ˜ì§‘ (images í´ë”ì—ì„œ ì§ì ‘)"""
        source_path = Path(self.config.source_dir)
        all_images = []

        # images í´ë”ì—ì„œ ì§ì ‘ ìˆ˜ì§‘ (train/val/test ë¶„í•  ì „)
        images_dir = source_path / 'images'
        labels_dir = source_path / 'labels'

        if not images_dir.exists():
            logger.error(f"ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ì—†ìŒ: {images_dir}")
            return all_images
        
        if not labels_dir.exists():
            logger.error(f"ë¼ë²¨ ë””ë ‰í† ë¦¬ ì—†ìŒ: {labels_dir}")
            return all_images

        # ëª¨ë“  TIF ì´ë¯¸ì§€ ìˆ˜ì§‘
        for img_path in list(images_dir.glob('*.tif')) + list(images_dir.glob('*.tiff')):
            label_path = labels_dir / f"{img_path.stem}.txt"

            if label_path.exists():
                classes, class_dist = self._parse_seg_label(label_path)

                if classes:
                    # ì£¼ìš” í´ë˜ìŠ¤ ì°¾ê¸°
                    class_counts = Counter(classes)
                    dominant_class = class_counts.most_common(1)[0][0]

                    info = ImageInfo(
                        filepath=img_path,
                        filename=img_path.name,
                        classes=classes,
                        class_distribution=class_dist,
                        dominant_class=dominant_class
                    )
                    all_images.append(info)

        return all_images

    def _remap_class_id(self, original_id: int) -> int:
        """ì›ë³¸ í´ë˜ìŠ¤ IDë¥¼ YOLO IDë¡œ ì¬ë§¤í•‘ (9->0, 10->1)"""
        if original_id in self.config.original_class_ids:
            return self.config.original_class_ids.index(original_id)
        return original_id
    
    def _parse_seg_label(self, label_path: Path) -> Tuple[List[int], Dict[str, int]]:
        """Segmentation ë¼ë²¨ íŒŒì‹± (í´ë˜ìŠ¤ ID ì¬ë§¤í•‘ í¬í•¨)"""
        classes = []
        class_dist = defaultdict(int)

        try:
            with open(label_path, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) >= 3:
                        original_class_id = int(parts[0])
                        
                        # í´ë˜ìŠ¤ ID ì¬ë§¤í•‘ (9->0, 10->1)
                        class_id = self._remap_class_id(original_class_id)
                        classes.append(class_id)

                        if 0 <= class_id < len(self.config.classes):
                            class_name = self.config.classes[class_id]
                        else:
                            class_name = f"Class_{class_id}"

                        class_dist[class_name] += 1
        except Exception as e:
            logger.error(f"ë¼ë²¨ íŒŒì‹± ì‹¤íŒ¨ {label_path.name}: {e}")

        return classes, dict(class_dist)

    def _stratified_split(self, image_infos: List[ImageInfo]) -> Dict[str, List[ImageInfo]]:
        """ê³„ì¸µí™” ë¶„í• """
        class_groups = defaultdict(list)
        for info in image_infos:
            class_groups[info.dominant_class].append(info)

        train_images = []
        val_images = []
        test_images = []

        for class_id, class_images in class_groups.items():
            random.shuffle(class_images)

            n = len(class_images)
            n_train = int(n * self.config.train_ratio)
            n_val = int(n * self.config.val_ratio)

            train_images.extend(class_images[:n_train])
            val_images.extend(class_images[n_train:n_train + n_val])
            test_images.extend(class_images[n_train + n_val:])

            if 0 <= class_id < len(self.config.classes):
                class_name = self.config.classes[class_id]
            else:
                class_name = f"Class_{class_id}"

            logger.info(f"  {class_name}: Train={n_train}, Val={n_val}, Test={n - n_train - n_val}")

        random.shuffle(train_images)
        random.shuffle(val_images)
        random.shuffle(test_images)

        return {
            'train': train_images,
            'val': val_images,
            'test': test_images
        }

    def _setup_output_structure(self, output_path: Path):
        """ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±"""
        if output_path.exists():
            logger.warning(f"ê¸°ì¡´ ë””ë ‰í† ë¦¬ ì‚­ì œ: {output_path}")
            shutil.rmtree(output_path)

        for split in ['train', 'val', 'test']:
            (output_path / 'images' / split).mkdir(parents=True, exist_ok=True)
            (output_path / 'labels' / split).mkdir(parents=True, exist_ok=True)

    def _calculate_class_augmentation_factors(self, train_images: List[ImageInfo]) -> Dict[int, int]:
        """í´ë˜ìŠ¤ë³„ ì¦ê°• ë°°ìˆ˜ ê³„ì‚°"""
        # í´ë˜ìŠ¤ë³„ train ì´ë¯¸ì§€ ìˆ˜ ê³„ì‚°
        class_counts = Counter()
        for info in train_images:
            class_counts[info.dominant_class] += 1
        
        logger.info(f"\nTrain ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬ (ì¬ë§¤í•‘ í›„):")
        for class_id, count in sorted(class_counts.items()):
            if 0 <= class_id < len(self.config.classes):
                class_name = self.config.classes[class_id]
            else:
                class_name = f"Class_{class_id}"
            logger.info(f"  - Class {class_id} ({class_name}): {count}ê°œ")
        
        if not class_counts:
            logger.warning("í´ë˜ìŠ¤ ì¹´ìš´íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
            return {}
        
        # í´ë˜ìŠ¤ë³„ ì¦ê°• ë°°ìˆ˜ ê³„ì‚°
        aug_factors = {}
        
        logger.info("\ní´ë˜ìŠ¤ë³„ ì¦ê°• ì „ëµ:")
        for class_id in sorted(class_counts.keys()):
            if 0 <= class_id < len(self.config.classes):
                class_name = self.config.classes[class_id]
            else:
                class_name = f"Class_{class_id}"
            
            current_count = class_counts[class_id]
            target_count = self.config.target_train_per_class
            
            # í•„ìš”í•œ ì¦ê°• ê°œìˆ˜ = ëª©í‘œ - í˜„ì¬
            needed = max(0, target_count - current_count)
            aug_factors[class_id] = needed
            
            logger.info(f"  - {class_name:20s}: {current_count:4d}ê°œ â†’ (+{needed:4d}) â†’ {current_count + needed:4d}ê°œ")
        
        logger.info(f"\nì¦ê°• factors: {aug_factors}")
        return aug_factors

    def _copy_and_augment(self, splits: Dict[str, List[ImageInfo]], output_path: Path) -> ProcessingStats:
        """ë°ì´í„° ë³µì‚¬ ë° í´ë˜ìŠ¤ë³„ ê· í˜• ì¦ê°•"""
        stats = ProcessingStats()
        stats.original_images = sum(len(images) for images in splits.values())

        total_processed = 0
        total_augmented = 0
        class_counter = Counter()
        
        # í´ë˜ìŠ¤ë³„ ì¦ê°• ë°°ìˆ˜ ê³„ì‚° (balance_classes=Trueì¼ ë•Œë§Œ)
        aug_factors = {}
        if self.config.enable_augmentation and self.config.balance_classes:
            aug_factors = self._calculate_class_augmentation_factors(splits['train'])

        for split_name, image_infos in splits.items():
            images_dir = output_path / 'images' / split_name
            labels_dir = output_path / 'labels' / split_name

            apply_augmentation = (split_name == 'train' and self.config.enable_augmentation)

            # Val/TestëŠ” ê°„ë‹¨íˆ ë³µì‚¬ë§Œ
            if not apply_augmentation:
                for info in tqdm(image_infos, desc=f"{split_name} ì²˜ë¦¬", ncols=70):
                    self._copy_single_file(info, images_dir, labels_dir)
                    total_processed += 1
                    
                    for class_name, count in info.class_distribution.items():
                        class_counter[class_name] += count
                continue
            
            # Trainì€ í´ë˜ìŠ¤ë³„ë¡œ ì²˜ë¦¬
            if self.config.balance_classes and aug_factors:
                # í´ë˜ìŠ¤ë³„ë¡œ ë¶„ë¦¬
                class_images = defaultdict(list)
                for info in image_infos:
                    class_images[info.dominant_class].append(info)
                
                # í´ë˜ìŠ¤ë³„ë¡œ ë³µì‚¬ ë° ì¦ê°•
                for class_id in sorted(class_images.keys()):
                    class_name = self.config.classes[class_id] if class_id < len(self.config.classes) else f"Class_{class_id}"
                    class_imgs = class_images[class_id]
                    
                    logger.info(f"\n{class_name} ì²˜ë¦¬ ì¤‘...")
                    
                    # ì›ë³¸ ë³µì‚¬
                    for info in tqdm(class_imgs, desc=f"  ì›ë³¸ ë³µì‚¬", ncols=70, 
                                   bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt}'):
                        self._copy_single_file(info, images_dir, labels_dir)
                        total_processed += 1
                        
                        for cls_name, count in info.class_distribution.items():
                            class_counter[cls_name] += count
                    
                    # ì¦ê°•
                    needed = aug_factors.get(class_id, 0)
                    if needed > 0:
                        augmented = self._augment_class_batch(
                            class_imgs, images_dir, labels_dir, class_id, needed
                        )
                        total_augmented += augmented
                        
                        # ì¦ê°• ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬ ì—…ë°ì´íŠ¸
                        for info in class_imgs[:1]:  # ëŒ€í‘œ ì´ë¯¸ì§€ì˜ ë¶„í¬ ì‚¬ìš©
                            for cls_name, count in info.class_distribution.items():
                                class_counter[cls_name] += count * augmented
            
            else:
                # ê¸°ì¡´ ë°©ì‹ (ëª¨ë“  ì´ë¯¸ì§€ì— ë™ì¼ ë°°ìˆ˜)
                for info in tqdm(image_infos, desc=f"{split_name} ì²˜ë¦¬", ncols=70):
                    self._copy_single_file(info, images_dir, labels_dir)
                    total_processed += 1

                    for class_name, count in info.class_distribution.items():
                        class_counter[class_name] += count

                    aug_count = self._augment_single(
                        info, images_dir, labels_dir, self.config.augmentation_factor - 1, 0
                    )
                    total_augmented += aug_count
                    
                    for class_name, count in info.class_distribution.items():
                        class_counter[class_name] += count * aug_count

        stats.processed_images = total_processed
        stats.augmented_images = total_augmented
        stats.total_objects = sum(class_counter.values())
        stats.class_distribution = dict(class_counter)

        return stats
    
    def _augment_class_batch(self, class_images: List[ImageInfo], images_dir: Path,
                            labels_dir: Path, class_id: int, needed: int) -> int:
        """íŠ¹ì • í´ë˜ìŠ¤ë¥¼ ë°°ì¹˜ë¡œ ì¦ê°•"""
        augmented = 0
        class_name = self.config.classes[class_id] if class_id < len(self.config.classes) else f"Class_{class_id}"
        
        pbar = tqdm(total=needed, desc=f"  ì¦ê°• ìƒì„±", ncols=70,
                   bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt}')
        
        method_idx = 0
        while augmented < needed:
            source_img = random.choice(class_images)
            
            try:
                if self._augment_single(source_img, images_dir, labels_dir, 1, method_idx, 
                                       aug_prefix=f"{class_name[:6]}_aug{augmented:04d}"):
                    augmented += 1
                    pbar.update(1)
                
                method_idx += 1
            except:
                continue
        
        pbar.close()
        return augmented

    def _copy_single_file(self, info: ImageInfo, images_dir: Path, labels_dir: Path):
        """ë‹¨ì¼ íŒŒì¼ ë³µì‚¬"""
        # ì´ë¯¸ì§€ ë³µì‚¬
        shutil.copy2(info.filepath, images_dir / info.filename)

        # ë¼ë²¨ ë³µì‚¬ - ì§ì ‘ ê²½ë¡œ
        # info.filepath: .../model3_greenhouse/images/xxx.png
        # source_label: .../model3_greenhouse/labels/xxx.txt
        source_data_root = info.filepath.parent.parent  # .../model3_greenhouse
        source_label = source_data_root / 'labels' / f"{info.filepath.stem}.txt"
        
        if source_label.exists():
            shutil.copy2(source_label, labels_dir / f"{info.filepath.stem}.txt")
        else:
            logger.warning(f"ë¼ë²¨ íŒŒì¼ ì—†ìŒ (ë³µì‚¬): {source_label}")

    def _augment_single(self, info: ImageInfo, images_dir: Path, labels_dir: Path, 
                       count: int, method_idx: int = 0, aug_prefix: str = None) -> int:
        """ë‹¨ì¼ ì´ë¯¸ì§€ ì¦ê°• (Segmentation)"""
        if count <= 0:
            return 0

        # ë¼ë²¨ ê²½ë¡œ (ì§ì ‘)
        source_data_root = info.filepath.parent.parent  # .../model3_greenhouse
        source_label = source_data_root / 'labels' / f"{info.filepath.stem}.txt"

        if not source_label.exists():
            return 0

        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = cv2.imread(str(info.filepath))
            if image is None:
                return 0

            # Segmentation ë¼ë²¨ ë¡œë“œ
            polygons, class_labels = self._load_seg_labels(source_label)
            if not polygons:
                return 0

            successful = 0

            for i in range(count):
                try:
                    # ì¦ê°• ì ìš© (ë‹¤ì–‘í•œ ê¸°ë²•)
                    aug_image, aug_polygons, aug_labels = self.augmenter.augment_image_and_polygons(
                        image, polygons, class_labels, method_idx + i
                    )

                    if not aug_polygons:
                        continue

                    # íŒŒì¼ëª… ê²°ì • (PNGë¡œ ì €ì¥)
                    if aug_prefix:
                        aug_img_name = f"{aug_prefix}.png"
                        aug_label_name = f"{aug_prefix}.txt"
                    else:
                        aug_img_name = f"{info.filepath.stem}_aug{i+1}.png"
                        aug_label_name = f"{info.filepath.stem}_aug{i+1}.txt"
                    
                    # ì¦ê°• ì´ë¯¸ì§€ ì €ì¥ (PNGë¡œ ë³€í™˜)
                    aug_img_path = images_dir / aug_img_name
                    result = cv2.imwrite(str(aug_img_path), aug_image)
                    if not result:
                        continue

                    # ì¦ê°• ë¼ë²¨ ì €ì¥
                    aug_label_path = labels_dir / aug_label_name
                    self._save_seg_labels(aug_label_path, aug_polygons, aug_labels)

                    # ì €ì¥ í™•ì¸
                    if aug_img_path.exists() and aug_label_path.exists():
                        successful += 1
                    
                except Exception as e:
                    logger.debug(f"ì¦ê°• ì‹¤íŒ¨: {e}")
                    continue

            return successful

        except Exception as e:
            return 0

    def _load_seg_labels(self, label_path: Path) -> Tuple[List[List[float]], List[int]]:
        """Segmentation ë¼ë²¨ ë¡œë“œ (í´ë˜ìŠ¤ ID ì¬ë§¤í•‘ í¬í•¨)"""
        polygons = []
        class_labels = []

        try:
            with open(label_path, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) >= 3:
                        original_class_id = int(parts[0])
                        polygon = [float(x) for x in parts[1:]]
                        
                        # í´ë˜ìŠ¤ ID ì¬ë§¤í•‘ (9->0, 10->1)
                        class_id = self._remap_class_id(original_class_id)

                        polygons.append(polygon)
                        class_labels.append(class_id)
        except Exception as e:
            logger.error(f"ë¼ë²¨ ë¡œë“œ ì‹¤íŒ¨ {label_path}: {e}")

        return polygons, class_labels

    def _save_seg_labels(self, label_path: Path, polygons: List[List[float]], class_labels: List[int]):
        """Segmentation ë¼ë²¨ ì €ì¥"""
        try:
            with open(label_path, 'w') as f:
                for polygon, class_id in zip(polygons, class_labels):
                    # class_id + polygon ì¢Œí‘œë“¤
                    coords_str = ' '.join([f"{coord:.10f}" for coord in polygon])
                    f.write(f"{class_id} {coords_str}\n")
        except Exception as e:
            logger.error(f"ë¼ë²¨ ì €ì¥ ì‹¤íŒ¨ {label_path}: {e}")

    def _create_yaml(self, splits: Dict[str, List[ImageInfo]], output_path: Path, stats: ProcessingStats):
        """YAML íŒŒì¼ ìƒì„±"""
        yaml_content = {
            'path': str(output_path.absolute()),
            'train': 'images/train',
            'val': 'images/val',
            'test': 'images/test',
            'nc': self.config.nc,
            'names': self.config.classes,

            'task': 'segment',  # Segmentation ëª…ì‹œ

            'dataset_info': {
                'total': stats.original_images,
                'train': len(splits['train']),
                'val': len(splits['val']),
                'test': len(splits['test']),
                'processed': stats.processed_images,
                'augmented': stats.augmented_images
            },

            'preprocessing': {
                'method': 'balanced_class_augmentation' if self.config.balance_classes else 'stratified_split_segmentation',
                'augmentation': self.config.enable_augmentation,
                'augmentation_factor': self.config.augmentation_factor,
                'balance_classes': self.config.balance_classes,
                'target_train_per_class': self.config.target_train_per_class if self.config.balance_classes else None,
                'random_seed': self.config.random_seed
            }
        }

        yaml_path = output_path / 'data.yaml'
        with open(yaml_path, 'w', encoding='utf-8') as f:
            yaml.dump(yaml_content, f, default_flow_style=False, allow_unicode=True, sort_keys=False)

        logger.info(f"YAML: {yaml_path}")

    def _save_stats(self, stats: ProcessingStats, output_path: Path):
        """í†µê³„ ì €ì¥"""
        stats_path = output_path / 'processing_stats.json'
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(asdict(stats), f, indent=2, ensure_ascii=False)

        logger.info(f"í†µê³„: {stats_path}")

    def _print_summary(self, stats: ProcessingStats):
        """ìš”ì•½ ì¶œë ¥"""
        logger.info(f"\nğŸ“Š ì²˜ë¦¬ í†µê³„:")
        logger.info(f"  - ì›ë³¸ ì´ë¯¸ì§€: {stats.original_images}ê°œ")
        logger.info(f"  - ì²˜ë¦¬ëœ ì´ë¯¸ì§€: {stats.processed_images}ê°œ")
        logger.info(f"  - ì¦ê°•ëœ ì´ë¯¸ì§€: {stats.augmented_images}ê°œ")
        logger.info(f"  - ì´ ì´ë¯¸ì§€: {stats.processed_images + stats.augmented_images}ê°œ")
        logger.info(f"  - ì¦ê°• ë¹„ìœ¨: {(stats.augmented_images/stats.processed_images if stats.processed_images > 0 else 0):.2f}ë°°")
        logger.info(f"  - ì´ ê°ì²´: {stats.total_objects}ê°œ")
        logger.info(f"  - ì²˜ë¦¬ ì‹œê°„: {stats.processing_time:.2f}ì´ˆ")

        logger.info(f"\nğŸ“Š í´ë˜ìŠ¤ ë¶„í¬:")
        for class_name, count in sorted(stats.class_distribution.items()):
            percentage = (count / stats.total_objects) * 100 if stats.total_objects > 0 else 0
            logger.info(f"  - {class_name}: {count}ê°œ ({percentage:.1f}%)")

        logger.info(f"\nâœ¨ ì¶œë ¥: {self.config.output_dir}")
        
        # ì¦ê°• í™•ì¸
        if self.config.enable_augmentation and stats.augmented_images == 0:
            logger.warning(f"\nâš ï¸  ê²½ê³ : ì¦ê°•ì´ í™œì„±í™”ë˜ì—ˆì§€ë§Œ ì¦ê°•ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤!")
            logger.warning(f"   - augmentation_factor: {self.config.augmentation_factor}")
            logger.warning(f"   - ì¦ê°• ëŒ€ìƒ: train ë°ì´í„°ë§Œ")


# ================== ë©”ì¸ í•¨ìˆ˜ ==================

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    config = SegConfig(
        source_dir=r"D:\Nong-View\model3_greenhouse",
        output_dir=r"D:\model3_greenhouse_seg_balanced_5000",
        original_class_ids=[9, 10],  # ì›ë³¸: 9=ë‹¨ë™, 10=ì—°ë™
        classes=['Greenhouse_single', 'Greenhouse_multi'],  # YOLO: 0=ë‹¨ë™, 1=ì—°ë™
        nc=2,
        enable_augmentation=True,
        augmentation_factor=3,
        balance_classes=True,
        target_train_per_class=5000,
        random_seed=42
    )

    preprocessor = SegmentationPreprocessor(config)
    stats = preprocessor.run()

    logger.info("\n" + "=" * 60)
    logger.info(">> YOLOv11-seg ì „ì²˜ë¦¬ ì™„ë£Œ!")
    logger.info("=" * 60)


if __name__ == "__main__":
    main()
